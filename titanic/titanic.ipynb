{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>51.0</td>\n",
       "      <td>D11</td>\n",
       "      <td>S</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>Hogeboom, Mrs. John C (Anna Andrews)</td>\n",
       "      <td>0</td>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Butler, Mr. Reginald Fenton</td>\n",
       "      <td>0</td>\n",
       "      <td>667</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>Vande Walle, Mr. Nestor Cyriel</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.0</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Navratil, Master. Edmond Roger</td>\n",
       "      <td>1</td>\n",
       "      <td>341</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0458</td>\n",
       "      <td>Braund, Mr. Lewis Richard</td>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>44.0</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Minahan, Dr. William Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>Meyer, Mrs. Edgar Joseph (Leila Saks)</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CA. 2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Beane, Mrs. Edward (Ethel Clarke)</td>\n",
       "      <td>0</td>\n",
       "      <td>547</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>23.0</td>\n",
       "      <td>D36</td>\n",
       "      <td>C</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>Newell, Miss. Marjorie</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>Uruchurtu, Don. Manuel E</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>17.4000</td>\n",
       "      <td>de Messemaeker, Mrs. Guillaume Joseph (Emma)</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>345572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Gustafsson, Mr. Karl Gideon</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>Mallet, Master. Andre</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S.C./PARIS 2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>0</td>\n",
       "      <td>867</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>65.0</td>\n",
       "      <td>E38</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Millet, Mr. Francis Davis</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>55.0</td>\n",
       "      <td>C30</td>\n",
       "      <td>S</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>Molson, Mr. Harry Markland</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>Ryan, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>518</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Leeni, Mr. Fahim (\"Philip Zenni\")</td>\n",
       "      <td>0</td>\n",
       "      <td>554</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Horgan, Mr. John</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>Cleaver, Miss. Alice</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>54.0</td>\n",
       "      <td>D26</td>\n",
       "      <td>S</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>White, Mr. Percival Wayland</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Gavey, Mr. Lawrence</td>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>Andersson, Mrs. Anders Johan (Alfrida Konstant...</td>\n",
       "      <td>5</td>\n",
       "      <td>611</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>36.5</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Navratil, Mr. Michel (\"Louis M Hoffman\")</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>Hassan, Mr. Houssein G N</td>\n",
       "      <td>0</td>\n",
       "      <td>732</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>Dean, Master. Bertram Vere</td>\n",
       "      <td>2</td>\n",
       "      <td>789</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C.A. 2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Canavan, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>1</td>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>23.0</td>\n",
       "      <td>B24</td>\n",
       "      <td>S</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>Payne, Mr. Vivian Ponsonby</td>\n",
       "      <td>0</td>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>51.0</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>Lines, Mrs. Ernest H (Elizabeth Lindsey James)</td>\n",
       "      <td>1</td>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>Abbott, Master. Eugene Joseph</td>\n",
       "      <td>2</td>\n",
       "      <td>1284</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Gilbert, Mr. William</td>\n",
       "      <td>0</td>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 30769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>Kink-Heilmann, Mr. Anton</td>\n",
       "      <td>1</td>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>18.0</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>Smith, Mrs. Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>0</td>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Colbert, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1288</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>48.0</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Larsson-Rondberg, Mr. Edvard A</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Conlon, Mr. Thomas Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>Bonnell, Miss. Caroline</td>\n",
       "      <td>0</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>Gale, Mr. Harry</td>\n",
       "      <td>0</td>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>1</td>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>Carrau, Mr. Jose Pedro</td>\n",
       "      <td>0</td>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>43.0</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>Frauenthal, Mr. Isaac Gerald</td>\n",
       "      <td>0</td>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>20.0</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>Nourney, Mr. Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Ware, Mr. William Jeffery</td>\n",
       "      <td>0</td>\n",
       "      <td>1298</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>50.0</td>\n",
       "      <td>C80</td>\n",
       "      <td>C</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>Widener, Mr. George Dunton</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Naughton, Miss. Hannah</td>\n",
       "      <td>0</td>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>37.0</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td>\n",
       "      <td>0</td>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
       "      <td>0</td>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A.5. 3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>39.0</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>0</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>38.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>1</td>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Cabin Embarked      Fare  \\\n",
       "765  51.0   D11        S   77.9583   \n",
       "666  25.0   NaN        S   13.0000   \n",
       "200  28.0   NaN        S    9.5000   \n",
       "271  25.0   NaN        S    0.0000   \n",
       "340   2.0    F2        S   26.0000   \n",
       "887  19.0   B42        S   30.0000   \n",
       "477  29.0   NaN        S    7.0458   \n",
       "245  44.0   C78        Q   90.0000   \n",
       "375   NaN   NaN        C   82.1708   \n",
       "863   NaN   NaN        S   69.5500   \n",
       "546  19.0   NaN        S   26.0000   \n",
       "393  23.0   D36        C  113.2750   \n",
       "30   40.0   NaN        C   27.7208   \n",
       "559  36.0   NaN        S   17.4000   \n",
       "379  19.0   NaN        S    7.7750   \n",
       "827   1.0   NaN        C   37.0042   \n",
       "866  27.0   NaN        C   13.8583   \n",
       "456  65.0   E38        S   26.5500   \n",
       "869   4.0   NaN        S   11.1333   \n",
       "492  55.0   C30        S   30.5000   \n",
       "517   NaN   NaN        Q   24.1500   \n",
       "553  22.0   NaN        C    7.2250   \n",
       "613   NaN   NaN        Q    7.7500   \n",
       "708  22.0   NaN        S  151.5500   \n",
       "124  54.0   D26        S   77.2875   \n",
       "619  26.0   NaN        S   10.5000   \n",
       "610  39.0   NaN        S   31.2750   \n",
       "148  36.5    F2        S   26.0000   \n",
       "731  11.0   NaN        C   18.7875   \n",
       "788   1.0   NaN        S   20.5750   \n",
       "..    ...   ...      ...       ...   \n",
       "388  21.0   NaN        Q    7.7500   \n",
       "389   6.0   NaN        S   21.0750   \n",
       "390  23.0   B24        S   93.5000   \n",
       "391  51.0   D28        S   39.4000   \n",
       "392  13.0   NaN        S   20.2500   \n",
       "393  47.0   NaN        S   10.5000   \n",
       "394  29.0   NaN        S   22.0250   \n",
       "395  18.0   C31        S   60.0000   \n",
       "396  24.0   NaN        Q    7.2500   \n",
       "397  48.0   B41        C   79.2000   \n",
       "398  22.0   NaN        S    7.7750   \n",
       "399  31.0   NaN        Q    7.7333   \n",
       "400  30.0    C7        S  164.8667   \n",
       "401  38.0   NaN        S   21.0000   \n",
       "402  22.0   NaN        C   59.4000   \n",
       "403  17.0   NaN        S   47.1000   \n",
       "404  43.0   D40        C   27.7208   \n",
       "405  20.0   D38        C   13.8625   \n",
       "406  23.0   NaN        S   10.5000   \n",
       "407  50.0   C80        C  211.5000   \n",
       "408   NaN   NaN        Q    7.7208   \n",
       "409   3.0   NaN        S   13.7750   \n",
       "410   NaN   NaN        Q    7.7500   \n",
       "411  37.0   C78        Q   90.0000   \n",
       "412  28.0   NaN        S    7.7750   \n",
       "413   NaN   NaN        S    8.0500   \n",
       "414  39.0  C105        C  108.9000   \n",
       "415  38.5   NaN        S    7.2500   \n",
       "416   NaN   NaN        S    8.0500   \n",
       "417   NaN   NaN        C   22.3583   \n",
       "\n",
       "                                                  Name  Parch  PassengerId  \\\n",
       "765               Hogeboom, Mrs. John C (Anna Andrews)      0          766   \n",
       "666                        Butler, Mr. Reginald Fenton      0          667   \n",
       "200                     Vande Walle, Mr. Nestor Cyriel      0          201   \n",
       "271                       Tornquist, Mr. William Henry      0          272   \n",
       "340                     Navratil, Master. Edmond Roger      1          341   \n",
       "887                       Graham, Miss. Margaret Edith      0          888   \n",
       "477                          Braund, Mr. Lewis Richard      0          478   \n",
       "245                        Minahan, Dr. William Edward      0          246   \n",
       "375              Meyer, Mrs. Edgar Joseph (Leila Saks)      0          376   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"      2          864   \n",
       "546                  Beane, Mrs. Edward (Ethel Clarke)      0          547   \n",
       "393                             Newell, Miss. Marjorie      0          394   \n",
       "30                            Uruchurtu, Don. Manuel E      0           31   \n",
       "559       de Messemaeker, Mrs. Guillaume Joseph (Emma)      0          560   \n",
       "379                        Gustafsson, Mr. Karl Gideon      0          380   \n",
       "827                              Mallet, Master. Andre      2          828   \n",
       "866                       Duran y More, Miss. Asuncion      0          867   \n",
       "456                          Millet, Mr. Francis Davis      0          457   \n",
       "869                    Johnson, Master. Harold Theodor      1          870   \n",
       "492                         Molson, Mr. Harry Markland      0          493   \n",
       "517                                  Ryan, Mr. Patrick      0          518   \n",
       "553                  Leeni, Mr. Fahim (\"Philip Zenni\")      0          554   \n",
       "613                                   Horgan, Mr. John      0          614   \n",
       "708                               Cleaver, Miss. Alice      0          709   \n",
       "124                        White, Mr. Percival Wayland      1          125   \n",
       "619                                Gavey, Mr. Lawrence      0          620   \n",
       "610  Andersson, Mrs. Anders Johan (Alfrida Konstant...      5          611   \n",
       "148           Navratil, Mr. Michel (\"Louis M Hoffman\")      2          149   \n",
       "731                           Hassan, Mr. Houssein G N      0          732   \n",
       "788                         Dean, Master. Bertram Vere      2          789   \n",
       "..                                                 ...    ...          ...   \n",
       "388                               Canavan, Mr. Patrick      0         1280   \n",
       "389                        Palsson, Master. Paul Folke      1         1281   \n",
       "390                         Payne, Mr. Vivian Ponsonby      0         1282   \n",
       "391     Lines, Mrs. Ernest H (Elizabeth Lindsey James)      1         1283   \n",
       "392                      Abbott, Master. Eugene Joseph      2         1284   \n",
       "393                               Gilbert, Mr. William      0         1285   \n",
       "394                           Kink-Heilmann, Mr. Anton      1         1286   \n",
       "395     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)      0         1287   \n",
       "396                               Colbert, Mr. Patrick      0         1288   \n",
       "397  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...      1         1289   \n",
       "398                     Larsson-Rondberg, Mr. Edvard A      0         1290   \n",
       "399                           Conlon, Mr. Thomas Henry      0         1291   \n",
       "400                            Bonnell, Miss. Caroline      0         1292   \n",
       "401                                    Gale, Mr. Harry      0         1293   \n",
       "402                     Gibson, Miss. Dorothy Winifred      1         1294   \n",
       "403                             Carrau, Mr. Jose Pedro      0         1295   \n",
       "404                       Frauenthal, Mr. Isaac Gerald      0         1296   \n",
       "405       Nourney, Mr. Alfred (Baron von Drachstedt\")\"      0         1297   \n",
       "406                          Ware, Mr. William Jeffery      0         1298   \n",
       "407                         Widener, Mr. George Dunton      1         1299   \n",
       "408                    Riordan, Miss. Johanna Hannah\"\"      0         1300   \n",
       "409                          Peacock, Miss. Treasteall      1         1301   \n",
       "410                             Naughton, Miss. Hannah      0         1302   \n",
       "411    Minahan, Mrs. William Edward (Lillian E Thorpe)      0         1303   \n",
       "412                     Henriksson, Miss. Jenny Lovisa      0         1304   \n",
       "413                                 Spector, Mr. Woolf      0         1305   \n",
       "414                       Oliva y Ocana, Dona. Fermina      0         1306   \n",
       "415                       Saether, Mr. Simon Sivertsen      0         1307   \n",
       "416                                Ware, Mr. Frederick      0         1308   \n",
       "417                           Peter, Master. Michael J      1         1309   \n",
       "\n",
       "     Pclass     Sex  SibSp  Survived              Ticket  \n",
       "765       1  female      1       1.0               13502  \n",
       "666       2    male      0       0.0              234686  \n",
       "200       3    male      0       0.0              345770  \n",
       "271       3    male      0       1.0                LINE  \n",
       "340       2    male      1       1.0              230080  \n",
       "887       1  female      0       1.0              112053  \n",
       "477       3    male      1       0.0                3460  \n",
       "245       1    male      2       0.0               19928  \n",
       "375       1  female      1       1.0            PC 17604  \n",
       "863       3  female      8       0.0            CA. 2343  \n",
       "546       2  female      1       1.0                2908  \n",
       "393       1  female      1       1.0               35273  \n",
       "30        1    male      0       0.0            PC 17601  \n",
       "559       3  female      1       1.0              345572  \n",
       "379       3    male      0       0.0              347069  \n",
       "827       2    male      0       1.0     S.C./PARIS 2079  \n",
       "866       2  female      1       1.0       SC/PARIS 2149  \n",
       "456       1    male      0       0.0               13509  \n",
       "869       3    male      1       1.0              347742  \n",
       "492       1    male      0       0.0              113787  \n",
       "517       3    male      0       0.0              371110  \n",
       "553       3    male      0       1.0                2620  \n",
       "613       3    male      0       0.0              370377  \n",
       "708       1  female      0       1.0              113781  \n",
       "124       1    male      0       0.0               35281  \n",
       "619       2    male      0       0.0               31028  \n",
       "610       3  female      1       0.0              347082  \n",
       "148       2    male      0       0.0              230080  \n",
       "731       3    male      0       0.0                2699  \n",
       "788       3    male      1       1.0           C.A. 2315  \n",
       "..      ...     ...    ...       ...                 ...  \n",
       "388       3    male      0       NaN              364858  \n",
       "389       3    male      3       NaN              349909  \n",
       "390       1    male      0       NaN               12749  \n",
       "391       1  female      0       NaN            PC 17592  \n",
       "392       3    male      0       NaN           C.A. 2673  \n",
       "393       2    male      0       NaN          C.A. 30769  \n",
       "394       3    male      3       NaN              315153  \n",
       "395       1  female      1       NaN               13695  \n",
       "396       3    male      0       NaN              371109  \n",
       "397       1  female      1       NaN               13567  \n",
       "398       3    male      0       NaN              347065  \n",
       "399       3    male      0       NaN               21332  \n",
       "400       1  female      0       NaN               36928  \n",
       "401       2    male      1       NaN               28664  \n",
       "402       1  female      0       NaN              112378  \n",
       "403       1    male      0       NaN              113059  \n",
       "404       1    male      1       NaN               17765  \n",
       "405       2    male      0       NaN       SC/PARIS 2166  \n",
       "406       2    male      1       NaN               28666  \n",
       "407       1    male      1       NaN              113503  \n",
       "408       3  female      0       NaN              334915  \n",
       "409       3  female      1       NaN  SOTON/O.Q. 3101315  \n",
       "410       3  female      0       NaN              365237  \n",
       "411       1  female      1       NaN               19928  \n",
       "412       3  female      0       NaN              347086  \n",
       "413       3    male      0       NaN           A.5. 3236  \n",
       "414       1  female      0       NaN            PC 17758  \n",
       "415       3    male      0       NaN  SOTON/O.Q. 3101262  \n",
       "416       3    male      0       NaN              359309  \n",
       "417       3    male      1       NaN                2668  \n",
       "\n",
       "[1309 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61616161616161613"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-df_train['Survived'].sum()/len(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(data_frame):\n",
    "    df_copy = data_frame.copy()\n",
    "    df_copy['AgeModulo'] = df_copy['Age'] % 5\n",
    "    df_copy['IsBasy'] = df_copy['Age'] < 2\n",
    "    df_copy['IsYoungChildren'] = df_copy['Age'] < 7\n",
    "    df_copy['IsChildren'] = df_copy['Age'] < 12\n",
    "    df_copy['IsAdolescent'] = df_copy['Age'] < 18\n",
    "    df_copy['IsOld'] = df_copy['Age'] > 60\n",
    "    df_copy['FareModulo'] = df_copy['Fare'] % 5\n",
    "    df_copy['IsInCabin'] = pd.isnull(df_copy['Cabin']).apply(lambda x : not x)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>AgeModulo</th>\n",
       "      <th>IsBasy</th>\n",
       "      <th>IsYoungChildren</th>\n",
       "      <th>IsChildren</th>\n",
       "      <th>IsAdolescent</th>\n",
       "      <th>IsOld</th>\n",
       "      <th>FareModulo</th>\n",
       "      <th>IsInCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>51.0</td>\n",
       "      <td>D11</td>\n",
       "      <td>S</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>Hogeboom, Mrs. John C (Anna Andrews)</td>\n",
       "      <td>0</td>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.9583</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Butler, Mr. Reginald Fenton</td>\n",
       "      <td>0</td>\n",
       "      <td>667</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>Vande Walle, Mr. Nestor Cyriel</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345770</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.0</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Navratil, Master. Edmond Roger</td>\n",
       "      <td>1</td>\n",
       "      <td>341</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112053</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0458</td>\n",
       "      <td>Braund, Mr. Lewis Richard</td>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3460</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>44.0</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Minahan, Dr. William Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19928</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>Meyer, Mrs. Edgar Joseph (Leila Saks)</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.1708</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Beane, Mrs. Edward (Ethel Clarke)</td>\n",
       "      <td>0</td>\n",
       "      <td>547</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>23.0</td>\n",
       "      <td>D36</td>\n",
       "      <td>C</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>Newell, Miss. Marjorie</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35273</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.2750</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>Uruchurtu, Don. Manuel E</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>17.4000</td>\n",
       "      <td>de Messemaeker, Mrs. Guillaume Joseph (Emma)</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>345572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Gustafsson, Mr. Karl Gideon</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>Mallet, Master. Andre</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S.C./PARIS 2079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>0</td>\n",
       "      <td>867</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.8583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>65.0</td>\n",
       "      <td>E38</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Millet, Mr. Francis Davis</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347742</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>55.0</td>\n",
       "      <td>C30</td>\n",
       "      <td>S</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>Molson, Mr. Harry Markland</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>Ryan, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>518</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.1500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Leeni, Mr. Fahim (\"Philip Zenni\")</td>\n",
       "      <td>0</td>\n",
       "      <td>554</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.2250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Horgan, Mr. John</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>Cleaver, Miss. Alice</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>54.0</td>\n",
       "      <td>D26</td>\n",
       "      <td>S</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>White, Mr. Percival Wayland</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35281</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Gavey, Mr. Lawrence</td>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>Andersson, Mrs. Anders Johan (Alfrida Konstant...</td>\n",
       "      <td>5</td>\n",
       "      <td>611</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>36.5</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Navratil, Mr. Michel (\"Louis M Hoffman\")</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230080</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>Hassan, Mr. Houssein G N</td>\n",
       "      <td>0</td>\n",
       "      <td>732</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.7875</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>Dean, Master. Bertram Vere</td>\n",
       "      <td>2</td>\n",
       "      <td>789</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C.A. 2315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Canavan, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>1</td>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>349909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>23.0</td>\n",
       "      <td>B24</td>\n",
       "      <td>S</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>Payne, Mr. Vivian Ponsonby</td>\n",
       "      <td>0</td>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12749</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>51.0</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>Lines, Mrs. Ernest H (Elizabeth Lindsey James)</td>\n",
       "      <td>1</td>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.4000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>Abbott, Master. Eugene Joseph</td>\n",
       "      <td>2</td>\n",
       "      <td>1284</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 2673</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Gilbert, Mr. William</td>\n",
       "      <td>0</td>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 30769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>Kink-Heilmann, Mr. Anton</td>\n",
       "      <td>1</td>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315153</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>18.0</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>Smith, Mrs. Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>0</td>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Colbert, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1288</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371109</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>48.0</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13567</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Larsson-Rondberg, Mr. Edvard A</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347065</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Conlon, Mr. Thomas Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>Bonnell, Miss. Caroline</td>\n",
       "      <td>0</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.8667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>Gale, Mr. Harry</td>\n",
       "      <td>0</td>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28664</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>1</td>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.4000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>Carrau, Mr. Jose Pedro</td>\n",
       "      <td>0</td>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>43.0</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>Frauenthal, Mr. Isaac Gerald</td>\n",
       "      <td>0</td>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7208</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>20.0</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>Nourney, Mr. Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.8625</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Ware, Mr. William Jeffery</td>\n",
       "      <td>0</td>\n",
       "      <td>1298</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28666</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>50.0</td>\n",
       "      <td>C80</td>\n",
       "      <td>C</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>Widener, Mr. George Dunton</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Naughton, Miss. Hannah</td>\n",
       "      <td>0</td>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>37.0</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td>\n",
       "      <td>0</td>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19928</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
       "      <td>0</td>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347086</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>39.0</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>0</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.9000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>38.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>1</td>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Cabin Embarked      Fare  \\\n",
       "765  51.0   D11        S   77.9583   \n",
       "666  25.0   NaN        S   13.0000   \n",
       "200  28.0   NaN        S    9.5000   \n",
       "271  25.0   NaN        S    0.0000   \n",
       "340   2.0    F2        S   26.0000   \n",
       "887  19.0   B42        S   30.0000   \n",
       "477  29.0   NaN        S    7.0458   \n",
       "245  44.0   C78        Q   90.0000   \n",
       "375   NaN   NaN        C   82.1708   \n",
       "863   NaN   NaN        S   69.5500   \n",
       "546  19.0   NaN        S   26.0000   \n",
       "393  23.0   D36        C  113.2750   \n",
       "30   40.0   NaN        C   27.7208   \n",
       "559  36.0   NaN        S   17.4000   \n",
       "379  19.0   NaN        S    7.7750   \n",
       "827   1.0   NaN        C   37.0042   \n",
       "866  27.0   NaN        C   13.8583   \n",
       "456  65.0   E38        S   26.5500   \n",
       "869   4.0   NaN        S   11.1333   \n",
       "492  55.0   C30        S   30.5000   \n",
       "517   NaN   NaN        Q   24.1500   \n",
       "553  22.0   NaN        C    7.2250   \n",
       "613   NaN   NaN        Q    7.7500   \n",
       "708  22.0   NaN        S  151.5500   \n",
       "124  54.0   D26        S   77.2875   \n",
       "619  26.0   NaN        S   10.5000   \n",
       "610  39.0   NaN        S   31.2750   \n",
       "148  36.5    F2        S   26.0000   \n",
       "731  11.0   NaN        C   18.7875   \n",
       "788   1.0   NaN        S   20.5750   \n",
       "..    ...   ...      ...       ...   \n",
       "388  21.0   NaN        Q    7.7500   \n",
       "389   6.0   NaN        S   21.0750   \n",
       "390  23.0   B24        S   93.5000   \n",
       "391  51.0   D28        S   39.4000   \n",
       "392  13.0   NaN        S   20.2500   \n",
       "393  47.0   NaN        S   10.5000   \n",
       "394  29.0   NaN        S   22.0250   \n",
       "395  18.0   C31        S   60.0000   \n",
       "396  24.0   NaN        Q    7.2500   \n",
       "397  48.0   B41        C   79.2000   \n",
       "398  22.0   NaN        S    7.7750   \n",
       "399  31.0   NaN        Q    7.7333   \n",
       "400  30.0    C7        S  164.8667   \n",
       "401  38.0   NaN        S   21.0000   \n",
       "402  22.0   NaN        C   59.4000   \n",
       "403  17.0   NaN        S   47.1000   \n",
       "404  43.0   D40        C   27.7208   \n",
       "405  20.0   D38        C   13.8625   \n",
       "406  23.0   NaN        S   10.5000   \n",
       "407  50.0   C80        C  211.5000   \n",
       "408   NaN   NaN        Q    7.7208   \n",
       "409   3.0   NaN        S   13.7750   \n",
       "410   NaN   NaN        Q    7.7500   \n",
       "411  37.0   C78        Q   90.0000   \n",
       "412  28.0   NaN        S    7.7750   \n",
       "413   NaN   NaN        S    8.0500   \n",
       "414  39.0  C105        C  108.9000   \n",
       "415  38.5   NaN        S    7.2500   \n",
       "416   NaN   NaN        S    8.0500   \n",
       "417   NaN   NaN        C   22.3583   \n",
       "\n",
       "                                                  Name  Parch  PassengerId  \\\n",
       "765               Hogeboom, Mrs. John C (Anna Andrews)      0          766   \n",
       "666                        Butler, Mr. Reginald Fenton      0          667   \n",
       "200                     Vande Walle, Mr. Nestor Cyriel      0          201   \n",
       "271                       Tornquist, Mr. William Henry      0          272   \n",
       "340                     Navratil, Master. Edmond Roger      1          341   \n",
       "887                       Graham, Miss. Margaret Edith      0          888   \n",
       "477                          Braund, Mr. Lewis Richard      0          478   \n",
       "245                        Minahan, Dr. William Edward      0          246   \n",
       "375              Meyer, Mrs. Edgar Joseph (Leila Saks)      0          376   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"      2          864   \n",
       "546                  Beane, Mrs. Edward (Ethel Clarke)      0          547   \n",
       "393                             Newell, Miss. Marjorie      0          394   \n",
       "30                            Uruchurtu, Don. Manuel E      0           31   \n",
       "559       de Messemaeker, Mrs. Guillaume Joseph (Emma)      0          560   \n",
       "379                        Gustafsson, Mr. Karl Gideon      0          380   \n",
       "827                              Mallet, Master. Andre      2          828   \n",
       "866                       Duran y More, Miss. Asuncion      0          867   \n",
       "456                          Millet, Mr. Francis Davis      0          457   \n",
       "869                    Johnson, Master. Harold Theodor      1          870   \n",
       "492                         Molson, Mr. Harry Markland      0          493   \n",
       "517                                  Ryan, Mr. Patrick      0          518   \n",
       "553                  Leeni, Mr. Fahim (\"Philip Zenni\")      0          554   \n",
       "613                                   Horgan, Mr. John      0          614   \n",
       "708                               Cleaver, Miss. Alice      0          709   \n",
       "124                        White, Mr. Percival Wayland      1          125   \n",
       "619                                Gavey, Mr. Lawrence      0          620   \n",
       "610  Andersson, Mrs. Anders Johan (Alfrida Konstant...      5          611   \n",
       "148           Navratil, Mr. Michel (\"Louis M Hoffman\")      2          149   \n",
       "731                           Hassan, Mr. Houssein G N      0          732   \n",
       "788                         Dean, Master. Bertram Vere      2          789   \n",
       "..                                                 ...    ...          ...   \n",
       "388                               Canavan, Mr. Patrick      0         1280   \n",
       "389                        Palsson, Master. Paul Folke      1         1281   \n",
       "390                         Payne, Mr. Vivian Ponsonby      0         1282   \n",
       "391     Lines, Mrs. Ernest H (Elizabeth Lindsey James)      1         1283   \n",
       "392                      Abbott, Master. Eugene Joseph      2         1284   \n",
       "393                               Gilbert, Mr. William      0         1285   \n",
       "394                           Kink-Heilmann, Mr. Anton      1         1286   \n",
       "395     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)      0         1287   \n",
       "396                               Colbert, Mr. Patrick      0         1288   \n",
       "397  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...      1         1289   \n",
       "398                     Larsson-Rondberg, Mr. Edvard A      0         1290   \n",
       "399                           Conlon, Mr. Thomas Henry      0         1291   \n",
       "400                            Bonnell, Miss. Caroline      0         1292   \n",
       "401                                    Gale, Mr. Harry      0         1293   \n",
       "402                     Gibson, Miss. Dorothy Winifred      1         1294   \n",
       "403                             Carrau, Mr. Jose Pedro      0         1295   \n",
       "404                       Frauenthal, Mr. Isaac Gerald      0         1296   \n",
       "405       Nourney, Mr. Alfred (Baron von Drachstedt\")\"      0         1297   \n",
       "406                          Ware, Mr. William Jeffery      0         1298   \n",
       "407                         Widener, Mr. George Dunton      1         1299   \n",
       "408                    Riordan, Miss. Johanna Hannah\"\"      0         1300   \n",
       "409                          Peacock, Miss. Treasteall      1         1301   \n",
       "410                             Naughton, Miss. Hannah      0         1302   \n",
       "411    Minahan, Mrs. William Edward (Lillian E Thorpe)      0         1303   \n",
       "412                     Henriksson, Miss. Jenny Lovisa      0         1304   \n",
       "413                                 Spector, Mr. Woolf      0         1305   \n",
       "414                       Oliva y Ocana, Dona. Fermina      0         1306   \n",
       "415                       Saether, Mr. Simon Sivertsen      0         1307   \n",
       "416                                Ware, Mr. Frederick      0         1308   \n",
       "417                           Peter, Master. Michael J      1         1309   \n",
       "\n",
       "     Pclass     Sex  SibSp  Survived              Ticket  AgeModulo  IsBasy  \\\n",
       "765       1  female      1       1.0               13502        1.0   False   \n",
       "666       2    male      0       0.0              234686        0.0   False   \n",
       "200       3    male      0       0.0              345770        3.0   False   \n",
       "271       3    male      0       1.0                LINE        0.0   False   \n",
       "340       2    male      1       1.0              230080        2.0   False   \n",
       "887       1  female      0       1.0              112053        4.0   False   \n",
       "477       3    male      1       0.0                3460        4.0   False   \n",
       "245       1    male      2       0.0               19928        4.0   False   \n",
       "375       1  female      1       1.0            PC 17604        NaN   False   \n",
       "863       3  female      8       0.0            CA. 2343        NaN   False   \n",
       "546       2  female      1       1.0                2908        4.0   False   \n",
       "393       1  female      1       1.0               35273        3.0   False   \n",
       "30        1    male      0       0.0            PC 17601        0.0   False   \n",
       "559       3  female      1       1.0              345572        1.0   False   \n",
       "379       3    male      0       0.0              347069        4.0   False   \n",
       "827       2    male      0       1.0     S.C./PARIS 2079        1.0    True   \n",
       "866       2  female      1       1.0       SC/PARIS 2149        2.0   False   \n",
       "456       1    male      0       0.0               13509        0.0   False   \n",
       "869       3    male      1       1.0              347742        4.0   False   \n",
       "492       1    male      0       0.0              113787        0.0   False   \n",
       "517       3    male      0       0.0              371110        NaN   False   \n",
       "553       3    male      0       1.0                2620        2.0   False   \n",
       "613       3    male      0       0.0              370377        NaN   False   \n",
       "708       1  female      0       1.0              113781        2.0   False   \n",
       "124       1    male      0       0.0               35281        4.0   False   \n",
       "619       2    male      0       0.0               31028        1.0   False   \n",
       "610       3  female      1       0.0              347082        4.0   False   \n",
       "148       2    male      0       0.0              230080        1.5   False   \n",
       "731       3    male      0       0.0                2699        1.0   False   \n",
       "788       3    male      1       1.0           C.A. 2315        1.0    True   \n",
       "..      ...     ...    ...       ...                 ...        ...     ...   \n",
       "388       3    male      0       NaN              364858        1.0   False   \n",
       "389       3    male      3       NaN              349909        1.0   False   \n",
       "390       1    male      0       NaN               12749        3.0   False   \n",
       "391       1  female      0       NaN            PC 17592        1.0   False   \n",
       "392       3    male      0       NaN           C.A. 2673        3.0   False   \n",
       "393       2    male      0       NaN          C.A. 30769        2.0   False   \n",
       "394       3    male      3       NaN              315153        4.0   False   \n",
       "395       1  female      1       NaN               13695        3.0   False   \n",
       "396       3    male      0       NaN              371109        4.0   False   \n",
       "397       1  female      1       NaN               13567        3.0   False   \n",
       "398       3    male      0       NaN              347065        2.0   False   \n",
       "399       3    male      0       NaN               21332        1.0   False   \n",
       "400       1  female      0       NaN               36928        0.0   False   \n",
       "401       2    male      1       NaN               28664        3.0   False   \n",
       "402       1  female      0       NaN              112378        2.0   False   \n",
       "403       1    male      0       NaN              113059        2.0   False   \n",
       "404       1    male      1       NaN               17765        3.0   False   \n",
       "405       2    male      0       NaN       SC/PARIS 2166        0.0   False   \n",
       "406       2    male      1       NaN               28666        3.0   False   \n",
       "407       1    male      1       NaN              113503        0.0   False   \n",
       "408       3  female      0       NaN              334915        NaN   False   \n",
       "409       3  female      1       NaN  SOTON/O.Q. 3101315        3.0   False   \n",
       "410       3  female      0       NaN              365237        NaN   False   \n",
       "411       1  female      1       NaN               19928        2.0   False   \n",
       "412       3  female      0       NaN              347086        3.0   False   \n",
       "413       3    male      0       NaN           A.5. 3236        NaN   False   \n",
       "414       1  female      0       NaN            PC 17758        4.0   False   \n",
       "415       3    male      0       NaN  SOTON/O.Q. 3101262        3.5   False   \n",
       "416       3    male      0       NaN              359309        NaN   False   \n",
       "417       3    male      1       NaN                2668        NaN   False   \n",
       "\n",
       "     IsYoungChildren  IsChildren  IsAdolescent  IsOld  FareModulo  IsInCabin  \n",
       "765            False       False         False  False      2.9583       True  \n",
       "666            False       False         False  False      3.0000      False  \n",
       "200            False       False         False  False      4.5000      False  \n",
       "271            False       False         False  False      0.0000      False  \n",
       "340             True        True          True  False      1.0000       True  \n",
       "887            False       False         False  False      0.0000       True  \n",
       "477            False       False         False  False      2.0458      False  \n",
       "245            False       False         False  False      0.0000       True  \n",
       "375            False       False         False  False      2.1708      False  \n",
       "863            False       False         False  False      4.5500      False  \n",
       "546            False       False         False  False      1.0000      False  \n",
       "393            False       False         False  False      3.2750       True  \n",
       "30             False       False         False  False      2.7208      False  \n",
       "559            False       False         False  False      2.4000      False  \n",
       "379            False       False         False  False      2.7750      False  \n",
       "827             True        True          True  False      2.0042      False  \n",
       "866            False       False         False  False      3.8583      False  \n",
       "456            False       False         False   True      1.5500       True  \n",
       "869             True        True          True  False      1.1333      False  \n",
       "492            False       False         False  False      0.5000       True  \n",
       "517            False       False         False  False      4.1500      False  \n",
       "553            False       False         False  False      2.2250      False  \n",
       "613            False       False         False  False      2.7500      False  \n",
       "708            False       False         False  False      1.5500      False  \n",
       "124            False       False         False  False      2.2875       True  \n",
       "619            False       False         False  False      0.5000      False  \n",
       "610            False       False         False  False      1.2750      False  \n",
       "148            False       False         False  False      1.0000       True  \n",
       "731            False        True          True  False      3.7875      False  \n",
       "788             True        True          True  False      0.5750      False  \n",
       "..               ...         ...           ...    ...         ...        ...  \n",
       "388            False       False         False  False      2.7500      False  \n",
       "389             True        True          True  False      1.0750      False  \n",
       "390            False       False         False  False      3.5000       True  \n",
       "391            False       False         False  False      4.4000       True  \n",
       "392            False       False          True  False      0.2500      False  \n",
       "393            False       False         False  False      0.5000      False  \n",
       "394            False       False         False  False      2.0250      False  \n",
       "395            False       False         False  False      0.0000       True  \n",
       "396            False       False         False  False      2.2500      False  \n",
       "397            False       False         False  False      4.2000       True  \n",
       "398            False       False         False  False      2.7750      False  \n",
       "399            False       False         False  False      2.7333      False  \n",
       "400            False       False         False  False      4.8667       True  \n",
       "401            False       False         False  False      1.0000      False  \n",
       "402            False       False         False  False      4.4000      False  \n",
       "403            False       False          True  False      2.1000      False  \n",
       "404            False       False         False  False      2.7208       True  \n",
       "405            False       False         False  False      3.8625       True  \n",
       "406            False       False         False  False      0.5000      False  \n",
       "407            False       False         False  False      1.5000       True  \n",
       "408            False       False         False  False      2.7208      False  \n",
       "409             True        True          True  False      3.7750      False  \n",
       "410            False       False         False  False      2.7500      False  \n",
       "411            False       False         False  False      0.0000       True  \n",
       "412            False       False         False  False      2.7750      False  \n",
       "413            False       False         False  False      3.0500      False  \n",
       "414            False       False         False  False      3.9000       True  \n",
       "415            False       False         False  False      2.2500      False  \n",
       "416            False       False         False  False      3.0500      False  \n",
       "417            False       False         False  False      2.3583      False  \n",
       "\n",
       "[1309 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_engineering(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL = ['Survived']\n",
    "ID = ['PassenderId']\n",
    "FEATURES = ['Pclass', 'Sex', 'AgeModulo', 'SibSp', 'Parch', 'Embarked', 'FareModulo', \n",
    "            'IsBasy', 'IsYoungChildren', 'IsChildren', 'IsAdolescent', 'IsOld',\n",
    "           'IsInCabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to categorical\n",
    "df[LABEL] = df[LABEL].astype(str)\n",
    "df[FEATURES] = df[FEATURES].astype(str)\n",
    "df_one_hot = pd.get_dummies(df[FEATURES], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_one_hot_train = df_one_hot[0:len(df_train.index)]\n",
    "df_one_hot_test = df_one_hot[len(df_train.index):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    dropout_rate = 0\n",
    "    hidden_size = 64\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hidden_size, activation='relu', input_dim=len(df_one_hot.columns)))\n",
    "    model.add(Dropout(dropout_rate, noise_shape=None, seed=None))\n",
    "    model.add(Dense(units=hidden_size, activation='tanh', input_dim=hidden_size))\n",
    "    model.add(Dropout(dropout_rate, noise_shape=None, seed=None))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.00001, decay=1e-7),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 937us/step - loss: 0.6676 - acc: 0.6117 - val_loss: 0.6611 - val_acc: 0.6778\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6648 - acc: 0.6130 - val_loss: 0.6581 - val_acc: 0.6556\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6622 - acc: 0.6105 - val_loss: 0.6549 - val_acc: 0.6444\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6596 - acc: 0.6192 - val_loss: 0.6519 - val_acc: 0.6444\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6572 - acc: 0.6192 - val_loss: 0.6490 - val_acc: 0.6333\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6548 - acc: 0.6205 - val_loss: 0.6464 - val_acc: 0.6333\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.6527 - acc: 0.6205 - val_loss: 0.6439 - val_acc: 0.6333\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.6509 - acc: 0.6230 - val_loss: 0.6419 - val_acc: 0.6333\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6489 - acc: 0.6230 - val_loss: 0.6394 - val_acc: 0.6333\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6468 - acc: 0.6267 - val_loss: 0.6370 - val_acc: 0.6333\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6449 - acc: 0.6305 - val_loss: 0.6350 - val_acc: 0.6333\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6430 - acc: 0.6305 - val_loss: 0.6327 - val_acc: 0.6333\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6413 - acc: 0.6317 - val_loss: 0.6309 - val_acc: 0.6444\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.6396 - acc: 0.6330 - val_loss: 0.6291 - val_acc: 0.6556\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6378 - acc: 0.6355 - val_loss: 0.6270 - val_acc: 0.6556\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6361 - acc: 0.6355 - val_loss: 0.6253 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6343 - acc: 0.6367 - val_loss: 0.6233 - val_acc: 0.6556\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6324 - acc: 0.6367 - val_loss: 0.6211 - val_acc: 0.6556\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6307 - acc: 0.6367 - val_loss: 0.6190 - val_acc: 0.6556\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6291 - acc: 0.6392 - val_loss: 0.6172 - val_acc: 0.6556\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6276 - acc: 0.6392 - val_loss: 0.6157 - val_acc: 0.6778\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6260 - acc: 0.6429 - val_loss: 0.6137 - val_acc: 0.6778\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6243 - acc: 0.6429 - val_loss: 0.6117 - val_acc: 0.6778\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 73us/step - loss: 0.6225 - acc: 0.6429 - val_loss: 0.6096 - val_acc: 0.6778\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6209 - acc: 0.6442 - val_loss: 0.6081 - val_acc: 0.6778\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6193 - acc: 0.6479 - val_loss: 0.6064 - val_acc: 0.6778\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6178 - acc: 0.6492 - val_loss: 0.6049 - val_acc: 0.6778\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6163 - acc: 0.6529 - val_loss: 0.6030 - val_acc: 0.6778\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6146 - acc: 0.6604 - val_loss: 0.6013 - val_acc: 0.6778\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 71us/step - loss: 0.6130 - acc: 0.6629 - val_loss: 0.5993 - val_acc: 0.6778\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6114 - acc: 0.6617 - val_loss: 0.5975 - val_acc: 0.6778\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6099 - acc: 0.6667 - val_loss: 0.5959 - val_acc: 0.6778\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6083 - acc: 0.6717 - val_loss: 0.5944 - val_acc: 0.6778\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6068 - acc: 0.6717 - val_loss: 0.5926 - val_acc: 0.6778\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6053 - acc: 0.6717 - val_loss: 0.5907 - val_acc: 0.6778\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6037 - acc: 0.6717 - val_loss: 0.5890 - val_acc: 0.6889\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6021 - acc: 0.6754 - val_loss: 0.5870 - val_acc: 0.6889\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6004 - acc: 0.6754 - val_loss: 0.5852 - val_acc: 0.6889\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5988 - acc: 0.6767 - val_loss: 0.5836 - val_acc: 0.6889\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5974 - acc: 0.6792 - val_loss: 0.5820 - val_acc: 0.6889\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5961 - acc: 0.6804 - val_loss: 0.5808 - val_acc: 0.6889\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5950 - acc: 0.6804 - val_loss: 0.5795 - val_acc: 0.6889\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5935 - acc: 0.6816 - val_loss: 0.5778 - val_acc: 0.6889\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5919 - acc: 0.6841 - val_loss: 0.5760 - val_acc: 0.7000\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5904 - acc: 0.6841 - val_loss: 0.5743 - val_acc: 0.7000\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5889 - acc: 0.6866 - val_loss: 0.5728 - val_acc: 0.7000\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5873 - acc: 0.6866 - val_loss: 0.5711 - val_acc: 0.7000\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5858 - acc: 0.6904 - val_loss: 0.5693 - val_acc: 0.7111\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5842 - acc: 0.7029 - val_loss: 0.5675 - val_acc: 0.7000\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5827 - acc: 0.7066 - val_loss: 0.5660 - val_acc: 0.7000\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5812 - acc: 0.7116 - val_loss: 0.5642 - val_acc: 0.7000\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5797 - acc: 0.7166 - val_loss: 0.5629 - val_acc: 0.7000\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5782 - acc: 0.7179 - val_loss: 0.5611 - val_acc: 0.7000\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5768 - acc: 0.7179 - val_loss: 0.5594 - val_acc: 0.7000\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5752 - acc: 0.7228 - val_loss: 0.5578 - val_acc: 0.7111\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5737 - acc: 0.7278 - val_loss: 0.5561 - val_acc: 0.7222\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5723 - acc: 0.7278 - val_loss: 0.5544 - val_acc: 0.7222\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5708 - acc: 0.7303 - val_loss: 0.5526 - val_acc: 0.7222\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5693 - acc: 0.7353 - val_loss: 0.5508 - val_acc: 0.7222\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5676 - acc: 0.7341 - val_loss: 0.5492 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5662 - acc: 0.7378 - val_loss: 0.5476 - val_acc: 0.7222\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5647 - acc: 0.7378 - val_loss: 0.5459 - val_acc: 0.7222\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5632 - acc: 0.7391 - val_loss: 0.5443 - val_acc: 0.7222\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5617 - acc: 0.7428 - val_loss: 0.5426 - val_acc: 0.7222\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5602 - acc: 0.7441 - val_loss: 0.5409 - val_acc: 0.7222\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5586 - acc: 0.7453 - val_loss: 0.5392 - val_acc: 0.7222\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5571 - acc: 0.7453 - val_loss: 0.5375 - val_acc: 0.7222\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5556 - acc: 0.7478 - val_loss: 0.5361 - val_acc: 0.7333\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5541 - acc: 0.7503 - val_loss: 0.5345 - val_acc: 0.7333\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5526 - acc: 0.7528 - val_loss: 0.5327 - val_acc: 0.7333\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5511 - acc: 0.7553 - val_loss: 0.5311 - val_acc: 0.7333\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5497 - acc: 0.7578 - val_loss: 0.5297 - val_acc: 0.7444\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5483 - acc: 0.7603 - val_loss: 0.5281 - val_acc: 0.7444\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5468 - acc: 0.7615 - val_loss: 0.5265 - val_acc: 0.7444\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5453 - acc: 0.7628 - val_loss: 0.5248 - val_acc: 0.7444\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5439 - acc: 0.7640 - val_loss: 0.5231 - val_acc: 0.7444\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5424 - acc: 0.7665 - val_loss: 0.5215 - val_acc: 0.7444\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5410 - acc: 0.7703 - val_loss: 0.5200 - val_acc: 0.7444\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5396 - acc: 0.7715 - val_loss: 0.5185 - val_acc: 0.7444\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5380 - acc: 0.7715 - val_loss: 0.5169 - val_acc: 0.7556\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5365 - acc: 0.7715 - val_loss: 0.5153 - val_acc: 0.7889\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5350 - acc: 0.7765 - val_loss: 0.5136 - val_acc: 0.7889\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5335 - acc: 0.7765 - val_loss: 0.5120 - val_acc: 0.7889\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5320 - acc: 0.7803 - val_loss: 0.5104 - val_acc: 0.7889\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5306 - acc: 0.7790 - val_loss: 0.5087 - val_acc: 0.7889\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5290 - acc: 0.7790 - val_loss: 0.5071 - val_acc: 0.7889\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5275 - acc: 0.7828 - val_loss: 0.5054 - val_acc: 0.7889\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5261 - acc: 0.7828 - val_loss: 0.5038 - val_acc: 0.7889\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5246 - acc: 0.7815 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5231 - acc: 0.7828 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5219 - acc: 0.7828 - val_loss: 0.4991 - val_acc: 0.8000\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5205 - acc: 0.7828 - val_loss: 0.4976 - val_acc: 0.8000\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5191 - acc: 0.7840 - val_loss: 0.4962 - val_acc: 0.8000\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5175 - acc: 0.7865 - val_loss: 0.4947 - val_acc: 0.8000\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5161 - acc: 0.7878 - val_loss: 0.4930 - val_acc: 0.8000\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5146 - acc: 0.7878 - val_loss: 0.4915 - val_acc: 0.8000\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5132 - acc: 0.7890 - val_loss: 0.4899 - val_acc: 0.8000\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 75us/step - loss: 0.5118 - acc: 0.7890 - val_loss: 0.4884 - val_acc: 0.8111\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.5105 - acc: 0.7890 - val_loss: 0.4873 - val_acc: 0.8111\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5091 - acc: 0.7903 - val_loss: 0.4859 - val_acc: 0.8111\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5077 - acc: 0.7940 - val_loss: 0.4846 - val_acc: 0.8111\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5063 - acc: 0.7978 - val_loss: 0.4832 - val_acc: 0.8111\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5051 - acc: 0.7990 - val_loss: 0.4817 - val_acc: 0.8111\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5038 - acc: 0.7990 - val_loss: 0.4803 - val_acc: 0.8111\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5025 - acc: 0.8002 - val_loss: 0.4789 - val_acc: 0.8444\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5012 - acc: 0.8002 - val_loss: 0.4774 - val_acc: 0.8444\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.4999 - acc: 0.8002 - val_loss: 0.4759 - val_acc: 0.8444\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4986 - acc: 0.8027 - val_loss: 0.4745 - val_acc: 0.8444\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4975 - acc: 0.8002 - val_loss: 0.4737 - val_acc: 0.8556\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4964 - acc: 0.8015 - val_loss: 0.4724 - val_acc: 0.8556\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4952 - acc: 0.8027 - val_loss: 0.4711 - val_acc: 0.8556\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4939 - acc: 0.8077 - val_loss: 0.4698 - val_acc: 0.8556\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4927 - acc: 0.8090 - val_loss: 0.4684 - val_acc: 0.8556\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4915 - acc: 0.8090 - val_loss: 0.4672 - val_acc: 0.8556\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4903 - acc: 0.8102 - val_loss: 0.4659 - val_acc: 0.8444\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4891 - acc: 0.8115 - val_loss: 0.4649 - val_acc: 0.8444\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.4880 - acc: 0.8127 - val_loss: 0.4637 - val_acc: 0.8444\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4868 - acc: 0.8127 - val_loss: 0.4624 - val_acc: 0.8444\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4857 - acc: 0.8115 - val_loss: 0.4612 - val_acc: 0.8444\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4846 - acc: 0.8115 - val_loss: 0.4601 - val_acc: 0.8444\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 60us/step - loss: 0.4836 - acc: 0.8115 - val_loss: 0.4589 - val_acc: 0.8444\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4825 - acc: 0.8115 - val_loss: 0.4576 - val_acc: 0.8444\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4813 - acc: 0.8115 - val_loss: 0.4564 - val_acc: 0.8444\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4802 - acc: 0.8102 - val_loss: 0.4553 - val_acc: 0.8444\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4791 - acc: 0.8102 - val_loss: 0.4540 - val_acc: 0.8444\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4779 - acc: 0.8115 - val_loss: 0.4529 - val_acc: 0.8444\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4769 - acc: 0.8140 - val_loss: 0.4518 - val_acc: 0.8444\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4758 - acc: 0.8140 - val_loss: 0.4507 - val_acc: 0.8444\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4747 - acc: 0.8140 - val_loss: 0.4497 - val_acc: 0.8444\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4737 - acc: 0.8152 - val_loss: 0.4487 - val_acc: 0.8444\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4727 - acc: 0.8165 - val_loss: 0.4477 - val_acc: 0.8444\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4718 - acc: 0.8177 - val_loss: 0.4472 - val_acc: 0.8444\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4708 - acc: 0.8190 - val_loss: 0.4461 - val_acc: 0.8444\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4698 - acc: 0.8202 - val_loss: 0.4449 - val_acc: 0.8444\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4688 - acc: 0.8215 - val_loss: 0.4439 - val_acc: 0.8444\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4679 - acc: 0.8265 - val_loss: 0.4430 - val_acc: 0.8444\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4668 - acc: 0.8277 - val_loss: 0.4420 - val_acc: 0.8444\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4659 - acc: 0.8277 - val_loss: 0.4409 - val_acc: 0.8444\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4649 - acc: 0.8277 - val_loss: 0.4398 - val_acc: 0.8444\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4639 - acc: 0.8277 - val_loss: 0.4389 - val_acc: 0.8444\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4630 - acc: 0.8327 - val_loss: 0.4380 - val_acc: 0.8444\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4621 - acc: 0.8315 - val_loss: 0.4373 - val_acc: 0.8444\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4611 - acc: 0.8327 - val_loss: 0.4365 - val_acc: 0.8444\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4602 - acc: 0.8327 - val_loss: 0.4354 - val_acc: 0.8444\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4593 - acc: 0.8315 - val_loss: 0.4344 - val_acc: 0.8444\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4584 - acc: 0.8327 - val_loss: 0.4336 - val_acc: 0.8444\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4575 - acc: 0.8377 - val_loss: 0.4330 - val_acc: 0.8667\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4566 - acc: 0.8390 - val_loss: 0.4321 - val_acc: 0.8556\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4557 - acc: 0.8377 - val_loss: 0.4311 - val_acc: 0.8556\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4549 - acc: 0.8390 - val_loss: 0.4300 - val_acc: 0.8667\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4541 - acc: 0.8402 - val_loss: 0.4290 - val_acc: 0.8667\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4532 - acc: 0.8402 - val_loss: 0.4282 - val_acc: 0.8667\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4523 - acc: 0.8402 - val_loss: 0.4272 - val_acc: 0.8667\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4514 - acc: 0.8414 - val_loss: 0.4265 - val_acc: 0.8556\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4506 - acc: 0.8402 - val_loss: 0.4257 - val_acc: 0.8556\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4499 - acc: 0.8402 - val_loss: 0.4248 - val_acc: 0.8556\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4490 - acc: 0.8414 - val_loss: 0.4242 - val_acc: 0.8556\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4482 - acc: 0.8414 - val_loss: 0.4234 - val_acc: 0.8556\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4475 - acc: 0.8414 - val_loss: 0.4228 - val_acc: 0.8667\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4467 - acc: 0.8402 - val_loss: 0.4225 - val_acc: 0.8667\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4461 - acc: 0.8390 - val_loss: 0.4225 - val_acc: 0.8667\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4455 - acc: 0.8414 - val_loss: 0.4220 - val_acc: 0.8667\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4448 - acc: 0.8427 - val_loss: 0.4212 - val_acc: 0.8667\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4441 - acc: 0.8427 - val_loss: 0.4202 - val_acc: 0.8667\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4434 - acc: 0.8402 - val_loss: 0.4193 - val_acc: 0.8667\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4427 - acc: 0.8402 - val_loss: 0.4186 - val_acc: 0.8667\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4420 - acc: 0.8402 - val_loss: 0.4179 - val_acc: 0.8667\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4414 - acc: 0.8402 - val_loss: 0.4171 - val_acc: 0.8667\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4407 - acc: 0.8402 - val_loss: 0.4163 - val_acc: 0.8667\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4400 - acc: 0.8402 - val_loss: 0.4158 - val_acc: 0.8667\n",
      "Epoch 171/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4393 - acc: 0.8402 - val_loss: 0.4151 - val_acc: 0.8667\n",
      "Epoch 172/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4387 - acc: 0.8414 - val_loss: 0.4144 - val_acc: 0.8667\n",
      "Epoch 173/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4380 - acc: 0.8427 - val_loss: 0.4137 - val_acc: 0.8667\n",
      "Epoch 174/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4373 - acc: 0.8439 - val_loss: 0.4134 - val_acc: 0.8667\n",
      "Epoch 175/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4366 - acc: 0.8439 - val_loss: 0.4127 - val_acc: 0.8667\n",
      "Epoch 176/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4360 - acc: 0.8439 - val_loss: 0.4122 - val_acc: 0.8667\n",
      "Epoch 177/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4353 - acc: 0.8452 - val_loss: 0.4119 - val_acc: 0.8556\n",
      "Epoch 178/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4347 - acc: 0.8439 - val_loss: 0.4115 - val_acc: 0.8444\n",
      "Epoch 179/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4343 - acc: 0.8464 - val_loss: 0.4115 - val_acc: 0.8333\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 1s 954us/step - loss: 0.6611 - acc: 0.6367 - val_loss: 0.6403 - val_acc: 0.6778\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6580 - acc: 0.6380 - val_loss: 0.6369 - val_acc: 0.6778\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6554 - acc: 0.6367 - val_loss: 0.6337 - val_acc: 0.6778\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6529 - acc: 0.6392 - val_loss: 0.6308 - val_acc: 0.6778\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6508 - acc: 0.6392 - val_loss: 0.6286 - val_acc: 0.6778\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6488 - acc: 0.6417 - val_loss: 0.6261 - val_acc: 0.6778\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6465 - acc: 0.6417 - val_loss: 0.6233 - val_acc: 0.6667\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6444 - acc: 0.6404 - val_loss: 0.6205 - val_acc: 0.6667\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6422 - acc: 0.6429 - val_loss: 0.6181 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6401 - acc: 0.6454 - val_loss: 0.6157 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6382 - acc: 0.6454 - val_loss: 0.6132 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6363 - acc: 0.6467 - val_loss: 0.6110 - val_acc: 0.6778\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6345 - acc: 0.6467 - val_loss: 0.6085 - val_acc: 0.6778\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6327 - acc: 0.6467 - val_loss: 0.6065 - val_acc: 0.6778\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6310 - acc: 0.6467 - val_loss: 0.6045 - val_acc: 0.6778\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6293 - acc: 0.6454 - val_loss: 0.6022 - val_acc: 0.6778\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6278 - acc: 0.6492 - val_loss: 0.6009 - val_acc: 0.6778\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6262 - acc: 0.6492 - val_loss: 0.5988 - val_acc: 0.6778\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6246 - acc: 0.6517 - val_loss: 0.5969 - val_acc: 0.6778\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6229 - acc: 0.6542 - val_loss: 0.5949 - val_acc: 0.6778\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6212 - acc: 0.6517 - val_loss: 0.5928 - val_acc: 0.6778\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6197 - acc: 0.6554 - val_loss: 0.5910 - val_acc: 0.6889\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6180 - acc: 0.6567 - val_loss: 0.5890 - val_acc: 0.6889\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6164 - acc: 0.6592 - val_loss: 0.5871 - val_acc: 0.6889\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6150 - acc: 0.6604 - val_loss: 0.5855 - val_acc: 0.6889\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6134 - acc: 0.6654 - val_loss: 0.5838 - val_acc: 0.7000\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6119 - acc: 0.6679 - val_loss: 0.5819 - val_acc: 0.7000\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6103 - acc: 0.6679 - val_loss: 0.5800 - val_acc: 0.7000\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6088 - acc: 0.6742 - val_loss: 0.5785 - val_acc: 0.7222\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6073 - acc: 0.6767 - val_loss: 0.5766 - val_acc: 0.7222\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6057 - acc: 0.6779 - val_loss: 0.5747 - val_acc: 0.7222\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6042 - acc: 0.6804 - val_loss: 0.5729 - val_acc: 0.7222\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6026 - acc: 0.6816 - val_loss: 0.5711 - val_acc: 0.7222\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6011 - acc: 0.6816 - val_loss: 0.5693 - val_acc: 0.7333\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5996 - acc: 0.6816 - val_loss: 0.5674 - val_acc: 0.7333\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5980 - acc: 0.6829 - val_loss: 0.5657 - val_acc: 0.7333\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5964 - acc: 0.6866 - val_loss: 0.5642 - val_acc: 0.7333\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5949 - acc: 0.6916 - val_loss: 0.5625 - val_acc: 0.7333\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5935 - acc: 0.6979 - val_loss: 0.5609 - val_acc: 0.7222\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5919 - acc: 0.7041 - val_loss: 0.5590 - val_acc: 0.7222\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5903 - acc: 0.7041 - val_loss: 0.5572 - val_acc: 0.7333\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5888 - acc: 0.7054 - val_loss: 0.5554 - val_acc: 0.7333\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5874 - acc: 0.7066 - val_loss: 0.5540 - val_acc: 0.7333\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5860 - acc: 0.7079 - val_loss: 0.5521 - val_acc: 0.7333\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5845 - acc: 0.7079 - val_loss: 0.5504 - val_acc: 0.7333\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5830 - acc: 0.7116 - val_loss: 0.5488 - val_acc: 0.7333\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5815 - acc: 0.7154 - val_loss: 0.5469 - val_acc: 0.7333\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5801 - acc: 0.7191 - val_loss: 0.5454 - val_acc: 0.7444\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5786 - acc: 0.7241 - val_loss: 0.5437 - val_acc: 0.7444\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5772 - acc: 0.7253 - val_loss: 0.5421 - val_acc: 0.7444\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5758 - acc: 0.7278 - val_loss: 0.5407 - val_acc: 0.7556\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5744 - acc: 0.7291 - val_loss: 0.5390 - val_acc: 0.7556\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5729 - acc: 0.7291 - val_loss: 0.5372 - val_acc: 0.7556\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5714 - acc: 0.7303 - val_loss: 0.5355 - val_acc: 0.7556\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5699 - acc: 0.7303 - val_loss: 0.5337 - val_acc: 0.7667\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.5684 - acc: 0.7303 - val_loss: 0.5320 - val_acc: 0.7667\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5670 - acc: 0.7316 - val_loss: 0.5303 - val_acc: 0.7667\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5655 - acc: 0.7328 - val_loss: 0.5286 - val_acc: 0.7667\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5640 - acc: 0.7366 - val_loss: 0.5269 - val_acc: 0.7667\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5625 - acc: 0.7416 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 61us/step - loss: 0.5609 - acc: 0.7416 - val_loss: 0.5235 - val_acc: 0.7778\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5595 - acc: 0.7466 - val_loss: 0.5218 - val_acc: 0.7778\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5581 - acc: 0.7503 - val_loss: 0.5203 - val_acc: 0.7778\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5567 - acc: 0.7503 - val_loss: 0.5188 - val_acc: 0.7778\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5552 - acc: 0.7528 - val_loss: 0.5175 - val_acc: 0.7889\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5538 - acc: 0.7541 - val_loss: 0.5158 - val_acc: 0.8000\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5523 - acc: 0.7578 - val_loss: 0.5143 - val_acc: 0.8000\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5508 - acc: 0.7615 - val_loss: 0.5130 - val_acc: 0.8111\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5494 - acc: 0.7640 - val_loss: 0.5114 - val_acc: 0.8111\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5480 - acc: 0.7640 - val_loss: 0.5099 - val_acc: 0.8111\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5467 - acc: 0.7628 - val_loss: 0.5083 - val_acc: 0.8111\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5452 - acc: 0.7653 - val_loss: 0.5069 - val_acc: 0.8111\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5439 - acc: 0.7653 - val_loss: 0.5057 - val_acc: 0.8111\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5425 - acc: 0.7653 - val_loss: 0.5042 - val_acc: 0.8111\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5410 - acc: 0.7653 - val_loss: 0.5025 - val_acc: 0.8111\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5396 - acc: 0.7665 - val_loss: 0.5008 - val_acc: 0.8111\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5383 - acc: 0.7665 - val_loss: 0.4993 - val_acc: 0.8111\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5369 - acc: 0.7690 - val_loss: 0.4978 - val_acc: 0.8111\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5358 - acc: 0.7703 - val_loss: 0.4962 - val_acc: 0.8111\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5343 - acc: 0.7715 - val_loss: 0.4948 - val_acc: 0.8111\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5329 - acc: 0.7715 - val_loss: 0.4934 - val_acc: 0.8111\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5316 - acc: 0.7740 - val_loss: 0.4922 - val_acc: 0.8111\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5303 - acc: 0.7753 - val_loss: 0.4906 - val_acc: 0.8111\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5290 - acc: 0.7765 - val_loss: 0.4891 - val_acc: 0.8111\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5278 - acc: 0.7765 - val_loss: 0.4877 - val_acc: 0.8111\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5266 - acc: 0.7778 - val_loss: 0.4866 - val_acc: 0.8333\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5253 - acc: 0.7778 - val_loss: 0.4852 - val_acc: 0.8333\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5241 - acc: 0.7778 - val_loss: 0.4843 - val_acc: 0.8333\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5229 - acc: 0.7765 - val_loss: 0.4828 - val_acc: 0.8333\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5216 - acc: 0.7778 - val_loss: 0.4814 - val_acc: 0.8333\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5203 - acc: 0.7815 - val_loss: 0.4799 - val_acc: 0.8333\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5191 - acc: 0.7815 - val_loss: 0.4784 - val_acc: 0.8333\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5178 - acc: 0.7853 - val_loss: 0.4770 - val_acc: 0.8333\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5165 - acc: 0.7903 - val_loss: 0.4758 - val_acc: 0.8222\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5151 - acc: 0.7865 - val_loss: 0.4747 - val_acc: 0.8222\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5139 - acc: 0.7865 - val_loss: 0.4734 - val_acc: 0.8222\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5127 - acc: 0.7865 - val_loss: 0.4722 - val_acc: 0.8222\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5115 - acc: 0.7878 - val_loss: 0.4707 - val_acc: 0.8222\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5103 - acc: 0.7903 - val_loss: 0.4693 - val_acc: 0.8222\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5092 - acc: 0.7890 - val_loss: 0.4680 - val_acc: 0.8222\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5081 - acc: 0.7903 - val_loss: 0.4667 - val_acc: 0.8222\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5069 - acc: 0.7928 - val_loss: 0.4654 - val_acc: 0.8222\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5057 - acc: 0.7953 - val_loss: 0.4640 - val_acc: 0.8222\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5044 - acc: 0.7965 - val_loss: 0.4629 - val_acc: 0.8222\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5035 - acc: 0.7990 - val_loss: 0.4625 - val_acc: 0.8222\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5023 - acc: 0.8015 - val_loss: 0.4613 - val_acc: 0.8222\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5013 - acc: 0.8015 - val_loss: 0.4606 - val_acc: 0.8222\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5002 - acc: 0.8027 - val_loss: 0.4598 - val_acc: 0.8111\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4991 - acc: 0.8027 - val_loss: 0.4586 - val_acc: 0.8000\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4980 - acc: 0.8040 - val_loss: 0.4572 - val_acc: 0.8000\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4969 - acc: 0.8040 - val_loss: 0.4560 - val_acc: 0.8000\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4958 - acc: 0.8027 - val_loss: 0.4548 - val_acc: 0.8111\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4948 - acc: 0.8027 - val_loss: 0.4535 - val_acc: 0.8111\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4936 - acc: 0.8040 - val_loss: 0.4524 - val_acc: 0.8111\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4926 - acc: 0.8040 - val_loss: 0.4513 - val_acc: 0.8111\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4916 - acc: 0.8027 - val_loss: 0.4501 - val_acc: 0.8222\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4905 - acc: 0.8052 - val_loss: 0.4493 - val_acc: 0.8111\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4894 - acc: 0.8090 - val_loss: 0.4482 - val_acc: 0.8111\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4884 - acc: 0.8090 - val_loss: 0.4472 - val_acc: 0.8222\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4873 - acc: 0.8115 - val_loss: 0.4463 - val_acc: 0.8222\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 57us/step - loss: 0.4862 - acc: 0.8115 - val_loss: 0.4453 - val_acc: 0.8111\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4853 - acc: 0.8102 - val_loss: 0.4444 - val_acc: 0.8222\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4843 - acc: 0.8115 - val_loss: 0.4434 - val_acc: 0.8111\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4833 - acc: 0.8127 - val_loss: 0.4422 - val_acc: 0.8111\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4825 - acc: 0.8102 - val_loss: 0.4419 - val_acc: 0.8111\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4816 - acc: 0.8127 - val_loss: 0.4408 - val_acc: 0.8111\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4808 - acc: 0.8127 - val_loss: 0.4397 - val_acc: 0.8111\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4799 - acc: 0.8115 - val_loss: 0.4389 - val_acc: 0.8222\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4789 - acc: 0.8115 - val_loss: 0.4378 - val_acc: 0.8222\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.4780 - acc: 0.8115 - val_loss: 0.4368 - val_acc: 0.8222\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4771 - acc: 0.8115 - val_loss: 0.4358 - val_acc: 0.8222\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4761 - acc: 0.8115 - val_loss: 0.4347 - val_acc: 0.8222\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4753 - acc: 0.8102 - val_loss: 0.4337 - val_acc: 0.8222\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4744 - acc: 0.8115 - val_loss: 0.4328 - val_acc: 0.8222\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4735 - acc: 0.8127 - val_loss: 0.4319 - val_acc: 0.8333\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.4727 - acc: 0.8152 - val_loss: 0.4311 - val_acc: 0.8222\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4718 - acc: 0.8152 - val_loss: 0.4305 - val_acc: 0.8222\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4709 - acc: 0.8165 - val_loss: 0.4295 - val_acc: 0.8222\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4701 - acc: 0.8177 - val_loss: 0.4286 - val_acc: 0.8222\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4692 - acc: 0.8152 - val_loss: 0.4283 - val_acc: 0.8222\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4685 - acc: 0.8152 - val_loss: 0.4274 - val_acc: 0.8222\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4677 - acc: 0.8152 - val_loss: 0.4267 - val_acc: 0.8222\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4669 - acc: 0.8165 - val_loss: 0.4257 - val_acc: 0.8222\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4660 - acc: 0.8140 - val_loss: 0.4252 - val_acc: 0.8333\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4652 - acc: 0.8140 - val_loss: 0.4242 - val_acc: 0.8333\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4644 - acc: 0.8165 - val_loss: 0.4232 - val_acc: 0.8333\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4637 - acc: 0.8177 - val_loss: 0.4225 - val_acc: 0.8333\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4628 - acc: 0.8152 - val_loss: 0.4219 - val_acc: 0.8333\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4621 - acc: 0.8140 - val_loss: 0.4211 - val_acc: 0.8333\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4613 - acc: 0.8140 - val_loss: 0.4203 - val_acc: 0.8333\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4605 - acc: 0.8140 - val_loss: 0.4195 - val_acc: 0.8333\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4597 - acc: 0.8140 - val_loss: 0.4187 - val_acc: 0.8333\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4590 - acc: 0.8152 - val_loss: 0.4179 - val_acc: 0.8333\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4583 - acc: 0.8177 - val_loss: 0.4172 - val_acc: 0.8333\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4576 - acc: 0.8140 - val_loss: 0.4169 - val_acc: 0.8333\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4568 - acc: 0.8115 - val_loss: 0.4164 - val_acc: 0.8333\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4560 - acc: 0.8127 - val_loss: 0.4161 - val_acc: 0.8333\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4553 - acc: 0.8152 - val_loss: 0.4155 - val_acc: 0.8333\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4546 - acc: 0.8152 - val_loss: 0.4147 - val_acc: 0.8333\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4540 - acc: 0.8152 - val_loss: 0.4140 - val_acc: 0.8333\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4533 - acc: 0.8165 - val_loss: 0.4138 - val_acc: 0.8333\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4527 - acc: 0.8165 - val_loss: 0.4132 - val_acc: 0.8333\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4521 - acc: 0.8165 - val_loss: 0.4125 - val_acc: 0.8333\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4514 - acc: 0.8165 - val_loss: 0.4117 - val_acc: 0.8333\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4508 - acc: 0.8165 - val_loss: 0.4109 - val_acc: 0.8333\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4501 - acc: 0.8190 - val_loss: 0.4103 - val_acc: 0.8333\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4494 - acc: 0.8177 - val_loss: 0.4099 - val_acc: 0.8333\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4487 - acc: 0.8152 - val_loss: 0.4096 - val_acc: 0.8333\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4480 - acc: 0.8152 - val_loss: 0.4090 - val_acc: 0.8333\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4473 - acc: 0.8152 - val_loss: 0.4083 - val_acc: 0.8333\n",
      "Epoch 171/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4466 - acc: 0.8152 - val_loss: 0.4080 - val_acc: 0.8333\n",
      "Epoch 172/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4459 - acc: 0.8165 - val_loss: 0.4074 - val_acc: 0.8333\n",
      "Epoch 173/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4453 - acc: 0.8165 - val_loss: 0.4067 - val_acc: 0.8333\n",
      "Epoch 174/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4447 - acc: 0.8165 - val_loss: 0.4060 - val_acc: 0.8333\n",
      "Epoch 175/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4441 - acc: 0.8165 - val_loss: 0.4052 - val_acc: 0.8333\n",
      "Epoch 176/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4434 - acc: 0.8202 - val_loss: 0.4048 - val_acc: 0.8333\n",
      "Epoch 177/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4428 - acc: 0.8202 - val_loss: 0.4043 - val_acc: 0.8333\n",
      "Epoch 178/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4422 - acc: 0.8202 - val_loss: 0.4039 - val_acc: 0.8333\n",
      "Epoch 179/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4416 - acc: 0.8240 - val_loss: 0.4033 - val_acc: 0.8333\n",
      "Epoch 180/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4410 - acc: 0.8202 - val_loss: 0.4026 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4404 - acc: 0.8240 - val_loss: 0.4021 - val_acc: 0.8333\n",
      "Epoch 182/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4398 - acc: 0.8240 - val_loss: 0.4019 - val_acc: 0.8333\n",
      "Epoch 183/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4391 - acc: 0.8265 - val_loss: 0.4014 - val_acc: 0.8333\n",
      "Epoch 184/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4387 - acc: 0.8265 - val_loss: 0.4015 - val_acc: 0.8333\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 942us/step - loss: 0.6705 - acc: 0.6467 - val_loss: 0.6511 - val_acc: 0.7556\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6660 - acc: 0.6617 - val_loss: 0.6459 - val_acc: 0.7556\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6620 - acc: 0.6767 - val_loss: 0.6412 - val_acc: 0.7556\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6586 - acc: 0.6841 - val_loss: 0.6375 - val_acc: 0.7444\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6554 - acc: 0.6866 - val_loss: 0.6335 - val_acc: 0.7667\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6521 - acc: 0.6841 - val_loss: 0.6295 - val_acc: 0.7444\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6490 - acc: 0.6866 - val_loss: 0.6258 - val_acc: 0.7333\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6461 - acc: 0.6891 - val_loss: 0.6223 - val_acc: 0.7333\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6434 - acc: 0.6904 - val_loss: 0.6192 - val_acc: 0.7333\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6408 - acc: 0.6854 - val_loss: 0.6160 - val_acc: 0.7333\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6385 - acc: 0.6829 - val_loss: 0.6129 - val_acc: 0.7333\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6361 - acc: 0.6854 - val_loss: 0.6102 - val_acc: 0.7222\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 83us/step - loss: 0.6339 - acc: 0.6854 - val_loss: 0.6074 - val_acc: 0.7000\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6318 - acc: 0.6841 - val_loss: 0.6048 - val_acc: 0.7000\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6300 - acc: 0.6854 - val_loss: 0.6031 - val_acc: 0.7111\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6282 - acc: 0.6866 - val_loss: 0.6007 - val_acc: 0.7111\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6265 - acc: 0.6866 - val_loss: 0.5988 - val_acc: 0.7111\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6247 - acc: 0.6891 - val_loss: 0.5967 - val_acc: 0.7111\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6231 - acc: 0.6916 - val_loss: 0.5948 - val_acc: 0.7111\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6213 - acc: 0.6916 - val_loss: 0.5924 - val_acc: 0.7111\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6194 - acc: 0.6929 - val_loss: 0.5904 - val_acc: 0.7111\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6177 - acc: 0.6929 - val_loss: 0.5885 - val_acc: 0.7222\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6161 - acc: 0.6929 - val_loss: 0.5864 - val_acc: 0.7222\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6144 - acc: 0.6941 - val_loss: 0.5845 - val_acc: 0.7222\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6128 - acc: 0.6954 - val_loss: 0.5825 - val_acc: 0.7222\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6112 - acc: 0.6966 - val_loss: 0.5805 - val_acc: 0.7222\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6095 - acc: 0.6966 - val_loss: 0.5785 - val_acc: 0.7222\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6078 - acc: 0.6979 - val_loss: 0.5765 - val_acc: 0.7222\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6062 - acc: 0.6991 - val_loss: 0.5745 - val_acc: 0.7222\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6046 - acc: 0.6991 - val_loss: 0.5725 - val_acc: 0.7222\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6031 - acc: 0.7029 - val_loss: 0.5709 - val_acc: 0.7222\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6015 - acc: 0.7041 - val_loss: 0.5692 - val_acc: 0.7222\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6000 - acc: 0.7054 - val_loss: 0.5673 - val_acc: 0.7222\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5985 - acc: 0.7054 - val_loss: 0.5655 - val_acc: 0.7222\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5971 - acc: 0.7091 - val_loss: 0.5641 - val_acc: 0.7333\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5957 - acc: 0.7104 - val_loss: 0.5623 - val_acc: 0.7333\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5942 - acc: 0.7104 - val_loss: 0.5604 - val_acc: 0.7333\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5926 - acc: 0.7116 - val_loss: 0.5586 - val_acc: 0.7333\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5912 - acc: 0.7116 - val_loss: 0.5571 - val_acc: 0.7333\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5897 - acc: 0.7129 - val_loss: 0.5553 - val_acc: 0.7333\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5883 - acc: 0.7129 - val_loss: 0.5536 - val_acc: 0.7333\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.5868 - acc: 0.7129 - val_loss: 0.5518 - val_acc: 0.7333\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5853 - acc: 0.7129 - val_loss: 0.5501 - val_acc: 0.7333\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5838 - acc: 0.7129 - val_loss: 0.5484 - val_acc: 0.7444\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5823 - acc: 0.7141 - val_loss: 0.5466 - val_acc: 0.7444\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5807 - acc: 0.7141 - val_loss: 0.5448 - val_acc: 0.7444\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5792 - acc: 0.7141 - val_loss: 0.5432 - val_acc: 0.7444\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5777 - acc: 0.7166 - val_loss: 0.5414 - val_acc: 0.7444\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5762 - acc: 0.7179 - val_loss: 0.5397 - val_acc: 0.7444\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5747 - acc: 0.7179 - val_loss: 0.5380 - val_acc: 0.7556\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5732 - acc: 0.7191 - val_loss: 0.5362 - val_acc: 0.7556\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5717 - acc: 0.7203 - val_loss: 0.5348 - val_acc: 0.7556\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5702 - acc: 0.7203 - val_loss: 0.5331 - val_acc: 0.7556\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5687 - acc: 0.7216 - val_loss: 0.5315 - val_acc: 0.7556\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5672 - acc: 0.7228 - val_loss: 0.5298 - val_acc: 0.7556\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5659 - acc: 0.7228 - val_loss: 0.5282 - val_acc: 0.7556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5643 - acc: 0.7266 - val_loss: 0.5265 - val_acc: 0.7667\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5628 - acc: 0.7278 - val_loss: 0.5248 - val_acc: 0.7667\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5614 - acc: 0.7278 - val_loss: 0.5231 - val_acc: 0.7667\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5599 - acc: 0.7303 - val_loss: 0.5218 - val_acc: 0.7667\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5585 - acc: 0.7328 - val_loss: 0.5201 - val_acc: 0.7667\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5572 - acc: 0.7366 - val_loss: 0.5188 - val_acc: 0.7667\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 90us/step - loss: 0.5557 - acc: 0.7403 - val_loss: 0.5173 - val_acc: 0.7667\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 75us/step - loss: 0.5541 - acc: 0.7416 - val_loss: 0.5157 - val_acc: 0.7667\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.5526 - acc: 0.7416 - val_loss: 0.5140 - val_acc: 0.7778\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5512 - acc: 0.7416 - val_loss: 0.5125 - val_acc: 0.7778\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5498 - acc: 0.7416 - val_loss: 0.5108 - val_acc: 0.7778\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5484 - acc: 0.7428 - val_loss: 0.5093 - val_acc: 0.7778\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5469 - acc: 0.7428 - val_loss: 0.5077 - val_acc: 0.7778\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5454 - acc: 0.7428 - val_loss: 0.5060 - val_acc: 0.7778\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5440 - acc: 0.7453 - val_loss: 0.5044 - val_acc: 0.7778\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5426 - acc: 0.7478 - val_loss: 0.5030 - val_acc: 0.7778\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5412 - acc: 0.7491 - val_loss: 0.5014 - val_acc: 0.7778\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5398 - acc: 0.7466 - val_loss: 0.4998 - val_acc: 0.7889\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5383 - acc: 0.7491 - val_loss: 0.4982 - val_acc: 0.7889\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.5369 - acc: 0.7491 - val_loss: 0.4968 - val_acc: 0.7889\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 72us/step - loss: 0.5355 - acc: 0.7503 - val_loss: 0.4951 - val_acc: 0.7889\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 85us/step - loss: 0.5340 - acc: 0.7503 - val_loss: 0.4936 - val_acc: 0.7889\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 88us/step - loss: 0.5326 - acc: 0.7516 - val_loss: 0.4920 - val_acc: 0.7889\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5312 - acc: 0.7528 - val_loss: 0.4905 - val_acc: 0.7889\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5298 - acc: 0.7541 - val_loss: 0.4890 - val_acc: 0.7889\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5284 - acc: 0.7566 - val_loss: 0.4876 - val_acc: 0.8000\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5272 - acc: 0.7578 - val_loss: 0.4865 - val_acc: 0.8000\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5259 - acc: 0.7591 - val_loss: 0.4851 - val_acc: 0.8000\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5245 - acc: 0.7640 - val_loss: 0.4835 - val_acc: 0.7889\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5231 - acc: 0.7653 - val_loss: 0.4821 - val_acc: 0.8000\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5218 - acc: 0.7665 - val_loss: 0.4807 - val_acc: 0.8000\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5205 - acc: 0.7690 - val_loss: 0.4794 - val_acc: 0.8000\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5193 - acc: 0.7715 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5179 - acc: 0.7765 - val_loss: 0.4766 - val_acc: 0.8000\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5166 - acc: 0.7790 - val_loss: 0.4751 - val_acc: 0.8222\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5153 - acc: 0.7790 - val_loss: 0.4737 - val_acc: 0.8222\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.5140 - acc: 0.7790 - val_loss: 0.4723 - val_acc: 0.8222\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5128 - acc: 0.7790 - val_loss: 0.4708 - val_acc: 0.8222\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5116 - acc: 0.7790 - val_loss: 0.4697 - val_acc: 0.8222\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5103 - acc: 0.7840 - val_loss: 0.4684 - val_acc: 0.8222\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5090 - acc: 0.7865 - val_loss: 0.4670 - val_acc: 0.8222\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5079 - acc: 0.7865 - val_loss: 0.4657 - val_acc: 0.8333\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5066 - acc: 0.7865 - val_loss: 0.4643 - val_acc: 0.8333\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5054 - acc: 0.7865 - val_loss: 0.4630 - val_acc: 0.8333\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5042 - acc: 0.7865 - val_loss: 0.4617 - val_acc: 0.8333\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5029 - acc: 0.7878 - val_loss: 0.4604 - val_acc: 0.8444\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5017 - acc: 0.7865 - val_loss: 0.4591 - val_acc: 0.8444\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5005 - acc: 0.7865 - val_loss: 0.4579 - val_acc: 0.8444\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4993 - acc: 0.7890 - val_loss: 0.4566 - val_acc: 0.8444\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 78us/step - loss: 0.4982 - acc: 0.7890 - val_loss: 0.4554 - val_acc: 0.8444\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 96us/step - loss: 0.4971 - acc: 0.7890 - val_loss: 0.4541 - val_acc: 0.8444\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 87us/step - loss: 0.4960 - acc: 0.7903 - val_loss: 0.4530 - val_acc: 0.8444\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.4949 - acc: 0.7903 - val_loss: 0.4519 - val_acc: 0.8444\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4937 - acc: 0.7915 - val_loss: 0.4506 - val_acc: 0.8444\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4926 - acc: 0.7928 - val_loss: 0.4495 - val_acc: 0.8444\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4915 - acc: 0.7928 - val_loss: 0.4483 - val_acc: 0.8444\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4904 - acc: 0.7928 - val_loss: 0.4472 - val_acc: 0.8444\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4893 - acc: 0.7940 - val_loss: 0.4461 - val_acc: 0.8444\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4882 - acc: 0.7940 - val_loss: 0.4449 - val_acc: 0.8444\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4871 - acc: 0.7953 - val_loss: 0.4438 - val_acc: 0.8444\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 62us/step - loss: 0.4860 - acc: 0.7965 - val_loss: 0.4428 - val_acc: 0.8556\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4851 - acc: 0.7978 - val_loss: 0.4418 - val_acc: 0.8556\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4843 - acc: 0.7990 - val_loss: 0.4408 - val_acc: 0.8556\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4832 - acc: 0.7978 - val_loss: 0.4399 - val_acc: 0.8556\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4823 - acc: 0.7990 - val_loss: 0.4390 - val_acc: 0.8556\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4815 - acc: 0.7990 - val_loss: 0.4379 - val_acc: 0.8556\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4805 - acc: 0.7990 - val_loss: 0.4369 - val_acc: 0.8556\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4797 - acc: 0.7990 - val_loss: 0.4365 - val_acc: 0.8556\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4789 - acc: 0.8015 - val_loss: 0.4357 - val_acc: 0.8556\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4777 - acc: 0.8015 - val_loss: 0.4348 - val_acc: 0.8556\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4768 - acc: 0.8002 - val_loss: 0.4339 - val_acc: 0.8556\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4758 - acc: 0.8040 - val_loss: 0.4330 - val_acc: 0.8556\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4749 - acc: 0.8027 - val_loss: 0.4320 - val_acc: 0.8556\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4742 - acc: 0.8052 - val_loss: 0.4312 - val_acc: 0.8556\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4736 - acc: 0.8052 - val_loss: 0.4308 - val_acc: 0.8444\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4727 - acc: 0.8065 - val_loss: 0.4300 - val_acc: 0.8556\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4719 - acc: 0.8077 - val_loss: 0.4291 - val_acc: 0.8444\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4710 - acc: 0.8090 - val_loss: 0.4283 - val_acc: 0.8444\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4702 - acc: 0.8077 - val_loss: 0.4274 - val_acc: 0.8444\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4693 - acc: 0.8090 - val_loss: 0.4265 - val_acc: 0.8444\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4684 - acc: 0.8115 - val_loss: 0.4256 - val_acc: 0.8444\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4675 - acc: 0.8115 - val_loss: 0.4249 - val_acc: 0.8444\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4667 - acc: 0.8115 - val_loss: 0.4241 - val_acc: 0.8444\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4659 - acc: 0.8127 - val_loss: 0.4232 - val_acc: 0.8444\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4651 - acc: 0.8140 - val_loss: 0.4229 - val_acc: 0.8444\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4644 - acc: 0.8140 - val_loss: 0.4220 - val_acc: 0.8444\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4636 - acc: 0.8177 - val_loss: 0.4213 - val_acc: 0.8444\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4627 - acc: 0.8177 - val_loss: 0.4207 - val_acc: 0.8667\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4620 - acc: 0.8152 - val_loss: 0.4201 - val_acc: 0.8778\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4612 - acc: 0.8165 - val_loss: 0.4194 - val_acc: 0.8778\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4604 - acc: 0.8165 - val_loss: 0.4187 - val_acc: 0.8778\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4597 - acc: 0.8177 - val_loss: 0.4179 - val_acc: 0.8778\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4589 - acc: 0.8177 - val_loss: 0.4177 - val_acc: 0.8778\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4584 - acc: 0.8177 - val_loss: 0.4169 - val_acc: 0.8778\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4576 - acc: 0.8202 - val_loss: 0.4162 - val_acc: 0.8778\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4568 - acc: 0.8190 - val_loss: 0.4156 - val_acc: 0.8778\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4561 - acc: 0.8190 - val_loss: 0.4149 - val_acc: 0.8778\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4554 - acc: 0.8202 - val_loss: 0.4142 - val_acc: 0.8778\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.4546 - acc: 0.8202 - val_loss: 0.4134 - val_acc: 0.8778\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4539 - acc: 0.8215 - val_loss: 0.4126 - val_acc: 0.8778\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4533 - acc: 0.8227 - val_loss: 0.4118 - val_acc: 0.8778\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4527 - acc: 0.8240 - val_loss: 0.4111 - val_acc: 0.8778\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4519 - acc: 0.8227 - val_loss: 0.4106 - val_acc: 0.8778\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4512 - acc: 0.8240 - val_loss: 0.4102 - val_acc: 0.8778\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4506 - acc: 0.8265 - val_loss: 0.4100 - val_acc: 0.8778\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4501 - acc: 0.8265 - val_loss: 0.4094 - val_acc: 0.8778\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4494 - acc: 0.8277 - val_loss: 0.4089 - val_acc: 0.8778\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4487 - acc: 0.8277 - val_loss: 0.4081 - val_acc: 0.8778\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4480 - acc: 0.8277 - val_loss: 0.4075 - val_acc: 0.8778\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4473 - acc: 0.8290 - val_loss: 0.4069 - val_acc: 0.8778\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4467 - acc: 0.8302 - val_loss: 0.4064 - val_acc: 0.8778\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4460 - acc: 0.8315 - val_loss: 0.4057 - val_acc: 0.8778\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4454 - acc: 0.8315 - val_loss: 0.4052 - val_acc: 0.8778\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4447 - acc: 0.8315 - val_loss: 0.4044 - val_acc: 0.8778\n",
      "Epoch 171/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4441 - acc: 0.8302 - val_loss: 0.4039 - val_acc: 0.8778\n",
      "Epoch 172/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4435 - acc: 0.8315 - val_loss: 0.4036 - val_acc: 0.8778\n",
      "Epoch 173/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4429 - acc: 0.8315 - val_loss: 0.4030 - val_acc: 0.8778\n",
      "Epoch 174/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4423 - acc: 0.8315 - val_loss: 0.4029 - val_acc: 0.8778\n",
      "Epoch 175/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4418 - acc: 0.8315 - val_loss: 0.4023 - val_acc: 0.8778\n",
      "Epoch 176/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4412 - acc: 0.8315 - val_loss: 0.4017 - val_acc: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4405 - acc: 0.8302 - val_loss: 0.4011 - val_acc: 0.8778\n",
      "Epoch 178/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4399 - acc: 0.8315 - val_loss: 0.4005 - val_acc: 0.8778\n",
      "Epoch 179/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4394 - acc: 0.8327 - val_loss: 0.3999 - val_acc: 0.8778\n",
      "Epoch 180/1000\n",
      "801/801 [==============================] - 0s 82us/step - loss: 0.4387 - acc: 0.8340 - val_loss: 0.3994 - val_acc: 0.8778\n",
      "Epoch 181/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4382 - acc: 0.8340 - val_loss: 0.3989 - val_acc: 0.8778\n",
      "Epoch 182/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4376 - acc: 0.8327 - val_loss: 0.3985 - val_acc: 0.8778\n",
      "Epoch 183/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4370 - acc: 0.8340 - val_loss: 0.3979 - val_acc: 0.8778\n",
      "Epoch 184/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4365 - acc: 0.8340 - val_loss: 0.3973 - val_acc: 0.8778\n",
      "Epoch 185/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4360 - acc: 0.8327 - val_loss: 0.3968 - val_acc: 0.8778\n",
      "Epoch 186/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4355 - acc: 0.8340 - val_loss: 0.3966 - val_acc: 0.8889\n",
      "Epoch 187/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4348 - acc: 0.8390 - val_loss: 0.3961 - val_acc: 0.8889\n",
      "Epoch 188/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4343 - acc: 0.8390 - val_loss: 0.3957 - val_acc: 0.8889\n",
      "Epoch 189/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4338 - acc: 0.8402 - val_loss: 0.3953 - val_acc: 0.8889\n",
      "Epoch 190/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4332 - acc: 0.8402 - val_loss: 0.3948 - val_acc: 0.8889\n",
      "Epoch 191/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4327 - acc: 0.8402 - val_loss: 0.3944 - val_acc: 0.8889\n",
      "Epoch 192/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4322 - acc: 0.8402 - val_loss: 0.3939 - val_acc: 0.8889\n",
      "Epoch 193/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4317 - acc: 0.8402 - val_loss: 0.3934 - val_acc: 0.8889\n",
      "Epoch 194/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4312 - acc: 0.8402 - val_loss: 0.3930 - val_acc: 0.8889\n",
      "Epoch 195/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4306 - acc: 0.8414 - val_loss: 0.3927 - val_acc: 0.8889\n",
      "Epoch 196/1000\n",
      "801/801 [==============================] - 0s 75us/step - loss: 0.4301 - acc: 0.8402 - val_loss: 0.3923 - val_acc: 0.8889\n",
      "Epoch 197/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.4296 - acc: 0.8402 - val_loss: 0.3919 - val_acc: 0.8889\n",
      "Epoch 198/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4291 - acc: 0.8427 - val_loss: 0.3915 - val_acc: 0.8889\n",
      "Epoch 199/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4287 - acc: 0.8427 - val_loss: 0.3914 - val_acc: 0.8889\n",
      "Epoch 200/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4284 - acc: 0.8427 - val_loss: 0.3911 - val_acc: 0.8889\n",
      "Epoch 201/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4280 - acc: 0.8427 - val_loss: 0.3908 - val_acc: 0.8889\n",
      "Epoch 202/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4274 - acc: 0.8439 - val_loss: 0.3906 - val_acc: 0.8889\n",
      "Epoch 203/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4269 - acc: 0.8439 - val_loss: 0.3903 - val_acc: 0.8778\n",
      "Epoch 204/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4263 - acc: 0.8439 - val_loss: 0.3900 - val_acc: 0.8778\n",
      "Epoch 205/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4259 - acc: 0.8439 - val_loss: 0.3896 - val_acc: 0.8778\n",
      "Epoch 206/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4254 - acc: 0.8439 - val_loss: 0.3892 - val_acc: 0.8778\n",
      "Epoch 207/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4251 - acc: 0.8439 - val_loss: 0.3891 - val_acc: 0.8778\n",
      "Epoch 208/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4247 - acc: 0.8452 - val_loss: 0.3890 - val_acc: 0.8778\n",
      "Epoch 209/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4242 - acc: 0.8452 - val_loss: 0.3888 - val_acc: 0.8778\n",
      "Epoch 210/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4236 - acc: 0.8464 - val_loss: 0.3888 - val_acc: 0.8778\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 0.7137 - acc: 0.5481 - val_loss: 0.6944 - val_acc: 0.6111\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.7102 - acc: 0.5593 - val_loss: 0.6907 - val_acc: 0.6333\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.7074 - acc: 0.5655 - val_loss: 0.6875 - val_acc: 0.6333\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.7046 - acc: 0.5718 - val_loss: 0.6841 - val_acc: 0.6333\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.7019 - acc: 0.5830 - val_loss: 0.6813 - val_acc: 0.6333\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6994 - acc: 0.5868 - val_loss: 0.6782 - val_acc: 0.6333\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6968 - acc: 0.5943 - val_loss: 0.6751 - val_acc: 0.6333\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6944 - acc: 0.5955 - val_loss: 0.6720 - val_acc: 0.6333\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6920 - acc: 0.6017 - val_loss: 0.6696 - val_acc: 0.6333\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6899 - acc: 0.6042 - val_loss: 0.6674 - val_acc: 0.6333\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6878 - acc: 0.6067 - val_loss: 0.6650 - val_acc: 0.6333\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6855 - acc: 0.6080 - val_loss: 0.6622 - val_acc: 0.6556\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6834 - acc: 0.6105 - val_loss: 0.6600 - val_acc: 0.6556\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6812 - acc: 0.6117 - val_loss: 0.6573 - val_acc: 0.6556\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6792 - acc: 0.6130 - val_loss: 0.6554 - val_acc: 0.6556\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6775 - acc: 0.6130 - val_loss: 0.6534 - val_acc: 0.6556\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6755 - acc: 0.6130 - val_loss: 0.6509 - val_acc: 0.6556\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6736 - acc: 0.6130 - val_loss: 0.6490 - val_acc: 0.6556\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6717 - acc: 0.6142 - val_loss: 0.6468 - val_acc: 0.6556\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6699 - acc: 0.6142 - val_loss: 0.6448 - val_acc: 0.6556\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6680 - acc: 0.6142 - val_loss: 0.6426 - val_acc: 0.6556\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6663 - acc: 0.6142 - val_loss: 0.6408 - val_acc: 0.6556\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6642 - acc: 0.6142 - val_loss: 0.6386 - val_acc: 0.6556\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6623 - acc: 0.6155 - val_loss: 0.6365 - val_acc: 0.6556\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6607 - acc: 0.6155 - val_loss: 0.6347 - val_acc: 0.6556\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6588 - acc: 0.6155 - val_loss: 0.6325 - val_acc: 0.6556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6569 - acc: 0.6155 - val_loss: 0.6302 - val_acc: 0.6556\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6551 - acc: 0.6192 - val_loss: 0.6282 - val_acc: 0.6556\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6534 - acc: 0.6205 - val_loss: 0.6265 - val_acc: 0.6556\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6516 - acc: 0.6205 - val_loss: 0.6243 - val_acc: 0.6556\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6498 - acc: 0.6217 - val_loss: 0.6225 - val_acc: 0.6556\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6480 - acc: 0.6217 - val_loss: 0.6206 - val_acc: 0.6556\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6462 - acc: 0.6217 - val_loss: 0.6188 - val_acc: 0.6556\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6444 - acc: 0.6217 - val_loss: 0.6168 - val_acc: 0.6556\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6425 - acc: 0.6242 - val_loss: 0.6146 - val_acc: 0.6556\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6407 - acc: 0.6255 - val_loss: 0.6126 - val_acc: 0.6556\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6390 - acc: 0.6255 - val_loss: 0.6109 - val_acc: 0.6556\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6374 - acc: 0.6255 - val_loss: 0.6095 - val_acc: 0.6556\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6358 - acc: 0.6255 - val_loss: 0.6074 - val_acc: 0.6556\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6340 - acc: 0.6267 - val_loss: 0.6056 - val_acc: 0.6556\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6322 - acc: 0.6292 - val_loss: 0.6035 - val_acc: 0.6556\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6303 - acc: 0.6317 - val_loss: 0.6016 - val_acc: 0.6556\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 79us/step - loss: 0.6285 - acc: 0.6330 - val_loss: 0.5999 - val_acc: 0.6556\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 71us/step - loss: 0.6268 - acc: 0.6317 - val_loss: 0.5979 - val_acc: 0.6556\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6250 - acc: 0.6342 - val_loss: 0.5961 - val_acc: 0.6556\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6232 - acc: 0.6342 - val_loss: 0.5940 - val_acc: 0.6556\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6213 - acc: 0.6355 - val_loss: 0.5920 - val_acc: 0.6556\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6195 - acc: 0.6367 - val_loss: 0.5898 - val_acc: 0.6556\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6177 - acc: 0.6392 - val_loss: 0.5878 - val_acc: 0.6556\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6160 - acc: 0.6417 - val_loss: 0.5858 - val_acc: 0.6556\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6143 - acc: 0.6417 - val_loss: 0.5839 - val_acc: 0.6556\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 81us/step - loss: 0.6125 - acc: 0.6417 - val_loss: 0.5819 - val_acc: 0.6556\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.6107 - acc: 0.6417 - val_loss: 0.5799 - val_acc: 0.6556\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 83us/step - loss: 0.6089 - acc: 0.6454 - val_loss: 0.5779 - val_acc: 0.6556\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 94us/step - loss: 0.6071 - acc: 0.6479 - val_loss: 0.5758 - val_acc: 0.6667\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6053 - acc: 0.6504 - val_loss: 0.5738 - val_acc: 0.6667\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6036 - acc: 0.6517 - val_loss: 0.5719 - val_acc: 0.6667\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6020 - acc: 0.6554 - val_loss: 0.5700 - val_acc: 0.6778\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6002 - acc: 0.6554 - val_loss: 0.5681 - val_acc: 0.6778\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5984 - acc: 0.6579 - val_loss: 0.5662 - val_acc: 0.6889\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5967 - acc: 0.6592 - val_loss: 0.5645 - val_acc: 0.6889\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5949 - acc: 0.6604 - val_loss: 0.5626 - val_acc: 0.7000\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5933 - acc: 0.6642 - val_loss: 0.5610 - val_acc: 0.7000\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5915 - acc: 0.6704 - val_loss: 0.5591 - val_acc: 0.7000\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5898 - acc: 0.6729 - val_loss: 0.5572 - val_acc: 0.7000\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5881 - acc: 0.6767 - val_loss: 0.5553 - val_acc: 0.7000\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5864 - acc: 0.6792 - val_loss: 0.5536 - val_acc: 0.7222\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5846 - acc: 0.6792 - val_loss: 0.5516 - val_acc: 0.7222\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5828 - acc: 0.6816 - val_loss: 0.5496 - val_acc: 0.7222\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5811 - acc: 0.6841 - val_loss: 0.5479 - val_acc: 0.7444\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5795 - acc: 0.6866 - val_loss: 0.5461 - val_acc: 0.7444\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5778 - acc: 0.6879 - val_loss: 0.5445 - val_acc: 0.7556\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5761 - acc: 0.6966 - val_loss: 0.5426 - val_acc: 0.7556\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5744 - acc: 0.6966 - val_loss: 0.5407 - val_acc: 0.7556\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5728 - acc: 0.6954 - val_loss: 0.5388 - val_acc: 0.7556\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5711 - acc: 0.6979 - val_loss: 0.5368 - val_acc: 0.7667\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5693 - acc: 0.6991 - val_loss: 0.5350 - val_acc: 0.7778\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5677 - acc: 0.7004 - val_loss: 0.5332 - val_acc: 0.7778\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5660 - acc: 0.7066 - val_loss: 0.5314 - val_acc: 0.7778\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5644 - acc: 0.7154 - val_loss: 0.5298 - val_acc: 0.7667\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5626 - acc: 0.7216 - val_loss: 0.5282 - val_acc: 0.7778\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5610 - acc: 0.7203 - val_loss: 0.5265 - val_acc: 0.7778\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5593 - acc: 0.7191 - val_loss: 0.5249 - val_acc: 0.7889\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5577 - acc: 0.7216 - val_loss: 0.5230 - val_acc: 0.7889\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5562 - acc: 0.7216 - val_loss: 0.5212 - val_acc: 0.7889\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5545 - acc: 0.7266 - val_loss: 0.5195 - val_acc: 0.8000\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 63us/step - loss: 0.5529 - acc: 0.7291 - val_loss: 0.5177 - val_acc: 0.8000\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5511 - acc: 0.7328 - val_loss: 0.5158 - val_acc: 0.7889\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5495 - acc: 0.7353 - val_loss: 0.5142 - val_acc: 0.7889\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5479 - acc: 0.7366 - val_loss: 0.5124 - val_acc: 0.7889\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5462 - acc: 0.7391 - val_loss: 0.5108 - val_acc: 0.7889\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5448 - acc: 0.7428 - val_loss: 0.5091 - val_acc: 0.7889\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5432 - acc: 0.7478 - val_loss: 0.5077 - val_acc: 0.8000\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5415 - acc: 0.7503 - val_loss: 0.5061 - val_acc: 0.8111\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5398 - acc: 0.7516 - val_loss: 0.5043 - val_acc: 0.8111\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5383 - acc: 0.7528 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.5369 - acc: 0.7516 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 94us/step - loss: 0.5353 - acc: 0.7528 - val_loss: 0.4995 - val_acc: 0.8000\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.5338 - acc: 0.7566 - val_loss: 0.4982 - val_acc: 0.8000\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 72us/step - loss: 0.5324 - acc: 0.7603 - val_loss: 0.4967 - val_acc: 0.8000\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5311 - acc: 0.7615 - val_loss: 0.4953 - val_acc: 0.8000\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5297 - acc: 0.7640 - val_loss: 0.4938 - val_acc: 0.8000\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5282 - acc: 0.7665 - val_loss: 0.4926 - val_acc: 0.8111\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5267 - acc: 0.7653 - val_loss: 0.4912 - val_acc: 0.8111\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5254 - acc: 0.7690 - val_loss: 0.4902 - val_acc: 0.8111\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5241 - acc: 0.7728 - val_loss: 0.4888 - val_acc: 0.8111\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5226 - acc: 0.7740 - val_loss: 0.4874 - val_acc: 0.8222\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5212 - acc: 0.7740 - val_loss: 0.4859 - val_acc: 0.8111\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5197 - acc: 0.7753 - val_loss: 0.4845 - val_acc: 0.8111\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5184 - acc: 0.7753 - val_loss: 0.4831 - val_acc: 0.8111\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5170 - acc: 0.7790 - val_loss: 0.4817 - val_acc: 0.8111\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5156 - acc: 0.7815 - val_loss: 0.4806 - val_acc: 0.8111\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5142 - acc: 0.7865 - val_loss: 0.4792 - val_acc: 0.8222\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5131 - acc: 0.7865 - val_loss: 0.4778 - val_acc: 0.8222\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5116 - acc: 0.7865 - val_loss: 0.4767 - val_acc: 0.8222\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5103 - acc: 0.7890 - val_loss: 0.4753 - val_acc: 0.8222\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5090 - acc: 0.7890 - val_loss: 0.4740 - val_acc: 0.8222\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5077 - acc: 0.7890 - val_loss: 0.4727 - val_acc: 0.8222\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5065 - acc: 0.7878 - val_loss: 0.4717 - val_acc: 0.8333\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5052 - acc: 0.7878 - val_loss: 0.4706 - val_acc: 0.8333\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5040 - acc: 0.7890 - val_loss: 0.4692 - val_acc: 0.8333\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5027 - acc: 0.7890 - val_loss: 0.4679 - val_acc: 0.8444\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5017 - acc: 0.7928 - val_loss: 0.4672 - val_acc: 0.8444\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5005 - acc: 0.7928 - val_loss: 0.4660 - val_acc: 0.8444\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4994 - acc: 0.7953 - val_loss: 0.4651 - val_acc: 0.8444\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4981 - acc: 0.7965 - val_loss: 0.4637 - val_acc: 0.8444\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4969 - acc: 0.7965 - val_loss: 0.4623 - val_acc: 0.8444\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4959 - acc: 0.7965 - val_loss: 0.4610 - val_acc: 0.8444\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4947 - acc: 0.7965 - val_loss: 0.4599 - val_acc: 0.8333\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 76us/step - loss: 0.4935 - acc: 0.7978 - val_loss: 0.4592 - val_acc: 0.8444\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.4925 - acc: 0.8027 - val_loss: 0.4581 - val_acc: 0.8444\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4915 - acc: 0.7978 - val_loss: 0.4568 - val_acc: 0.8333\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4904 - acc: 0.7965 - val_loss: 0.4558 - val_acc: 0.8333\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4893 - acc: 0.8027 - val_loss: 0.4549 - val_acc: 0.8444\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4882 - acc: 0.8040 - val_loss: 0.4539 - val_acc: 0.8444\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4872 - acc: 0.8040 - val_loss: 0.4528 - val_acc: 0.8444\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.4862 - acc: 0.8052 - val_loss: 0.4522 - val_acc: 0.8444\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 76us/step - loss: 0.4853 - acc: 0.8052 - val_loss: 0.4511 - val_acc: 0.8444\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 82us/step - loss: 0.4842 - acc: 0.8052 - val_loss: 0.4499 - val_acc: 0.8444\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.4833 - acc: 0.8052 - val_loss: 0.4489 - val_acc: 0.8444\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.4823 - acc: 0.8052 - val_loss: 0.4479 - val_acc: 0.8444\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 72us/step - loss: 0.4813 - acc: 0.8090 - val_loss: 0.4471 - val_acc: 0.8444\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4802 - acc: 0.8102 - val_loss: 0.4460 - val_acc: 0.8444\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 86us/step - loss: 0.4792 - acc: 0.8115 - val_loss: 0.4451 - val_acc: 0.8444\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.4783 - acc: 0.8102 - val_loss: 0.4440 - val_acc: 0.8444\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4774 - acc: 0.8140 - val_loss: 0.4430 - val_acc: 0.8444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 70us/step - loss: 0.4765 - acc: 0.8165 - val_loss: 0.4421 - val_acc: 0.8444\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4755 - acc: 0.8165 - val_loss: 0.4412 - val_acc: 0.8444\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4747 - acc: 0.8177 - val_loss: 0.4403 - val_acc: 0.8444\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4737 - acc: 0.8190 - val_loss: 0.4394 - val_acc: 0.8444\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4727 - acc: 0.8190 - val_loss: 0.4386 - val_acc: 0.8444\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4718 - acc: 0.8190 - val_loss: 0.4377 - val_acc: 0.8444\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4708 - acc: 0.8190 - val_loss: 0.4368 - val_acc: 0.8444\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4699 - acc: 0.8177 - val_loss: 0.4360 - val_acc: 0.8444\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4692 - acc: 0.8202 - val_loss: 0.4351 - val_acc: 0.8444\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4683 - acc: 0.8190 - val_loss: 0.4344 - val_acc: 0.8444\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4676 - acc: 0.8190 - val_loss: 0.4344 - val_acc: 0.8444\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4668 - acc: 0.8215 - val_loss: 0.4338 - val_acc: 0.8444\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4662 - acc: 0.8227 - val_loss: 0.4329 - val_acc: 0.8444\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4655 - acc: 0.8190 - val_loss: 0.4324 - val_acc: 0.8444\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4646 - acc: 0.8190 - val_loss: 0.4315 - val_acc: 0.8444\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4638 - acc: 0.8177 - val_loss: 0.4307 - val_acc: 0.8444\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4631 - acc: 0.8190 - val_loss: 0.4300 - val_acc: 0.8444\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4622 - acc: 0.8190 - val_loss: 0.4291 - val_acc: 0.8444\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4614 - acc: 0.8190 - val_loss: 0.4282 - val_acc: 0.8444\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 80us/step - loss: 0.4607 - acc: 0.8177 - val_loss: 0.4275 - val_acc: 0.8444\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.4600 - acc: 0.8177 - val_loss: 0.4267 - val_acc: 0.8444\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 94us/step - loss: 0.4592 - acc: 0.8177 - val_loss: 0.4260 - val_acc: 0.8444\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 78us/step - loss: 0.4585 - acc: 0.8177 - val_loss: 0.4255 - val_acc: 0.8333\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4580 - acc: 0.8190 - val_loss: 0.4256 - val_acc: 0.8333\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 967us/step - loss: 0.8602 - acc: 0.3870 - val_loss: 0.8702 - val_acc: 0.3556\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.8447 - acc: 0.3870 - val_loss: 0.8539 - val_acc: 0.3556\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.8310 - acc: 0.3845 - val_loss: 0.8382 - val_acc: 0.3556\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.8184 - acc: 0.3808 - val_loss: 0.8248 - val_acc: 0.3556\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.8070 - acc: 0.3795 - val_loss: 0.8116 - val_acc: 0.3444\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.7955 - acc: 0.3783 - val_loss: 0.7973 - val_acc: 0.3444\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.7846 - acc: 0.3783 - val_loss: 0.7858 - val_acc: 0.3444\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.7744 - acc: 0.3720 - val_loss: 0.7734 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.7645 - acc: 0.3683 - val_loss: 0.7620 - val_acc: 0.3333\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.7551 - acc: 0.3770 - val_loss: 0.7512 - val_acc: 0.3333\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 71us/step - loss: 0.7463 - acc: 0.3795 - val_loss: 0.7409 - val_acc: 0.3556\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.7388 - acc: 0.3695 - val_loss: 0.7318 - val_acc: 0.3667\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.7311 - acc: 0.3795 - val_loss: 0.7224 - val_acc: 0.3667\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.7243 - acc: 0.3820 - val_loss: 0.7147 - val_acc: 0.3889\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.7176 - acc: 0.4032 - val_loss: 0.7060 - val_acc: 0.3889\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.7114 - acc: 0.4157 - val_loss: 0.6991 - val_acc: 0.4222\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.7059 - acc: 0.4295 - val_loss: 0.6925 - val_acc: 0.4667\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.7003 - acc: 0.4419 - val_loss: 0.6851 - val_acc: 0.5222\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6946 - acc: 0.4869 - val_loss: 0.6783 - val_acc: 0.5667\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6899 - acc: 0.5243 - val_loss: 0.6726 - val_acc: 0.6333\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6850 - acc: 0.5481 - val_loss: 0.6664 - val_acc: 0.6778\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6810 - acc: 0.5668 - val_loss: 0.6618 - val_acc: 0.6889\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6773 - acc: 0.5930 - val_loss: 0.6573 - val_acc: 0.6667\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6738 - acc: 0.6080 - val_loss: 0.6529 - val_acc: 0.6778\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6698 - acc: 0.6192 - val_loss: 0.6476 - val_acc: 0.7111\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6662 - acc: 0.6267 - val_loss: 0.6433 - val_acc: 0.7000\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6630 - acc: 0.6330 - val_loss: 0.6393 - val_acc: 0.6889\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6597 - acc: 0.6404 - val_loss: 0.6346 - val_acc: 0.7222\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6567 - acc: 0.6529 - val_loss: 0.6315 - val_acc: 0.7222\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6536 - acc: 0.6542 - val_loss: 0.6273 - val_acc: 0.7333\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6508 - acc: 0.6592 - val_loss: 0.6239 - val_acc: 0.7333\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6483 - acc: 0.6617 - val_loss: 0.6208 - val_acc: 0.7333\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6456 - acc: 0.6529 - val_loss: 0.6171 - val_acc: 0.7222\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6430 - acc: 0.6604 - val_loss: 0.6141 - val_acc: 0.7222\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6407 - acc: 0.6579 - val_loss: 0.6111 - val_acc: 0.7222\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6384 - acc: 0.6629 - val_loss: 0.6082 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6362 - acc: 0.6617 - val_loss: 0.6054 - val_acc: 0.7333\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6339 - acc: 0.6604 - val_loss: 0.6022 - val_acc: 0.7333\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6315 - acc: 0.6617 - val_loss: 0.5990 - val_acc: 0.7333\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6292 - acc: 0.6592 - val_loss: 0.5960 - val_acc: 0.7333\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6272 - acc: 0.6604 - val_loss: 0.5940 - val_acc: 0.7333\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6253 - acc: 0.6592 - val_loss: 0.5911 - val_acc: 0.7333\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6233 - acc: 0.6604 - val_loss: 0.5890 - val_acc: 0.7333\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6214 - acc: 0.6604 - val_loss: 0.5864 - val_acc: 0.7333\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6198 - acc: 0.6604 - val_loss: 0.5847 - val_acc: 0.7333\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6180 - acc: 0.6604 - val_loss: 0.5822 - val_acc: 0.7333\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6162 - acc: 0.6604 - val_loss: 0.5805 - val_acc: 0.7333\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6147 - acc: 0.6629 - val_loss: 0.5786 - val_acc: 0.7333\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6128 - acc: 0.6592 - val_loss: 0.5761 - val_acc: 0.7333\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6109 - acc: 0.6629 - val_loss: 0.5737 - val_acc: 0.7333\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6091 - acc: 0.6642 - val_loss: 0.5715 - val_acc: 0.7333\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6074 - acc: 0.6642 - val_loss: 0.5692 - val_acc: 0.7333\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6056 - acc: 0.6629 - val_loss: 0.5671 - val_acc: 0.7333\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6040 - acc: 0.6617 - val_loss: 0.5650 - val_acc: 0.7333\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6026 - acc: 0.6654 - val_loss: 0.5637 - val_acc: 0.7333\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6011 - acc: 0.6654 - val_loss: 0.5616 - val_acc: 0.7333\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5995 - acc: 0.6654 - val_loss: 0.5597 - val_acc: 0.7333\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5981 - acc: 0.6667 - val_loss: 0.5586 - val_acc: 0.7333\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5967 - acc: 0.6667 - val_loss: 0.5567 - val_acc: 0.7333\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5952 - acc: 0.6692 - val_loss: 0.5553 - val_acc: 0.7333\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5935 - acc: 0.6704 - val_loss: 0.5533 - val_acc: 0.7333\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5920 - acc: 0.6742 - val_loss: 0.5513 - val_acc: 0.7333\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5905 - acc: 0.6767 - val_loss: 0.5500 - val_acc: 0.7333\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5892 - acc: 0.6854 - val_loss: 0.5488 - val_acc: 0.7556\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5877 - acc: 0.6891 - val_loss: 0.5468 - val_acc: 0.7556\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5863 - acc: 0.6904 - val_loss: 0.5453 - val_acc: 0.7556\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5849 - acc: 0.6916 - val_loss: 0.5435 - val_acc: 0.7556\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5833 - acc: 0.6941 - val_loss: 0.5418 - val_acc: 0.7556\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5818 - acc: 0.6954 - val_loss: 0.5401 - val_acc: 0.7556\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5803 - acc: 0.6979 - val_loss: 0.5384 - val_acc: 0.7556\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5789 - acc: 0.6979 - val_loss: 0.5365 - val_acc: 0.7556\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5774 - acc: 0.6991 - val_loss: 0.5348 - val_acc: 0.7556\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5759 - acc: 0.7029 - val_loss: 0.5335 - val_acc: 0.7556\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5744 - acc: 0.7104 - val_loss: 0.5322 - val_acc: 0.7556\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5731 - acc: 0.7179 - val_loss: 0.5309 - val_acc: 0.7444\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5715 - acc: 0.7203 - val_loss: 0.5293 - val_acc: 0.7444\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5701 - acc: 0.7216 - val_loss: 0.5277 - val_acc: 0.7444\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5687 - acc: 0.7266 - val_loss: 0.5263 - val_acc: 0.7556\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5671 - acc: 0.7303 - val_loss: 0.5248 - val_acc: 0.7667\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5656 - acc: 0.7303 - val_loss: 0.5235 - val_acc: 0.7667\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5643 - acc: 0.7378 - val_loss: 0.5224 - val_acc: 0.7778\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5629 - acc: 0.7378 - val_loss: 0.5211 - val_acc: 0.7778\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5614 - acc: 0.7428 - val_loss: 0.5197 - val_acc: 0.7778\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5600 - acc: 0.7491 - val_loss: 0.5183 - val_acc: 0.7778\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5586 - acc: 0.7541 - val_loss: 0.5166 - val_acc: 0.7778\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5571 - acc: 0.7566 - val_loss: 0.5148 - val_acc: 0.7778\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5557 - acc: 0.7578 - val_loss: 0.5135 - val_acc: 0.7778\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5543 - acc: 0.7615 - val_loss: 0.5119 - val_acc: 0.7778\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5529 - acc: 0.7665 - val_loss: 0.5107 - val_acc: 0.7778\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5514 - acc: 0.7678 - val_loss: 0.5092 - val_acc: 0.7778\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5500 - acc: 0.7678 - val_loss: 0.5074 - val_acc: 0.7778\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5485 - acc: 0.7678 - val_loss: 0.5057 - val_acc: 0.7778\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5471 - acc: 0.7715 - val_loss: 0.5043 - val_acc: 0.7778\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5458 - acc: 0.7728 - val_loss: 0.5029 - val_acc: 0.7778\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5445 - acc: 0.7753 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5433 - acc: 0.7803 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 58us/step - loss: 0.5421 - acc: 0.7828 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5409 - acc: 0.7828 - val_loss: 0.4982 - val_acc: 0.8000\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5396 - acc: 0.7828 - val_loss: 0.4966 - val_acc: 0.8000\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5382 - acc: 0.7815 - val_loss: 0.4952 - val_acc: 0.8222\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5368 - acc: 0.7828 - val_loss: 0.4937 - val_acc: 0.8222\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5355 - acc: 0.7828 - val_loss: 0.4920 - val_acc: 0.8222\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5342 - acc: 0.7840 - val_loss: 0.4904 - val_acc: 0.8222\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5329 - acc: 0.7828 - val_loss: 0.4889 - val_acc: 0.8222\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5315 - acc: 0.7840 - val_loss: 0.4877 - val_acc: 0.8333\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5302 - acc: 0.7853 - val_loss: 0.4864 - val_acc: 0.8333\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5290 - acc: 0.7865 - val_loss: 0.4854 - val_acc: 0.8222\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5277 - acc: 0.7890 - val_loss: 0.4839 - val_acc: 0.8222\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5264 - acc: 0.7915 - val_loss: 0.4826 - val_acc: 0.8222\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5250 - acc: 0.7915 - val_loss: 0.4811 - val_acc: 0.8222\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5239 - acc: 0.7890 - val_loss: 0.4797 - val_acc: 0.8222\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5227 - acc: 0.7903 - val_loss: 0.4791 - val_acc: 0.8222\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5215 - acc: 0.7940 - val_loss: 0.4777 - val_acc: 0.8222\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5202 - acc: 0.7940 - val_loss: 0.4762 - val_acc: 0.8222\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5190 - acc: 0.7965 - val_loss: 0.4748 - val_acc: 0.8222\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5178 - acc: 0.7978 - val_loss: 0.4734 - val_acc: 0.8222\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5164 - acc: 0.7953 - val_loss: 0.4724 - val_acc: 0.8222\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5151 - acc: 0.7940 - val_loss: 0.4711 - val_acc: 0.8222\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5139 - acc: 0.7953 - val_loss: 0.4696 - val_acc: 0.8222\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5127 - acc: 0.7928 - val_loss: 0.4686 - val_acc: 0.8222\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5114 - acc: 0.7915 - val_loss: 0.4673 - val_acc: 0.8333\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5102 - acc: 0.7928 - val_loss: 0.4660 - val_acc: 0.8333\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5091 - acc: 0.7940 - val_loss: 0.4651 - val_acc: 0.8333\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5081 - acc: 0.7940 - val_loss: 0.4639 - val_acc: 0.8333\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5070 - acc: 0.7953 - val_loss: 0.4628 - val_acc: 0.8333\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5059 - acc: 0.7965 - val_loss: 0.4619 - val_acc: 0.8444\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5047 - acc: 0.7965 - val_loss: 0.4607 - val_acc: 0.8444\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5036 - acc: 0.7965 - val_loss: 0.4596 - val_acc: 0.8444\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5024 - acc: 0.7965 - val_loss: 0.4587 - val_acc: 0.8444\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5013 - acc: 0.7965 - val_loss: 0.4574 - val_acc: 0.8444\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5001 - acc: 0.7965 - val_loss: 0.4563 - val_acc: 0.8444\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4989 - acc: 0.7965 - val_loss: 0.4553 - val_acc: 0.8444\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4978 - acc: 0.7978 - val_loss: 0.4542 - val_acc: 0.8444\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4968 - acc: 0.7978 - val_loss: 0.4531 - val_acc: 0.8444\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4957 - acc: 0.7978 - val_loss: 0.4521 - val_acc: 0.8444\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4946 - acc: 0.8002 - val_loss: 0.4515 - val_acc: 0.8444\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4936 - acc: 0.8015 - val_loss: 0.4503 - val_acc: 0.8444\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4924 - acc: 0.8040 - val_loss: 0.4493 - val_acc: 0.8444\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4913 - acc: 0.8065 - val_loss: 0.4483 - val_acc: 0.8444\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4903 - acc: 0.8077 - val_loss: 0.4477 - val_acc: 0.8444\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4892 - acc: 0.8090 - val_loss: 0.4467 - val_acc: 0.8444\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4882 - acc: 0.8102 - val_loss: 0.4458 - val_acc: 0.8556\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4871 - acc: 0.8102 - val_loss: 0.4449 - val_acc: 0.8556\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.4862 - acc: 0.8127 - val_loss: 0.4446 - val_acc: 0.8556\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.4853 - acc: 0.8177 - val_loss: 0.4441 - val_acc: 0.8556\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4843 - acc: 0.8177 - val_loss: 0.4428 - val_acc: 0.8556\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4833 - acc: 0.8177 - val_loss: 0.4417 - val_acc: 0.8556\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4823 - acc: 0.8177 - val_loss: 0.4407 - val_acc: 0.8556\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4813 - acc: 0.8177 - val_loss: 0.4396 - val_acc: 0.8556\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4803 - acc: 0.8165 - val_loss: 0.4386 - val_acc: 0.8556\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4793 - acc: 0.8165 - val_loss: 0.4378 - val_acc: 0.8556\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4783 - acc: 0.8165 - val_loss: 0.4371 - val_acc: 0.8778\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4774 - acc: 0.8165 - val_loss: 0.4359 - val_acc: 0.8667\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.4764 - acc: 0.8165 - val_loss: 0.4349 - val_acc: 0.8667\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4755 - acc: 0.8165 - val_loss: 0.4339 - val_acc: 0.8667\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4747 - acc: 0.8177 - val_loss: 0.4339 - val_acc: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4739 - acc: 0.8227 - val_loss: 0.4329 - val_acc: 0.8778\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4729 - acc: 0.8215 - val_loss: 0.4320 - val_acc: 0.8778\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4720 - acc: 0.8215 - val_loss: 0.4308 - val_acc: 0.8667\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4711 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8778\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4701 - acc: 0.8227 - val_loss: 0.4291 - val_acc: 0.8778\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4693 - acc: 0.8227 - val_loss: 0.4282 - val_acc: 0.8778\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4685 - acc: 0.8227 - val_loss: 0.4273 - val_acc: 0.8778\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4676 - acc: 0.8227 - val_loss: 0.4265 - val_acc: 0.8778\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4667 - acc: 0.8227 - val_loss: 0.4256 - val_acc: 0.8778\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4658 - acc: 0.8227 - val_loss: 0.4249 - val_acc: 0.8778\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4649 - acc: 0.8252 - val_loss: 0.4246 - val_acc: 0.8778\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4640 - acc: 0.8277 - val_loss: 0.4238 - val_acc: 0.8778\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4632 - acc: 0.8277 - val_loss: 0.4231 - val_acc: 0.8667\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4624 - acc: 0.8265 - val_loss: 0.4224 - val_acc: 0.8667\n",
      "Epoch 171/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4616 - acc: 0.8265 - val_loss: 0.4220 - val_acc: 0.8667\n",
      "Epoch 172/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4609 - acc: 0.8290 - val_loss: 0.4214 - val_acc: 0.8667\n",
      "Epoch 173/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4599 - acc: 0.8290 - val_loss: 0.4207 - val_acc: 0.8667\n",
      "Epoch 174/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4590 - acc: 0.8302 - val_loss: 0.4197 - val_acc: 0.8667\n",
      "Epoch 175/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4583 - acc: 0.8302 - val_loss: 0.4187 - val_acc: 0.8667\n",
      "Epoch 176/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4575 - acc: 0.8302 - val_loss: 0.4181 - val_acc: 0.8667\n",
      "Epoch 177/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4567 - acc: 0.8302 - val_loss: 0.4173 - val_acc: 0.8667\n",
      "Epoch 178/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4559 - acc: 0.8302 - val_loss: 0.4166 - val_acc: 0.8667\n",
      "Epoch 179/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4551 - acc: 0.8302 - val_loss: 0.4155 - val_acc: 0.8667\n",
      "Epoch 180/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4543 - acc: 0.8302 - val_loss: 0.4149 - val_acc: 0.8667\n",
      "Epoch 181/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4536 - acc: 0.8327 - val_loss: 0.4145 - val_acc: 0.8667\n",
      "Epoch 182/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4527 - acc: 0.8327 - val_loss: 0.4136 - val_acc: 0.8667\n",
      "Epoch 183/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4520 - acc: 0.8327 - val_loss: 0.4128 - val_acc: 0.8667\n",
      "Epoch 184/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4513 - acc: 0.8340 - val_loss: 0.4121 - val_acc: 0.8667\n",
      "Epoch 185/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4505 - acc: 0.8340 - val_loss: 0.4118 - val_acc: 0.8667\n",
      "Epoch 186/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4498 - acc: 0.8315 - val_loss: 0.4110 - val_acc: 0.8667\n",
      "Epoch 187/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4491 - acc: 0.8315 - val_loss: 0.4102 - val_acc: 0.8667\n",
      "Epoch 188/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4484 - acc: 0.8315 - val_loss: 0.4094 - val_acc: 0.8667\n",
      "Epoch 189/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4477 - acc: 0.8315 - val_loss: 0.4088 - val_acc: 0.8667\n",
      "Epoch 190/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4469 - acc: 0.8315 - val_loss: 0.4083 - val_acc: 0.8667\n",
      "Epoch 191/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4462 - acc: 0.8315 - val_loss: 0.4079 - val_acc: 0.8556\n",
      "Epoch 192/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4455 - acc: 0.8327 - val_loss: 0.4083 - val_acc: 0.8556\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 0.7885 - acc: 0.3608 - val_loss: 0.8239 - val_acc: 0.3000\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.7800 - acc: 0.3571 - val_loss: 0.8139 - val_acc: 0.2889\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.7717 - acc: 0.3571 - val_loss: 0.8039 - val_acc: 0.2889\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.7641 - acc: 0.3645 - val_loss: 0.7947 - val_acc: 0.2889\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.7566 - acc: 0.3620 - val_loss: 0.7855 - val_acc: 0.2667\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.7496 - acc: 0.3596 - val_loss: 0.7776 - val_acc: 0.2778\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.7427 - acc: 0.3670 - val_loss: 0.7687 - val_acc: 0.2556\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.7365 - acc: 0.3708 - val_loss: 0.7615 - val_acc: 0.2556\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.7302 - acc: 0.3695 - val_loss: 0.7534 - val_acc: 0.2556\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.7241 - acc: 0.3733 - val_loss: 0.7458 - val_acc: 0.2444\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.7180 - acc: 0.3820 - val_loss: 0.7387 - val_acc: 0.2556\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.7126 - acc: 0.3908 - val_loss: 0.7314 - val_acc: 0.3000\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.7070 - acc: 0.4120 - val_loss: 0.7250 - val_acc: 0.3000\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.7019 - acc: 0.4257 - val_loss: 0.7185 - val_acc: 0.3333\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6974 - acc: 0.4657 - val_loss: 0.7133 - val_acc: 0.4111\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6930 - acc: 0.5343 - val_loss: 0.7079 - val_acc: 0.4778\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6890 - acc: 0.5830 - val_loss: 0.7029 - val_acc: 0.5556\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6849 - acc: 0.6155 - val_loss: 0.6975 - val_acc: 0.6000\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 73us/step - loss: 0.6807 - acc: 0.6267 - val_loss: 0.6923 - val_acc: 0.6111\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6767 - acc: 0.6542 - val_loss: 0.6870 - val_acc: 0.6333\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6731 - acc: 0.6692 - val_loss: 0.6830 - val_acc: 0.6444\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6699 - acc: 0.6729 - val_loss: 0.6789 - val_acc: 0.6444\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6665 - acc: 0.6792 - val_loss: 0.6743 - val_acc: 0.6556\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6631 - acc: 0.6829 - val_loss: 0.6704 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6599 - acc: 0.6816 - val_loss: 0.6666 - val_acc: 0.6556\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6572 - acc: 0.6829 - val_loss: 0.6634 - val_acc: 0.6444\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6545 - acc: 0.6841 - val_loss: 0.6601 - val_acc: 0.6556\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6518 - acc: 0.6866 - val_loss: 0.6568 - val_acc: 0.6556\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6489 - acc: 0.6891 - val_loss: 0.6529 - val_acc: 0.6556\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6461 - acc: 0.6854 - val_loss: 0.6493 - val_acc: 0.6556\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6431 - acc: 0.6767 - val_loss: 0.6456 - val_acc: 0.6556\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6405 - acc: 0.6742 - val_loss: 0.6426 - val_acc: 0.6556\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6379 - acc: 0.6792 - val_loss: 0.6393 - val_acc: 0.6556\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6358 - acc: 0.6767 - val_loss: 0.6368 - val_acc: 0.6556\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6332 - acc: 0.6717 - val_loss: 0.6333 - val_acc: 0.6444\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6306 - acc: 0.6679 - val_loss: 0.6300 - val_acc: 0.6444\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6281 - acc: 0.6617 - val_loss: 0.6270 - val_acc: 0.6444\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6258 - acc: 0.6642 - val_loss: 0.6243 - val_acc: 0.6444\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6234 - acc: 0.6642 - val_loss: 0.6213 - val_acc: 0.6444\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6211 - acc: 0.6692 - val_loss: 0.6187 - val_acc: 0.6444\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6191 - acc: 0.6704 - val_loss: 0.6167 - val_acc: 0.6444\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6171 - acc: 0.6729 - val_loss: 0.6142 - val_acc: 0.6444\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6150 - acc: 0.6704 - val_loss: 0.6114 - val_acc: 0.6444\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6128 - acc: 0.6717 - val_loss: 0.6085 - val_acc: 0.6444\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6106 - acc: 0.6729 - val_loss: 0.6059 - val_acc: 0.6444\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6085 - acc: 0.6717 - val_loss: 0.6033 - val_acc: 0.6444\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6065 - acc: 0.6717 - val_loss: 0.6008 - val_acc: 0.6556\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6045 - acc: 0.6704 - val_loss: 0.5982 - val_acc: 0.6556\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6026 - acc: 0.6742 - val_loss: 0.5964 - val_acc: 0.6556\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6009 - acc: 0.6792 - val_loss: 0.5946 - val_acc: 0.6667\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5989 - acc: 0.6854 - val_loss: 0.5923 - val_acc: 0.6778\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5969 - acc: 0.6879 - val_loss: 0.5901 - val_acc: 0.6667\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5950 - acc: 0.6991 - val_loss: 0.5881 - val_acc: 0.6556\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.5931 - acc: 0.7004 - val_loss: 0.5857 - val_acc: 0.6778\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5912 - acc: 0.7004 - val_loss: 0.5832 - val_acc: 0.6778\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5893 - acc: 0.7029 - val_loss: 0.5813 - val_acc: 0.6667\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5875 - acc: 0.7029 - val_loss: 0.5787 - val_acc: 0.6889\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5855 - acc: 0.7029 - val_loss: 0.5766 - val_acc: 0.7000\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5837 - acc: 0.7016 - val_loss: 0.5742 - val_acc: 0.7000\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5818 - acc: 0.7054 - val_loss: 0.5722 - val_acc: 0.7000\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5800 - acc: 0.7104 - val_loss: 0.5701 - val_acc: 0.7000\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5781 - acc: 0.7116 - val_loss: 0.5680 - val_acc: 0.7000\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5765 - acc: 0.7154 - val_loss: 0.5666 - val_acc: 0.6889\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5749 - acc: 0.7216 - val_loss: 0.5645 - val_acc: 0.6889\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5731 - acc: 0.7253 - val_loss: 0.5628 - val_acc: 0.6889\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5713 - acc: 0.7291 - val_loss: 0.5607 - val_acc: 0.7000\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5696 - acc: 0.7291 - val_loss: 0.5587 - val_acc: 0.7000\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.5679 - acc: 0.7328 - val_loss: 0.5570 - val_acc: 0.6889\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5661 - acc: 0.7341 - val_loss: 0.5554 - val_acc: 0.7000\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5647 - acc: 0.7378 - val_loss: 0.5542 - val_acc: 0.7111\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5631 - acc: 0.7403 - val_loss: 0.5523 - val_acc: 0.7111\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5615 - acc: 0.7403 - val_loss: 0.5504 - val_acc: 0.7111\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5599 - acc: 0.7403 - val_loss: 0.5490 - val_acc: 0.7111\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5585 - acc: 0.7416 - val_loss: 0.5479 - val_acc: 0.7222\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5568 - acc: 0.7453 - val_loss: 0.5461 - val_acc: 0.7333\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5551 - acc: 0.7491 - val_loss: 0.5442 - val_acc: 0.7333\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5536 - acc: 0.7553 - val_loss: 0.5426 - val_acc: 0.7556\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5523 - acc: 0.7628 - val_loss: 0.5418 - val_acc: 0.7556\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5508 - acc: 0.7640 - val_loss: 0.5401 - val_acc: 0.7667\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5493 - acc: 0.7640 - val_loss: 0.5381 - val_acc: 0.7667\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5476 - acc: 0.7640 - val_loss: 0.5367 - val_acc: 0.7667\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5461 - acc: 0.7665 - val_loss: 0.5352 - val_acc: 0.7778\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5446 - acc: 0.7728 - val_loss: 0.5338 - val_acc: 0.7778\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5431 - acc: 0.7740 - val_loss: 0.5321 - val_acc: 0.7778\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 53us/step - loss: 0.5417 - acc: 0.7765 - val_loss: 0.5308 - val_acc: 0.7778\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5402 - acc: 0.7790 - val_loss: 0.5290 - val_acc: 0.7778\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5387 - acc: 0.7790 - val_loss: 0.5272 - val_acc: 0.7778\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5372 - acc: 0.7778 - val_loss: 0.5253 - val_acc: 0.7778\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5357 - acc: 0.7765 - val_loss: 0.5235 - val_acc: 0.7778\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5342 - acc: 0.7778 - val_loss: 0.5219 - val_acc: 0.7778\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5329 - acc: 0.7853 - val_loss: 0.5207 - val_acc: 0.7778\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5314 - acc: 0.7865 - val_loss: 0.5192 - val_acc: 0.7889\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5302 - acc: 0.7878 - val_loss: 0.5184 - val_acc: 0.8000\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5290 - acc: 0.7928 - val_loss: 0.5172 - val_acc: 0.8000\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5277 - acc: 0.7890 - val_loss: 0.5155 - val_acc: 0.8000\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5263 - acc: 0.7915 - val_loss: 0.5141 - val_acc: 0.8000\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5249 - acc: 0.7903 - val_loss: 0.5127 - val_acc: 0.8000\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5235 - acc: 0.7978 - val_loss: 0.5115 - val_acc: 0.8111\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5221 - acc: 0.7990 - val_loss: 0.5101 - val_acc: 0.8111\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5209 - acc: 0.8002 - val_loss: 0.5085 - val_acc: 0.8111\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5196 - acc: 0.8002 - val_loss: 0.5070 - val_acc: 0.8111\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5183 - acc: 0.8040 - val_loss: 0.5064 - val_acc: 0.8111\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5172 - acc: 0.8040 - val_loss: 0.5050 - val_acc: 0.8111\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5162 - acc: 0.8040 - val_loss: 0.5044 - val_acc: 0.8111\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5150 - acc: 0.8077 - val_loss: 0.5031 - val_acc: 0.8111\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5137 - acc: 0.8102 - val_loss: 0.5017 - val_acc: 0.8111\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5123 - acc: 0.8127 - val_loss: 0.5000 - val_acc: 0.8111\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5111 - acc: 0.8127 - val_loss: 0.4987 - val_acc: 0.8111\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5098 - acc: 0.8140 - val_loss: 0.4975 - val_acc: 0.8111\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5085 - acc: 0.8127 - val_loss: 0.4961 - val_acc: 0.8111\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5073 - acc: 0.8127 - val_loss: 0.4948 - val_acc: 0.8111\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5060 - acc: 0.8115 - val_loss: 0.4941 - val_acc: 0.8222\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5048 - acc: 0.8115 - val_loss: 0.4930 - val_acc: 0.8222\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5038 - acc: 0.8152 - val_loss: 0.4915 - val_acc: 0.8222\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5025 - acc: 0.8165 - val_loss: 0.4900 - val_acc: 0.8222\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5014 - acc: 0.8127 - val_loss: 0.4886 - val_acc: 0.8222\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5002 - acc: 0.8177 - val_loss: 0.4877 - val_acc: 0.8222\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4990 - acc: 0.8190 - val_loss: 0.4864 - val_acc: 0.8222\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4979 - acc: 0.8202 - val_loss: 0.4851 - val_acc: 0.8222\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4969 - acc: 0.8202 - val_loss: 0.4845 - val_acc: 0.8333\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4959 - acc: 0.8202 - val_loss: 0.4831 - val_acc: 0.8222\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4948 - acc: 0.8227 - val_loss: 0.4819 - val_acc: 0.8222\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4938 - acc: 0.8227 - val_loss: 0.4811 - val_acc: 0.8333\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4926 - acc: 0.8227 - val_loss: 0.4801 - val_acc: 0.8444\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4915 - acc: 0.8227 - val_loss: 0.4792 - val_acc: 0.8444\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4904 - acc: 0.8240 - val_loss: 0.4779 - val_acc: 0.8444\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4893 - acc: 0.8240 - val_loss: 0.4772 - val_acc: 0.8444\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4883 - acc: 0.8240 - val_loss: 0.4758 - val_acc: 0.8444\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4872 - acc: 0.8252 - val_loss: 0.4747 - val_acc: 0.8444\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4861 - acc: 0.8252 - val_loss: 0.4736 - val_acc: 0.8444\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4852 - acc: 0.8290 - val_loss: 0.4730 - val_acc: 0.8444\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4843 - acc: 0.8277 - val_loss: 0.4717 - val_acc: 0.8444\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4832 - acc: 0.8277 - val_loss: 0.4707 - val_acc: 0.8444\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4822 - acc: 0.8315 - val_loss: 0.4700 - val_acc: 0.8556\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4812 - acc: 0.8315 - val_loss: 0.4690 - val_acc: 0.8556\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4804 - acc: 0.8315 - val_loss: 0.4680 - val_acc: 0.8444\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4795 - acc: 0.8327 - val_loss: 0.4672 - val_acc: 0.8556\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4785 - acc: 0.8327 - val_loss: 0.4661 - val_acc: 0.8556\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4775 - acc: 0.8340 - val_loss: 0.4652 - val_acc: 0.8556\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4766 - acc: 0.8327 - val_loss: 0.4640 - val_acc: 0.8556\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4756 - acc: 0.8327 - val_loss: 0.4629 - val_acc: 0.8556\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4747 - acc: 0.8327 - val_loss: 0.4618 - val_acc: 0.8556\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4737 - acc: 0.8340 - val_loss: 0.4608 - val_acc: 0.8556\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4728 - acc: 0.8327 - val_loss: 0.4598 - val_acc: 0.8556\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 61us/step - loss: 0.4719 - acc: 0.8315 - val_loss: 0.4586 - val_acc: 0.8444\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4710 - acc: 0.8340 - val_loss: 0.4576 - val_acc: 0.8556\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4701 - acc: 0.8327 - val_loss: 0.4567 - val_acc: 0.8556\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4693 - acc: 0.8327 - val_loss: 0.4557 - val_acc: 0.8556\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4683 - acc: 0.8327 - val_loss: 0.4547 - val_acc: 0.8556\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4675 - acc: 0.8327 - val_loss: 0.4537 - val_acc: 0.8556\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4666 - acc: 0.8340 - val_loss: 0.4529 - val_acc: 0.8556\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4657 - acc: 0.8377 - val_loss: 0.4521 - val_acc: 0.8556\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4648 - acc: 0.8377 - val_loss: 0.4512 - val_acc: 0.8556\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4639 - acc: 0.8365 - val_loss: 0.4504 - val_acc: 0.8556\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4630 - acc: 0.8377 - val_loss: 0.4495 - val_acc: 0.8556\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4622 - acc: 0.8377 - val_loss: 0.4486 - val_acc: 0.8556\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4613 - acc: 0.8365 - val_loss: 0.4480 - val_acc: 0.8556\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4604 - acc: 0.8365 - val_loss: 0.4471 - val_acc: 0.8556\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4596 - acc: 0.8377 - val_loss: 0.4460 - val_acc: 0.8556\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4588 - acc: 0.8377 - val_loss: 0.4453 - val_acc: 0.8556\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4580 - acc: 0.8377 - val_loss: 0.4444 - val_acc: 0.8556\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4572 - acc: 0.8365 - val_loss: 0.4437 - val_acc: 0.8556\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4564 - acc: 0.8390 - val_loss: 0.4429 - val_acc: 0.8556\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4556 - acc: 0.8377 - val_loss: 0.4422 - val_acc: 0.8556\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4549 - acc: 0.8377 - val_loss: 0.4414 - val_acc: 0.8556\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4542 - acc: 0.8377 - val_loss: 0.4405 - val_acc: 0.8556\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4535 - acc: 0.8390 - val_loss: 0.4398 - val_acc: 0.8556\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4527 - acc: 0.8377 - val_loss: 0.4394 - val_acc: 0.8556\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4519 - acc: 0.8377 - val_loss: 0.4387 - val_acc: 0.8556\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4511 - acc: 0.8365 - val_loss: 0.4382 - val_acc: 0.8556\n",
      "Epoch 171/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4503 - acc: 0.8365 - val_loss: 0.4373 - val_acc: 0.8556\n",
      "Epoch 172/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4497 - acc: 0.8377 - val_loss: 0.4365 - val_acc: 0.8556\n",
      "Epoch 173/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4489 - acc: 0.8377 - val_loss: 0.4358 - val_acc: 0.8556\n",
      "Epoch 174/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4481 - acc: 0.8352 - val_loss: 0.4351 - val_acc: 0.8556\n",
      "Epoch 175/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4474 - acc: 0.8377 - val_loss: 0.4345 - val_acc: 0.8556\n",
      "Epoch 176/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4466 - acc: 0.8402 - val_loss: 0.4340 - val_acc: 0.8556\n",
      "Epoch 177/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4459 - acc: 0.8402 - val_loss: 0.4331 - val_acc: 0.8556\n",
      "Epoch 178/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4452 - acc: 0.8414 - val_loss: 0.4326 - val_acc: 0.8556\n",
      "Epoch 179/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4445 - acc: 0.8414 - val_loss: 0.4318 - val_acc: 0.8556\n",
      "Epoch 180/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4438 - acc: 0.8427 - val_loss: 0.4310 - val_acc: 0.8556\n",
      "Epoch 181/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4431 - acc: 0.8427 - val_loss: 0.4304 - val_acc: 0.8556\n",
      "Epoch 182/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4424 - acc: 0.8464 - val_loss: 0.4302 - val_acc: 0.8556\n",
      "Epoch 183/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4417 - acc: 0.8452 - val_loss: 0.4295 - val_acc: 0.8556\n",
      "Epoch 184/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4410 - acc: 0.8452 - val_loss: 0.4287 - val_acc: 0.8556\n",
      "Epoch 185/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4404 - acc: 0.8452 - val_loss: 0.4279 - val_acc: 0.8556\n",
      "Epoch 186/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4398 - acc: 0.8452 - val_loss: 0.4271 - val_acc: 0.8556\n",
      "Epoch 187/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4391 - acc: 0.8464 - val_loss: 0.4269 - val_acc: 0.8556\n",
      "Epoch 188/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4384 - acc: 0.8464 - val_loss: 0.4264 - val_acc: 0.8556\n",
      "Epoch 189/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4378 - acc: 0.8464 - val_loss: 0.4256 - val_acc: 0.8556\n",
      "Epoch 190/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4371 - acc: 0.8439 - val_loss: 0.4255 - val_acc: 0.8556\n",
      "Epoch 191/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4364 - acc: 0.8439 - val_loss: 0.4252 - val_acc: 0.8444\n",
      "Epoch 192/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4358 - acc: 0.8439 - val_loss: 0.4245 - val_acc: 0.8444\n",
      "Epoch 193/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4351 - acc: 0.8439 - val_loss: 0.4238 - val_acc: 0.8444\n",
      "Epoch 194/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4344 - acc: 0.8439 - val_loss: 0.4238 - val_acc: 0.8444\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 0.6856 - acc: 0.5343 - val_loss: 0.6838 - val_acc: 0.5889\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6812 - acc: 0.5705 - val_loss: 0.6791 - val_acc: 0.6111\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6769 - acc: 0.5905 - val_loss: 0.6739 - val_acc: 0.6222\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6725 - acc: 0.6117 - val_loss: 0.6690 - val_acc: 0.6333\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6687 - acc: 0.6317 - val_loss: 0.6642 - val_acc: 0.6444\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6647 - acc: 0.6392 - val_loss: 0.6600 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6610 - acc: 0.6429 - val_loss: 0.6559 - val_acc: 0.6556\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6576 - acc: 0.6442 - val_loss: 0.6517 - val_acc: 0.6667\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6543 - acc: 0.6542 - val_loss: 0.6482 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6514 - acc: 0.6579 - val_loss: 0.6447 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6485 - acc: 0.6554 - val_loss: 0.6414 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6456 - acc: 0.6554 - val_loss: 0.6383 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6428 - acc: 0.6542 - val_loss: 0.6349 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6401 - acc: 0.6554 - val_loss: 0.6317 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6376 - acc: 0.6554 - val_loss: 0.6292 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6352 - acc: 0.6567 - val_loss: 0.6258 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6326 - acc: 0.6567 - val_loss: 0.6229 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6301 - acc: 0.6579 - val_loss: 0.6200 - val_acc: 0.6667\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6276 - acc: 0.6592 - val_loss: 0.6171 - val_acc: 0.6667\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6252 - acc: 0.6592 - val_loss: 0.6142 - val_acc: 0.6667\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6228 - acc: 0.6629 - val_loss: 0.6114 - val_acc: 0.6667\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6206 - acc: 0.6642 - val_loss: 0.6086 - val_acc: 0.6778\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6182 - acc: 0.6679 - val_loss: 0.6061 - val_acc: 0.6778\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6161 - acc: 0.6704 - val_loss: 0.6039 - val_acc: 0.6667\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6141 - acc: 0.6754 - val_loss: 0.6018 - val_acc: 0.6667\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6119 - acc: 0.6779 - val_loss: 0.5996 - val_acc: 0.6778\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6097 - acc: 0.6829 - val_loss: 0.5971 - val_acc: 0.6889\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6075 - acc: 0.6854 - val_loss: 0.5948 - val_acc: 0.6889\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6053 - acc: 0.6891 - val_loss: 0.5922 - val_acc: 0.6889\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6032 - acc: 0.6916 - val_loss: 0.5900 - val_acc: 0.6889\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6011 - acc: 0.6916 - val_loss: 0.5876 - val_acc: 0.7000\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5990 - acc: 0.6929 - val_loss: 0.5853 - val_acc: 0.7000\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5971 - acc: 0.6941 - val_loss: 0.5831 - val_acc: 0.7000\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5952 - acc: 0.6941 - val_loss: 0.5805 - val_acc: 0.7000\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5930 - acc: 0.6966 - val_loss: 0.5784 - val_acc: 0.7000\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5913 - acc: 0.6979 - val_loss: 0.5767 - val_acc: 0.7111\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5896 - acc: 0.7041 - val_loss: 0.5751 - val_acc: 0.7111\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5877 - acc: 0.7079 - val_loss: 0.5730 - val_acc: 0.7222\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5858 - acc: 0.7129 - val_loss: 0.5710 - val_acc: 0.7333\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5837 - acc: 0.7129 - val_loss: 0.5686 - val_acc: 0.7333\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5817 - acc: 0.7141 - val_loss: 0.5664 - val_acc: 0.7556\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5797 - acc: 0.7141 - val_loss: 0.5643 - val_acc: 0.7556\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5779 - acc: 0.7228 - val_loss: 0.5626 - val_acc: 0.7556\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5761 - acc: 0.7253 - val_loss: 0.5606 - val_acc: 0.7667\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5742 - acc: 0.7266 - val_loss: 0.5583 - val_acc: 0.7667\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5723 - acc: 0.7291 - val_loss: 0.5562 - val_acc: 0.7667\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5704 - acc: 0.7303 - val_loss: 0.5541 - val_acc: 0.7667\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5685 - acc: 0.7316 - val_loss: 0.5520 - val_acc: 0.7667\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5666 - acc: 0.7341 - val_loss: 0.5499 - val_acc: 0.7667\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5648 - acc: 0.7353 - val_loss: 0.5478 - val_acc: 0.7667\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5629 - acc: 0.7428 - val_loss: 0.5458 - val_acc: 0.7667\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5609 - acc: 0.7466 - val_loss: 0.5440 - val_acc: 0.7778\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5591 - acc: 0.7478 - val_loss: 0.5420 - val_acc: 0.7778\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5573 - acc: 0.7478 - val_loss: 0.5399 - val_acc: 0.7889\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5555 - acc: 0.7503 - val_loss: 0.5378 - val_acc: 0.7889\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5534 - acc: 0.7578 - val_loss: 0.5358 - val_acc: 0.7889\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5516 - acc: 0.7566 - val_loss: 0.5337 - val_acc: 0.7889\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5497 - acc: 0.7591 - val_loss: 0.5318 - val_acc: 0.8000\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5480 - acc: 0.7653 - val_loss: 0.5303 - val_acc: 0.7889\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5462 - acc: 0.7653 - val_loss: 0.5284 - val_acc: 0.8000\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5445 - acc: 0.7653 - val_loss: 0.5268 - val_acc: 0.8000\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5430 - acc: 0.7690 - val_loss: 0.5256 - val_acc: 0.8111\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5414 - acc: 0.7703 - val_loss: 0.5236 - val_acc: 0.8111\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5397 - acc: 0.7703 - val_loss: 0.5216 - val_acc: 0.8111\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5380 - acc: 0.7703 - val_loss: 0.5200 - val_acc: 0.8111\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5363 - acc: 0.7703 - val_loss: 0.5182 - val_acc: 0.8222\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5347 - acc: 0.7715 - val_loss: 0.5167 - val_acc: 0.8222\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5332 - acc: 0.7728 - val_loss: 0.5152 - val_acc: 0.8222\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5316 - acc: 0.7765 - val_loss: 0.5138 - val_acc: 0.8222\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5300 - acc: 0.7790 - val_loss: 0.5119 - val_acc: 0.8222\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 60us/step - loss: 0.5283 - acc: 0.7790 - val_loss: 0.5100 - val_acc: 0.8222\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5266 - acc: 0.7840 - val_loss: 0.5083 - val_acc: 0.8111\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5250 - acc: 0.7853 - val_loss: 0.5065 - val_acc: 0.8111\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5233 - acc: 0.7853 - val_loss: 0.5049 - val_acc: 0.8111\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5218 - acc: 0.7865 - val_loss: 0.5031 - val_acc: 0.8111\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5201 - acc: 0.7878 - val_loss: 0.5014 - val_acc: 0.8111\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5186 - acc: 0.7878 - val_loss: 0.4997 - val_acc: 0.8111\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5171 - acc: 0.7890 - val_loss: 0.4981 - val_acc: 0.8111\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5156 - acc: 0.7878 - val_loss: 0.4966 - val_acc: 0.8111\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5141 - acc: 0.7890 - val_loss: 0.4949 - val_acc: 0.8111\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5126 - acc: 0.7890 - val_loss: 0.4933 - val_acc: 0.8111\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5111 - acc: 0.7878 - val_loss: 0.4917 - val_acc: 0.8111\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5097 - acc: 0.7878 - val_loss: 0.4901 - val_acc: 0.8111\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5084 - acc: 0.7890 - val_loss: 0.4885 - val_acc: 0.8111\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5069 - acc: 0.7878 - val_loss: 0.4870 - val_acc: 0.8111\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5055 - acc: 0.7878 - val_loss: 0.4855 - val_acc: 0.8111\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5043 - acc: 0.7890 - val_loss: 0.4847 - val_acc: 0.8111\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5029 - acc: 0.7903 - val_loss: 0.4835 - val_acc: 0.8111\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.5014 - acc: 0.7903 - val_loss: 0.4820 - val_acc: 0.8111\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.5001 - acc: 0.7903 - val_loss: 0.4805 - val_acc: 0.8111\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.4990 - acc: 0.7915 - val_loss: 0.4789 - val_acc: 0.8111\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.4976 - acc: 0.7928 - val_loss: 0.4779 - val_acc: 0.8111\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4961 - acc: 0.7928 - val_loss: 0.4763 - val_acc: 0.8111\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4946 - acc: 0.7953 - val_loss: 0.4752 - val_acc: 0.8111\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4935 - acc: 0.7965 - val_loss: 0.4737 - val_acc: 0.8111\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4921 - acc: 0.8002 - val_loss: 0.4725 - val_acc: 0.8222\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.4908 - acc: 0.8015 - val_loss: 0.4710 - val_acc: 0.8222\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4895 - acc: 0.7990 - val_loss: 0.4696 - val_acc: 0.8222\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4883 - acc: 0.8027 - val_loss: 0.4687 - val_acc: 0.8333\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4870 - acc: 0.8052 - val_loss: 0.4674 - val_acc: 0.8333\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4858 - acc: 0.8065 - val_loss: 0.4661 - val_acc: 0.8333\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4846 - acc: 0.8077 - val_loss: 0.4650 - val_acc: 0.8333\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.4835 - acc: 0.8077 - val_loss: 0.4643 - val_acc: 0.8333\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4827 - acc: 0.8102 - val_loss: 0.4640 - val_acc: 0.8333\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4817 - acc: 0.8102 - val_loss: 0.4634 - val_acc: 0.8333\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.4807 - acc: 0.8102 - val_loss: 0.4621 - val_acc: 0.8333\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4795 - acc: 0.8115 - val_loss: 0.4613 - val_acc: 0.8333\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4785 - acc: 0.8127 - val_loss: 0.4600 - val_acc: 0.8333\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4774 - acc: 0.8127 - val_loss: 0.4591 - val_acc: 0.8333\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4763 - acc: 0.8127 - val_loss: 0.4578 - val_acc: 0.8333\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4752 - acc: 0.8115 - val_loss: 0.4565 - val_acc: 0.8333\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4741 - acc: 0.8127 - val_loss: 0.4555 - val_acc: 0.8333\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4731 - acc: 0.8165 - val_loss: 0.4547 - val_acc: 0.8333\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4722 - acc: 0.8190 - val_loss: 0.4538 - val_acc: 0.8333\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4711 - acc: 0.8190 - val_loss: 0.4528 - val_acc: 0.8444\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4700 - acc: 0.8190 - val_loss: 0.4516 - val_acc: 0.8444\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4690 - acc: 0.8190 - val_loss: 0.4506 - val_acc: 0.8444\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4681 - acc: 0.8202 - val_loss: 0.4497 - val_acc: 0.8444\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4670 - acc: 0.8202 - val_loss: 0.4485 - val_acc: 0.8444\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4660 - acc: 0.8202 - val_loss: 0.4475 - val_acc: 0.8444\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4650 - acc: 0.8202 - val_loss: 0.4466 - val_acc: 0.8333\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 82us/step - loss: 0.4641 - acc: 0.8202 - val_loss: 0.4455 - val_acc: 0.8333\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.4631 - acc: 0.8202 - val_loss: 0.4446 - val_acc: 0.8333\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4622 - acc: 0.8190 - val_loss: 0.4437 - val_acc: 0.8333\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 93us/step - loss: 0.4613 - acc: 0.8202 - val_loss: 0.4426 - val_acc: 0.8333\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 96us/step - loss: 0.4603 - acc: 0.8215 - val_loss: 0.4418 - val_acc: 0.8222\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.4593 - acc: 0.8202 - val_loss: 0.4409 - val_acc: 0.8222\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4585 - acc: 0.8215 - val_loss: 0.4399 - val_acc: 0.8222\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4576 - acc: 0.8202 - val_loss: 0.4390 - val_acc: 0.8222\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4568 - acc: 0.8202 - val_loss: 0.4381 - val_acc: 0.8222\n",
      "Epoch 131/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 62us/step - loss: 0.4559 - acc: 0.8202 - val_loss: 0.4373 - val_acc: 0.8222\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4550 - acc: 0.8202 - val_loss: 0.4365 - val_acc: 0.8222\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4542 - acc: 0.8215 - val_loss: 0.4356 - val_acc: 0.8222\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4534 - acc: 0.8190 - val_loss: 0.4350 - val_acc: 0.8222\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4525 - acc: 0.8215 - val_loss: 0.4341 - val_acc: 0.8222\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4516 - acc: 0.8215 - val_loss: 0.4334 - val_acc: 0.8222\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4508 - acc: 0.8215 - val_loss: 0.4326 - val_acc: 0.8222\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4499 - acc: 0.8215 - val_loss: 0.4320 - val_acc: 0.8222\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4491 - acc: 0.8240 - val_loss: 0.4313 - val_acc: 0.8222\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 75us/step - loss: 0.4483 - acc: 0.8240 - val_loss: 0.4305 - val_acc: 0.8222\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.4476 - acc: 0.8240 - val_loss: 0.4299 - val_acc: 0.8222\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.4468 - acc: 0.8227 - val_loss: 0.4296 - val_acc: 0.8333\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4460 - acc: 0.8277 - val_loss: 0.4289 - val_acc: 0.8333\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4456 - acc: 0.8290 - val_loss: 0.4292 - val_acc: 0.8333\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 0.6833 - acc: 0.5418 - val_loss: 0.6663 - val_acc: 0.5667\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 72us/step - loss: 0.6760 - acc: 0.5918 - val_loss: 0.6590 - val_acc: 0.6111\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.6689 - acc: 0.6317 - val_loss: 0.6504 - val_acc: 0.6556\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6620 - acc: 0.6529 - val_loss: 0.6423 - val_acc: 0.7222\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6558 - acc: 0.6779 - val_loss: 0.6349 - val_acc: 0.7444\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6507 - acc: 0.6792 - val_loss: 0.6291 - val_acc: 0.7444\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6456 - acc: 0.6866 - val_loss: 0.6228 - val_acc: 0.7444\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6412 - acc: 0.6941 - val_loss: 0.6180 - val_acc: 0.7444\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6368 - acc: 0.7091 - val_loss: 0.6125 - val_acc: 0.7778\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6332 - acc: 0.7216 - val_loss: 0.6087 - val_acc: 0.7889\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6299 - acc: 0.7228 - val_loss: 0.6045 - val_acc: 0.7889\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.6262 - acc: 0.7266 - val_loss: 0.6000 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6229 - acc: 0.7278 - val_loss: 0.5962 - val_acc: 0.7889\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6195 - acc: 0.7253 - val_loss: 0.5919 - val_acc: 0.8000\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6165 - acc: 0.7266 - val_loss: 0.5887 - val_acc: 0.8000\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.6138 - acc: 0.7291 - val_loss: 0.5852 - val_acc: 0.8111\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6111 - acc: 0.7241 - val_loss: 0.5821 - val_acc: 0.8111\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6084 - acc: 0.7253 - val_loss: 0.5786 - val_acc: 0.8333\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6058 - acc: 0.7216 - val_loss: 0.5758 - val_acc: 0.8333\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6033 - acc: 0.7203 - val_loss: 0.5724 - val_acc: 0.8444\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6007 - acc: 0.7228 - val_loss: 0.5689 - val_acc: 0.8444\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5982 - acc: 0.7266 - val_loss: 0.5665 - val_acc: 0.8444\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5961 - acc: 0.7278 - val_loss: 0.5642 - val_acc: 0.8444\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5944 - acc: 0.7278 - val_loss: 0.5622 - val_acc: 0.8444\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5921 - acc: 0.7266 - val_loss: 0.5593 - val_acc: 0.8333\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5898 - acc: 0.7216 - val_loss: 0.5565 - val_acc: 0.8222\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 72us/step - loss: 0.5877 - acc: 0.7216 - val_loss: 0.5536 - val_acc: 0.8333\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.5855 - acc: 0.7253 - val_loss: 0.5514 - val_acc: 0.8333\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5839 - acc: 0.7303 - val_loss: 0.5498 - val_acc: 0.8333\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5821 - acc: 0.7291 - val_loss: 0.5473 - val_acc: 0.8333\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5801 - acc: 0.7253 - val_loss: 0.5449 - val_acc: 0.8333\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5781 - acc: 0.7253 - val_loss: 0.5424 - val_acc: 0.8333\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5762 - acc: 0.7228 - val_loss: 0.5402 - val_acc: 0.8222\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5744 - acc: 0.7278 - val_loss: 0.5383 - val_acc: 0.8333\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5726 - acc: 0.7303 - val_loss: 0.5360 - val_acc: 0.8333\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5707 - acc: 0.7291 - val_loss: 0.5338 - val_acc: 0.8333\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5688 - acc: 0.7303 - val_loss: 0.5320 - val_acc: 0.8333\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.5670 - acc: 0.7316 - val_loss: 0.5301 - val_acc: 0.8333\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.5654 - acc: 0.7366 - val_loss: 0.5283 - val_acc: 0.8333\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5636 - acc: 0.7391 - val_loss: 0.5261 - val_acc: 0.8333\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5618 - acc: 0.7378 - val_loss: 0.5240 - val_acc: 0.8333\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5600 - acc: 0.7416 - val_loss: 0.5219 - val_acc: 0.8333\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5583 - acc: 0.7428 - val_loss: 0.5200 - val_acc: 0.8333\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5565 - acc: 0.7428 - val_loss: 0.5179 - val_acc: 0.8333\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5549 - acc: 0.7441 - val_loss: 0.5159 - val_acc: 0.8333\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5532 - acc: 0.7416 - val_loss: 0.5140 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5516 - acc: 0.7428 - val_loss: 0.5120 - val_acc: 0.8333\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5499 - acc: 0.7428 - val_loss: 0.5101 - val_acc: 0.8333\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5482 - acc: 0.7478 - val_loss: 0.5087 - val_acc: 0.8333\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5467 - acc: 0.7503 - val_loss: 0.5072 - val_acc: 0.8333\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5450 - acc: 0.7528 - val_loss: 0.5055 - val_acc: 0.8333\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5434 - acc: 0.7541 - val_loss: 0.5036 - val_acc: 0.8333\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5418 - acc: 0.7541 - val_loss: 0.5017 - val_acc: 0.8333\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5401 - acc: 0.7566 - val_loss: 0.5002 - val_acc: 0.8444\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5385 - acc: 0.7591 - val_loss: 0.4984 - val_acc: 0.8556\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5369 - acc: 0.7615 - val_loss: 0.4969 - val_acc: 0.8667\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5353 - acc: 0.7640 - val_loss: 0.4951 - val_acc: 0.8667\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5337 - acc: 0.7653 - val_loss: 0.4937 - val_acc: 0.8667\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5323 - acc: 0.7690 - val_loss: 0.4920 - val_acc: 0.8667\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5311 - acc: 0.7690 - val_loss: 0.4905 - val_acc: 0.8667\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5296 - acc: 0.7690 - val_loss: 0.4887 - val_acc: 0.8667\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5282 - acc: 0.7703 - val_loss: 0.4871 - val_acc: 0.8667\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5267 - acc: 0.7740 - val_loss: 0.4853 - val_acc: 0.8667\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5252 - acc: 0.7740 - val_loss: 0.4839 - val_acc: 0.8667\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5239 - acc: 0.7753 - val_loss: 0.4827 - val_acc: 0.8778\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5223 - acc: 0.7740 - val_loss: 0.4812 - val_acc: 0.8778\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5208 - acc: 0.7778 - val_loss: 0.4802 - val_acc: 0.8778\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5194 - acc: 0.7803 - val_loss: 0.4790 - val_acc: 0.8778\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5181 - acc: 0.7803 - val_loss: 0.4775 - val_acc: 0.8778\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5169 - acc: 0.7853 - val_loss: 0.4768 - val_acc: 0.8778\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5156 - acc: 0.7915 - val_loss: 0.4752 - val_acc: 0.8778\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.5144 - acc: 0.7890 - val_loss: 0.4737 - val_acc: 0.8778\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5130 - acc: 0.7890 - val_loss: 0.4722 - val_acc: 0.8778\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5117 - acc: 0.7915 - val_loss: 0.4711 - val_acc: 0.8778\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5104 - acc: 0.7940 - val_loss: 0.4696 - val_acc: 0.8778\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5093 - acc: 0.7903 - val_loss: 0.4690 - val_acc: 0.8667\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5081 - acc: 0.7928 - val_loss: 0.4676 - val_acc: 0.8667\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5068 - acc: 0.7928 - val_loss: 0.4662 - val_acc: 0.8667\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5058 - acc: 0.7990 - val_loss: 0.4650 - val_acc: 0.8778\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5049 - acc: 0.7978 - val_loss: 0.4641 - val_acc: 0.8778\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5039 - acc: 0.7990 - val_loss: 0.4629 - val_acc: 0.8778\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5028 - acc: 0.8015 - val_loss: 0.4619 - val_acc: 0.8778\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5016 - acc: 0.8002 - val_loss: 0.4607 - val_acc: 0.8778\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.5007 - acc: 0.8015 - val_loss: 0.4593 - val_acc: 0.8778\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4994 - acc: 0.8015 - val_loss: 0.4582 - val_acc: 0.8667\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4983 - acc: 0.8065 - val_loss: 0.4570 - val_acc: 0.8667\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4972 - acc: 0.8040 - val_loss: 0.4564 - val_acc: 0.8556\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4962 - acc: 0.8027 - val_loss: 0.4554 - val_acc: 0.8556\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4949 - acc: 0.8027 - val_loss: 0.4543 - val_acc: 0.8556\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4938 - acc: 0.8040 - val_loss: 0.4535 - val_acc: 0.8444\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4928 - acc: 0.8027 - val_loss: 0.4526 - val_acc: 0.8222\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4917 - acc: 0.8052 - val_loss: 0.4516 - val_acc: 0.8222\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4906 - acc: 0.8052 - val_loss: 0.4504 - val_acc: 0.8222\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4895 - acc: 0.8052 - val_loss: 0.4491 - val_acc: 0.8222\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4884 - acc: 0.8040 - val_loss: 0.4479 - val_acc: 0.8222\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4873 - acc: 0.8065 - val_loss: 0.4468 - val_acc: 0.8222\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4863 - acc: 0.8065 - val_loss: 0.4457 - val_acc: 0.8222\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4853 - acc: 0.8077 - val_loss: 0.4444 - val_acc: 0.8333\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4842 - acc: 0.8090 - val_loss: 0.4433 - val_acc: 0.8333\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4832 - acc: 0.8077 - val_loss: 0.4423 - val_acc: 0.8222\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4821 - acc: 0.8090 - val_loss: 0.4413 - val_acc: 0.8222\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4811 - acc: 0.8102 - val_loss: 0.4404 - val_acc: 0.8222\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4801 - acc: 0.8102 - val_loss: 0.4393 - val_acc: 0.8222\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4790 - acc: 0.8102 - val_loss: 0.4384 - val_acc: 0.8222\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4780 - acc: 0.8102 - val_loss: 0.4377 - val_acc: 0.8222\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4771 - acc: 0.8102 - val_loss: 0.4365 - val_acc: 0.8222\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 62us/step - loss: 0.4761 - acc: 0.8102 - val_loss: 0.4358 - val_acc: 0.8222\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4751 - acc: 0.8077 - val_loss: 0.4349 - val_acc: 0.8222\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4741 - acc: 0.8077 - val_loss: 0.4338 - val_acc: 0.8222\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4732 - acc: 0.8090 - val_loss: 0.4328 - val_acc: 0.8222\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.4722 - acc: 0.8102 - val_loss: 0.4322 - val_acc: 0.8111\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4713 - acc: 0.8140 - val_loss: 0.4313 - val_acc: 0.8111\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4703 - acc: 0.8127 - val_loss: 0.4307 - val_acc: 0.8111\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.4694 - acc: 0.8127 - val_loss: 0.4300 - val_acc: 0.8222\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4685 - acc: 0.8115 - val_loss: 0.4294 - val_acc: 0.8222\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4676 - acc: 0.8127 - val_loss: 0.4286 - val_acc: 0.8333\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4667 - acc: 0.8127 - val_loss: 0.4275 - val_acc: 0.8222\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 70us/step - loss: 0.4658 - acc: 0.8127 - val_loss: 0.4265 - val_acc: 0.8222\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4649 - acc: 0.8140 - val_loss: 0.4255 - val_acc: 0.8222\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.4640 - acc: 0.8140 - val_loss: 0.4247 - val_acc: 0.8222\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4632 - acc: 0.8152 - val_loss: 0.4243 - val_acc: 0.8333\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4625 - acc: 0.8165 - val_loss: 0.4232 - val_acc: 0.8222\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4616 - acc: 0.8202 - val_loss: 0.4224 - val_acc: 0.8222\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4609 - acc: 0.8177 - val_loss: 0.4222 - val_acc: 0.8333\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4602 - acc: 0.8177 - val_loss: 0.4217 - val_acc: 0.8333\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 74us/step - loss: 0.4595 - acc: 0.8177 - val_loss: 0.4209 - val_acc: 0.8333\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4587 - acc: 0.8177 - val_loss: 0.4205 - val_acc: 0.8444\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.4579 - acc: 0.8177 - val_loss: 0.4196 - val_acc: 0.8444\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4571 - acc: 0.8177 - val_loss: 0.4187 - val_acc: 0.8444\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4565 - acc: 0.8215 - val_loss: 0.4178 - val_acc: 0.8222\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4560 - acc: 0.8202 - val_loss: 0.4182 - val_acc: 0.8556\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 0.6770 - acc: 0.6092 - val_loss: 0.6720 - val_acc: 0.6111\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.6705 - acc: 0.6404 - val_loss: 0.6643 - val_acc: 0.6778\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 77us/step - loss: 0.6647 - acc: 0.6767 - val_loss: 0.6572 - val_acc: 0.7222\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6594 - acc: 0.6829 - val_loss: 0.6507 - val_acc: 0.7556\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.6547 - acc: 0.6941 - val_loss: 0.6447 - val_acc: 0.8000\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6510 - acc: 0.7054 - val_loss: 0.6404 - val_acc: 0.7889\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6473 - acc: 0.7066 - val_loss: 0.6351 - val_acc: 0.7778\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 70us/step - loss: 0.6439 - acc: 0.7104 - val_loss: 0.6314 - val_acc: 0.7667\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6406 - acc: 0.7066 - val_loss: 0.6267 - val_acc: 0.7667\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6371 - acc: 0.7066 - val_loss: 0.6225 - val_acc: 0.7444\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.6340 - acc: 0.7116 - val_loss: 0.6183 - val_acc: 0.7444\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6310 - acc: 0.7079 - val_loss: 0.6144 - val_acc: 0.7333\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6286 - acc: 0.7116 - val_loss: 0.6116 - val_acc: 0.7333\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.6263 - acc: 0.7104 - val_loss: 0.6089 - val_acc: 0.7444\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6243 - acc: 0.7016 - val_loss: 0.6064 - val_acc: 0.7444\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.6220 - acc: 0.7029 - val_loss: 0.6031 - val_acc: 0.7333\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6196 - acc: 0.6916 - val_loss: 0.5999 - val_acc: 0.7222\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.6172 - acc: 0.6891 - val_loss: 0.5969 - val_acc: 0.7222\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6153 - acc: 0.6879 - val_loss: 0.5947 - val_acc: 0.7222\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 78us/step - loss: 0.6134 - acc: 0.6854 - val_loss: 0.5918 - val_acc: 0.7222\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6115 - acc: 0.6841 - val_loss: 0.5899 - val_acc: 0.7222\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6097 - acc: 0.6841 - val_loss: 0.5871 - val_acc: 0.7222\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6079 - acc: 0.6829 - val_loss: 0.5848 - val_acc: 0.7222\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6064 - acc: 0.6854 - val_loss: 0.5831 - val_acc: 0.7222\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6049 - acc: 0.6854 - val_loss: 0.5815 - val_acc: 0.7222\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 74us/step - loss: 0.6036 - acc: 0.6879 - val_loss: 0.5801 - val_acc: 0.7333\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 78us/step - loss: 0.6020 - acc: 0.6879 - val_loss: 0.5778 - val_acc: 0.7333\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6003 - acc: 0.6879 - val_loss: 0.5756 - val_acc: 0.7444\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5987 - acc: 0.6891 - val_loss: 0.5736 - val_acc: 0.7444\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5971 - acc: 0.6891 - val_loss: 0.5714 - val_acc: 0.7333\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5955 - acc: 0.6879 - val_loss: 0.5693 - val_acc: 0.7333\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 79us/step - loss: 0.5939 - acc: 0.6879 - val_loss: 0.5672 - val_acc: 0.7444\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5923 - acc: 0.6879 - val_loss: 0.5652 - val_acc: 0.7444\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5908 - acc: 0.6866 - val_loss: 0.5631 - val_acc: 0.7444\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.5893 - acc: 0.6904 - val_loss: 0.5617 - val_acc: 0.7556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5880 - acc: 0.6954 - val_loss: 0.5604 - val_acc: 0.7556\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.5865 - acc: 0.6979 - val_loss: 0.5588 - val_acc: 0.7556\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5851 - acc: 0.6979 - val_loss: 0.5570 - val_acc: 0.7556\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 71us/step - loss: 0.5837 - acc: 0.7016 - val_loss: 0.5555 - val_acc: 0.7667\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5824 - acc: 0.7029 - val_loss: 0.5544 - val_acc: 0.7667\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5811 - acc: 0.7029 - val_loss: 0.5527 - val_acc: 0.7667\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 70us/step - loss: 0.5797 - acc: 0.7054 - val_loss: 0.5508 - val_acc: 0.7667\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5782 - acc: 0.7054 - val_loss: 0.5493 - val_acc: 0.7667\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5768 - acc: 0.7054 - val_loss: 0.5475 - val_acc: 0.7667\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5756 - acc: 0.7054 - val_loss: 0.5465 - val_acc: 0.7667\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 81us/step - loss: 0.5745 - acc: 0.7129 - val_loss: 0.5455 - val_acc: 0.7667\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.5733 - acc: 0.7141 - val_loss: 0.5437 - val_acc: 0.7667\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5718 - acc: 0.7191 - val_loss: 0.5421 - val_acc: 0.7667\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 70us/step - loss: 0.5704 - acc: 0.7191 - val_loss: 0.5403 - val_acc: 0.7667\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5690 - acc: 0.7191 - val_loss: 0.5384 - val_acc: 0.7667\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5675 - acc: 0.7241 - val_loss: 0.5369 - val_acc: 0.7778\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5661 - acc: 0.7278 - val_loss: 0.5355 - val_acc: 0.7778\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5646 - acc: 0.7341 - val_loss: 0.5339 - val_acc: 0.7778\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5633 - acc: 0.7341 - val_loss: 0.5324 - val_acc: 0.7778\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5619 - acc: 0.7341 - val_loss: 0.5307 - val_acc: 0.7889\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5605 - acc: 0.7391 - val_loss: 0.5291 - val_acc: 0.7889\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5590 - acc: 0.7378 - val_loss: 0.5276 - val_acc: 0.7889\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5576 - acc: 0.7391 - val_loss: 0.5259 - val_acc: 0.7889\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5563 - acc: 0.7391 - val_loss: 0.5242 - val_acc: 0.7889\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5549 - acc: 0.7416 - val_loss: 0.5230 - val_acc: 0.7889\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5537 - acc: 0.7516 - val_loss: 0.5219 - val_acc: 0.8000\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5525 - acc: 0.7516 - val_loss: 0.5206 - val_acc: 0.8000\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5512 - acc: 0.7528 - val_loss: 0.5190 - val_acc: 0.8000\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5499 - acc: 0.7553 - val_loss: 0.5174 - val_acc: 0.8000\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5486 - acc: 0.7553 - val_loss: 0.5158 - val_acc: 0.8000\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5473 - acc: 0.7553 - val_loss: 0.5143 - val_acc: 0.8000\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5460 - acc: 0.7603 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5447 - acc: 0.7628 - val_loss: 0.5119 - val_acc: 0.7889\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5434 - acc: 0.7665 - val_loss: 0.5104 - val_acc: 0.7889\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5421 - acc: 0.7665 - val_loss: 0.5089 - val_acc: 0.7889\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5409 - acc: 0.7665 - val_loss: 0.5073 - val_acc: 0.7889\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5395 - acc: 0.7690 - val_loss: 0.5058 - val_acc: 0.7889\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5382 - acc: 0.7715 - val_loss: 0.5045 - val_acc: 0.8000\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5368 - acc: 0.7765 - val_loss: 0.5031 - val_acc: 0.7889\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5356 - acc: 0.7865 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.5342 - acc: 0.7878 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.5330 - acc: 0.7878 - val_loss: 0.4988 - val_acc: 0.8000\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5318 - acc: 0.7878 - val_loss: 0.4972 - val_acc: 0.8000\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5303 - acc: 0.7903 - val_loss: 0.4959 - val_acc: 0.8111\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5289 - acc: 0.7903 - val_loss: 0.4947 - val_acc: 0.8111\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5276 - acc: 0.7903 - val_loss: 0.4933 - val_acc: 0.8222\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.5263 - acc: 0.7903 - val_loss: 0.4918 - val_acc: 0.8222\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5250 - acc: 0.7953 - val_loss: 0.4903 - val_acc: 0.8222\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5238 - acc: 0.7965 - val_loss: 0.4888 - val_acc: 0.8222\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5225 - acc: 0.7965 - val_loss: 0.4875 - val_acc: 0.8222\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5212 - acc: 0.7965 - val_loss: 0.4863 - val_acc: 0.8333\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5201 - acc: 0.7990 - val_loss: 0.4857 - val_acc: 0.8444\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5190 - acc: 0.8015 - val_loss: 0.4845 - val_acc: 0.8556\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5181 - acc: 0.8015 - val_loss: 0.4840 - val_acc: 0.8667\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5170 - acc: 0.8015 - val_loss: 0.4830 - val_acc: 0.8667\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5157 - acc: 0.8002 - val_loss: 0.4817 - val_acc: 0.8667\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5148 - acc: 0.8015 - val_loss: 0.4811 - val_acc: 0.8667\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5137 - acc: 0.8015 - val_loss: 0.4796 - val_acc: 0.8667\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5126 - acc: 0.8027 - val_loss: 0.4782 - val_acc: 0.8667\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5113 - acc: 0.8015 - val_loss: 0.4769 - val_acc: 0.8667\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 53us/step - loss: 0.5102 - acc: 0.8015 - val_loss: 0.4755 - val_acc: 0.8667\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5090 - acc: 0.8015 - val_loss: 0.4740 - val_acc: 0.8667\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5080 - acc: 0.8015 - val_loss: 0.4731 - val_acc: 0.8667\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5070 - acc: 0.8015 - val_loss: 0.4722 - val_acc: 0.8667\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5060 - acc: 0.8015 - val_loss: 0.4707 - val_acc: 0.8667\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5047 - acc: 0.8040 - val_loss: 0.4698 - val_acc: 0.8667\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.5038 - acc: 0.8052 - val_loss: 0.4689 - val_acc: 0.8667\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5028 - acc: 0.8090 - val_loss: 0.4680 - val_acc: 0.8556\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.5017 - acc: 0.8115 - val_loss: 0.4665 - val_acc: 0.8556\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5005 - acc: 0.8140 - val_loss: 0.4654 - val_acc: 0.8556\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4994 - acc: 0.8140 - val_loss: 0.4642 - val_acc: 0.8556\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4983 - acc: 0.8165 - val_loss: 0.4631 - val_acc: 0.8556\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4972 - acc: 0.8165 - val_loss: 0.4618 - val_acc: 0.8556\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4962 - acc: 0.8165 - val_loss: 0.4605 - val_acc: 0.8556\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4951 - acc: 0.8152 - val_loss: 0.4591 - val_acc: 0.8556\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4941 - acc: 0.8152 - val_loss: 0.4580 - val_acc: 0.8556\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4932 - acc: 0.8152 - val_loss: 0.4568 - val_acc: 0.8556\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4922 - acc: 0.8152 - val_loss: 0.4556 - val_acc: 0.8556\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4912 - acc: 0.8152 - val_loss: 0.4546 - val_acc: 0.8556\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4904 - acc: 0.8127 - val_loss: 0.4535 - val_acc: 0.8556\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4895 - acc: 0.8127 - val_loss: 0.4526 - val_acc: 0.8556\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4886 - acc: 0.8127 - val_loss: 0.4516 - val_acc: 0.8556\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4876 - acc: 0.8140 - val_loss: 0.4506 - val_acc: 0.8556\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4866 - acc: 0.8152 - val_loss: 0.4497 - val_acc: 0.8556\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4856 - acc: 0.8177 - val_loss: 0.4487 - val_acc: 0.8556\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4847 - acc: 0.8177 - val_loss: 0.4476 - val_acc: 0.8556\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4837 - acc: 0.8190 - val_loss: 0.4467 - val_acc: 0.8556\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4827 - acc: 0.8190 - val_loss: 0.4458 - val_acc: 0.8667\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4816 - acc: 0.8190 - val_loss: 0.4449 - val_acc: 0.8667\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.4808 - acc: 0.8190 - val_loss: 0.4439 - val_acc: 0.8667\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.4798 - acc: 0.8190 - val_loss: 0.4430 - val_acc: 0.8667\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4789 - acc: 0.8190 - val_loss: 0.4419 - val_acc: 0.8667\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.4779 - acc: 0.8177 - val_loss: 0.4410 - val_acc: 0.8667\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4771 - acc: 0.8177 - val_loss: 0.4401 - val_acc: 0.8667\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4761 - acc: 0.8177 - val_loss: 0.4391 - val_acc: 0.8667\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4751 - acc: 0.8190 - val_loss: 0.4382 - val_acc: 0.8667\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4744 - acc: 0.8190 - val_loss: 0.4373 - val_acc: 0.8667\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4734 - acc: 0.8190 - val_loss: 0.4366 - val_acc: 0.8667\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4725 - acc: 0.8190 - val_loss: 0.4357 - val_acc: 0.8667\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4717 - acc: 0.8202 - val_loss: 0.4348 - val_acc: 0.8556\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4708 - acc: 0.8227 - val_loss: 0.4341 - val_acc: 0.8556\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4699 - acc: 0.8215 - val_loss: 0.4335 - val_acc: 0.8556\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4690 - acc: 0.8240 - val_loss: 0.4326 - val_acc: 0.8556\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4681 - acc: 0.8240 - val_loss: 0.4319 - val_acc: 0.8556\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4673 - acc: 0.8240 - val_loss: 0.4309 - val_acc: 0.8556\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4664 - acc: 0.8240 - val_loss: 0.4299 - val_acc: 0.8556\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4656 - acc: 0.8252 - val_loss: 0.4289 - val_acc: 0.8556\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4649 - acc: 0.8240 - val_loss: 0.4280 - val_acc: 0.8556\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4641 - acc: 0.8240 - val_loss: 0.4271 - val_acc: 0.8556\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4633 - acc: 0.8240 - val_loss: 0.4264 - val_acc: 0.8556\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4624 - acc: 0.8252 - val_loss: 0.4259 - val_acc: 0.8556\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4617 - acc: 0.8290 - val_loss: 0.4254 - val_acc: 0.8556\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4609 - acc: 0.8277 - val_loss: 0.4246 - val_acc: 0.8556\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4600 - acc: 0.8290 - val_loss: 0.4241 - val_acc: 0.8556\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4593 - acc: 0.8265 - val_loss: 0.4236 - val_acc: 0.8556\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4586 - acc: 0.8277 - val_loss: 0.4225 - val_acc: 0.8556\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4577 - acc: 0.8290 - val_loss: 0.4218 - val_acc: 0.8556\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4570 - acc: 0.8265 - val_loss: 0.4212 - val_acc: 0.8556\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4563 - acc: 0.8290 - val_loss: 0.4203 - val_acc: 0.8556\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4556 - acc: 0.8302 - val_loss: 0.4196 - val_acc: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4548 - acc: 0.8315 - val_loss: 0.4187 - val_acc: 0.8556\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4542 - acc: 0.8302 - val_loss: 0.4179 - val_acc: 0.8556\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4534 - acc: 0.8327 - val_loss: 0.4173 - val_acc: 0.8667\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.4528 - acc: 0.8352 - val_loss: 0.4167 - val_acc: 0.8667\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4521 - acc: 0.8352 - val_loss: 0.4162 - val_acc: 0.8667\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4514 - acc: 0.8352 - val_loss: 0.4153 - val_acc: 0.8667\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4507 - acc: 0.8377 - val_loss: 0.4146 - val_acc: 0.8667\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4500 - acc: 0.8390 - val_loss: 0.4139 - val_acc: 0.8667\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4494 - acc: 0.8390 - val_loss: 0.4132 - val_acc: 0.8667\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4488 - acc: 0.8390 - val_loss: 0.4124 - val_acc: 0.8667\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4482 - acc: 0.8390 - val_loss: 0.4118 - val_acc: 0.8667\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4476 - acc: 0.8390 - val_loss: 0.4112 - val_acc: 0.8667\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4471 - acc: 0.8365 - val_loss: 0.4113 - val_acc: 0.8667\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 0.7396 - acc: 0.4082 - val_loss: 0.7329 - val_acc: 0.3889\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.7313 - acc: 0.4170 - val_loss: 0.7240 - val_acc: 0.4222\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.7239 - acc: 0.4295 - val_loss: 0.7157 - val_acc: 0.4333\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.7172 - acc: 0.4332 - val_loss: 0.7080 - val_acc: 0.4444\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.7103 - acc: 0.4370 - val_loss: 0.6992 - val_acc: 0.4444\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.7033 - acc: 0.4594 - val_loss: 0.6913 - val_acc: 0.5111\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6974 - acc: 0.4881 - val_loss: 0.6847 - val_acc: 0.5444\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6917 - acc: 0.5256 - val_loss: 0.6776 - val_acc: 0.5889\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6865 - acc: 0.5356 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6817 - acc: 0.5568 - val_loss: 0.6663 - val_acc: 0.6556\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6767 - acc: 0.6030 - val_loss: 0.6602 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6722 - acc: 0.6242 - val_loss: 0.6553 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6678 - acc: 0.6330 - val_loss: 0.6495 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6633 - acc: 0.6504 - val_loss: 0.6440 - val_acc: 0.6889\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6590 - acc: 0.6629 - val_loss: 0.6391 - val_acc: 0.7111\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6551 - acc: 0.6754 - val_loss: 0.6345 - val_acc: 0.7222\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6514 - acc: 0.6904 - val_loss: 0.6304 - val_acc: 0.7444\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6481 - acc: 0.7004 - val_loss: 0.6262 - val_acc: 0.7444\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6451 - acc: 0.7054 - val_loss: 0.6230 - val_acc: 0.7333\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6422 - acc: 0.7079 - val_loss: 0.6190 - val_acc: 0.7444\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6391 - acc: 0.7054 - val_loss: 0.6151 - val_acc: 0.7444\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6360 - acc: 0.7029 - val_loss: 0.6117 - val_acc: 0.7444\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6334 - acc: 0.7104 - val_loss: 0.6088 - val_acc: 0.7667\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6307 - acc: 0.7179 - val_loss: 0.6054 - val_acc: 0.7556\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6281 - acc: 0.7191 - val_loss: 0.6023 - val_acc: 0.7667\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6256 - acc: 0.7154 - val_loss: 0.5992 - val_acc: 0.7556\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6232 - acc: 0.7166 - val_loss: 0.5966 - val_acc: 0.7556\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6209 - acc: 0.7154 - val_loss: 0.5941 - val_acc: 0.7444\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6189 - acc: 0.7191 - val_loss: 0.5919 - val_acc: 0.7556\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6168 - acc: 0.7116 - val_loss: 0.5891 - val_acc: 0.7333\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6148 - acc: 0.7129 - val_loss: 0.5872 - val_acc: 0.7444\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6127 - acc: 0.7129 - val_loss: 0.5846 - val_acc: 0.7444\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6106 - acc: 0.7141 - val_loss: 0.5819 - val_acc: 0.7333\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6084 - acc: 0.7079 - val_loss: 0.5795 - val_acc: 0.7444\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6064 - acc: 0.7066 - val_loss: 0.5769 - val_acc: 0.7444\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6043 - acc: 0.7066 - val_loss: 0.5745 - val_acc: 0.7444\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6023 - acc: 0.7054 - val_loss: 0.5721 - val_acc: 0.7333\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6004 - acc: 0.7029 - val_loss: 0.5700 - val_acc: 0.7222\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5985 - acc: 0.7029 - val_loss: 0.5677 - val_acc: 0.7222\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5965 - acc: 0.7054 - val_loss: 0.5655 - val_acc: 0.7222\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5947 - acc: 0.7066 - val_loss: 0.5636 - val_acc: 0.7333\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5928 - acc: 0.7091 - val_loss: 0.5614 - val_acc: 0.7444\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.5910 - acc: 0.7129 - val_loss: 0.5597 - val_acc: 0.7556\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5891 - acc: 0.7141 - val_loss: 0.5575 - val_acc: 0.7556\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5873 - acc: 0.7179 - val_loss: 0.5555 - val_acc: 0.7556\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5855 - acc: 0.7166 - val_loss: 0.5534 - val_acc: 0.7556\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.5838 - acc: 0.7166 - val_loss: 0.5515 - val_acc: 0.7556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5820 - acc: 0.7191 - val_loss: 0.5498 - val_acc: 0.7556\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5803 - acc: 0.7203 - val_loss: 0.5481 - val_acc: 0.7556\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5786 - acc: 0.7179 - val_loss: 0.5461 - val_acc: 0.7556\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5768 - acc: 0.7241 - val_loss: 0.5444 - val_acc: 0.7556\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5751 - acc: 0.7228 - val_loss: 0.5425 - val_acc: 0.7556\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5733 - acc: 0.7253 - val_loss: 0.5407 - val_acc: 0.7556\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5717 - acc: 0.7253 - val_loss: 0.5390 - val_acc: 0.7556\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5701 - acc: 0.7278 - val_loss: 0.5377 - val_acc: 0.7556\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5684 - acc: 0.7303 - val_loss: 0.5360 - val_acc: 0.7667\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5666 - acc: 0.7391 - val_loss: 0.5345 - val_acc: 0.7667\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5650 - acc: 0.7466 - val_loss: 0.5330 - val_acc: 0.7778\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5634 - acc: 0.7516 - val_loss: 0.5316 - val_acc: 0.7889\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5617 - acc: 0.7516 - val_loss: 0.5297 - val_acc: 0.7889\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5602 - acc: 0.7528 - val_loss: 0.5278 - val_acc: 0.7889\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5585 - acc: 0.7491 - val_loss: 0.5259 - val_acc: 0.7889\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5569 - acc: 0.7491 - val_loss: 0.5243 - val_acc: 0.8000\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5555 - acc: 0.7516 - val_loss: 0.5233 - val_acc: 0.8111\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5542 - acc: 0.7591 - val_loss: 0.5220 - val_acc: 0.8333\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5527 - acc: 0.7566 - val_loss: 0.5201 - val_acc: 0.8333\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5510 - acc: 0.7615 - val_loss: 0.5185 - val_acc: 0.8333\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5493 - acc: 0.7628 - val_loss: 0.5168 - val_acc: 0.8333\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5480 - acc: 0.7628 - val_loss: 0.5156 - val_acc: 0.8444\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5465 - acc: 0.7653 - val_loss: 0.5140 - val_acc: 0.8556\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5449 - acc: 0.7653 - val_loss: 0.5123 - val_acc: 0.8556\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5434 - acc: 0.7615 - val_loss: 0.5107 - val_acc: 0.8556\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5419 - acc: 0.7628 - val_loss: 0.5090 - val_acc: 0.8556\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5405 - acc: 0.7640 - val_loss: 0.5072 - val_acc: 0.8556\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.5389 - acc: 0.7653 - val_loss: 0.5056 - val_acc: 0.8556\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5375 - acc: 0.7640 - val_loss: 0.5042 - val_acc: 0.8556\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.5360 - acc: 0.7665 - val_loss: 0.5026 - val_acc: 0.8556\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5345 - acc: 0.7665 - val_loss: 0.5010 - val_acc: 0.8556\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5331 - acc: 0.7678 - val_loss: 0.4994 - val_acc: 0.8556\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5317 - acc: 0.7690 - val_loss: 0.4978 - val_acc: 0.8556\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5302 - acc: 0.7703 - val_loss: 0.4963 - val_acc: 0.8556\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5288 - acc: 0.7703 - val_loss: 0.4950 - val_acc: 0.8556\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5275 - acc: 0.7703 - val_loss: 0.4934 - val_acc: 0.8556\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5260 - acc: 0.7703 - val_loss: 0.4918 - val_acc: 0.8556\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5246 - acc: 0.7715 - val_loss: 0.4904 - val_acc: 0.8556\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5233 - acc: 0.7715 - val_loss: 0.4888 - val_acc: 0.8556\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.5218 - acc: 0.7740 - val_loss: 0.4874 - val_acc: 0.8444\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.5203 - acc: 0.7765 - val_loss: 0.4859 - val_acc: 0.8444\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5188 - acc: 0.7803 - val_loss: 0.4848 - val_acc: 0.8444\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5175 - acc: 0.7853 - val_loss: 0.4835 - val_acc: 0.8333\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5163 - acc: 0.7915 - val_loss: 0.4827 - val_acc: 0.8333\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5152 - acc: 0.7965 - val_loss: 0.4818 - val_acc: 0.8333\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.5141 - acc: 0.8015 - val_loss: 0.4807 - val_acc: 0.8556\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5131 - acc: 0.8027 - val_loss: 0.4799 - val_acc: 0.8556\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.5120 - acc: 0.8027 - val_loss: 0.4787 - val_acc: 0.8556\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5108 - acc: 0.8040 - val_loss: 0.4776 - val_acc: 0.8556\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.5096 - acc: 0.8052 - val_loss: 0.4763 - val_acc: 0.8556\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.5083 - acc: 0.8052 - val_loss: 0.4751 - val_acc: 0.8556\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5071 - acc: 0.8040 - val_loss: 0.4740 - val_acc: 0.8556\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.5058 - acc: 0.8040 - val_loss: 0.4725 - val_acc: 0.8556\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.5045 - acc: 0.8027 - val_loss: 0.4710 - val_acc: 0.8556\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.5033 - acc: 0.8027 - val_loss: 0.4698 - val_acc: 0.8556\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.5023 - acc: 0.8040 - val_loss: 0.4690 - val_acc: 0.8556\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.5012 - acc: 0.8052 - val_loss: 0.4676 - val_acc: 0.8556\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - ETA: 0s - loss: 0.4783 - acc: 0.812 - 0s 61us/step - loss: 0.5001 - acc: 0.8040 - val_loss: 0.4661 - val_acc: 0.8556\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4988 - acc: 0.8077 - val_loss: 0.4648 - val_acc: 0.8556\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4977 - acc: 0.8065 - val_loss: 0.4635 - val_acc: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4965 - acc: 0.8040 - val_loss: 0.4625 - val_acc: 0.8556\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4954 - acc: 0.8090 - val_loss: 0.4614 - val_acc: 0.8556\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4942 - acc: 0.8090 - val_loss: 0.4600 - val_acc: 0.8556\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4930 - acc: 0.8090 - val_loss: 0.4586 - val_acc: 0.8556\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4918 - acc: 0.8077 - val_loss: 0.4575 - val_acc: 0.8556\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4909 - acc: 0.8102 - val_loss: 0.4568 - val_acc: 0.8667\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4898 - acc: 0.8127 - val_loss: 0.4557 - val_acc: 0.8556\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4888 - acc: 0.8127 - val_loss: 0.4547 - val_acc: 0.8667\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4877 - acc: 0.8140 - val_loss: 0.4534 - val_acc: 0.8667\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4866 - acc: 0.8140 - val_loss: 0.4524 - val_acc: 0.8667\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4856 - acc: 0.8140 - val_loss: 0.4515 - val_acc: 0.8667\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4845 - acc: 0.8152 - val_loss: 0.4501 - val_acc: 0.8667\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4835 - acc: 0.8152 - val_loss: 0.4490 - val_acc: 0.8667\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4825 - acc: 0.8152 - val_loss: 0.4481 - val_acc: 0.8667\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4815 - acc: 0.8152 - val_loss: 0.4469 - val_acc: 0.8667\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4804 - acc: 0.8140 - val_loss: 0.4459 - val_acc: 0.8667\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4795 - acc: 0.8140 - val_loss: 0.4447 - val_acc: 0.8667\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4786 - acc: 0.8152 - val_loss: 0.4444 - val_acc: 0.8667\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4778 - acc: 0.8177 - val_loss: 0.4434 - val_acc: 0.8667\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4769 - acc: 0.8177 - val_loss: 0.4423 - val_acc: 0.8667\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4759 - acc: 0.8177 - val_loss: 0.4412 - val_acc: 0.8667\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4751 - acc: 0.8165 - val_loss: 0.4402 - val_acc: 0.8667\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4742 - acc: 0.8152 - val_loss: 0.4392 - val_acc: 0.8667\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4734 - acc: 0.8177 - val_loss: 0.4388 - val_acc: 0.8667\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4725 - acc: 0.8190 - val_loss: 0.4382 - val_acc: 0.8667\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4716 - acc: 0.8202 - val_loss: 0.4371 - val_acc: 0.8667\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4708 - acc: 0.8227 - val_loss: 0.4361 - val_acc: 0.8667\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4699 - acc: 0.8227 - val_loss: 0.4352 - val_acc: 0.8667\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4691 - acc: 0.8240 - val_loss: 0.4342 - val_acc: 0.8667\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4681 - acc: 0.8240 - val_loss: 0.4336 - val_acc: 0.8667\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.4673 - acc: 0.8240 - val_loss: 0.4327 - val_acc: 0.8667\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4664 - acc: 0.8202 - val_loss: 0.4318 - val_acc: 0.8667\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4656 - acc: 0.8190 - val_loss: 0.4311 - val_acc: 0.8667\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4646 - acc: 0.8202 - val_loss: 0.4303 - val_acc: 0.8667\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4638 - acc: 0.8202 - val_loss: 0.4296 - val_acc: 0.8667\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4630 - acc: 0.8190 - val_loss: 0.4288 - val_acc: 0.8667\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4622 - acc: 0.8215 - val_loss: 0.4280 - val_acc: 0.8667\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4615 - acc: 0.8227 - val_loss: 0.4270 - val_acc: 0.8667\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4607 - acc: 0.8190 - val_loss: 0.4263 - val_acc: 0.8667\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4599 - acc: 0.8227 - val_loss: 0.4257 - val_acc: 0.8667\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.4591 - acc: 0.8252 - val_loss: 0.4251 - val_acc: 0.8778\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4583 - acc: 0.8265 - val_loss: 0.4247 - val_acc: 0.8778\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4575 - acc: 0.8277 - val_loss: 0.4239 - val_acc: 0.8778\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4568 - acc: 0.8277 - val_loss: 0.4231 - val_acc: 0.8778\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.4560 - acc: 0.8290 - val_loss: 0.4221 - val_acc: 0.8778\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.4552 - acc: 0.8277 - val_loss: 0.4214 - val_acc: 0.8778\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4544 - acc: 0.8277 - val_loss: 0.4206 - val_acc: 0.8778\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.4537 - acc: 0.8290 - val_loss: 0.4198 - val_acc: 0.8778\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.4530 - acc: 0.8315 - val_loss: 0.4190 - val_acc: 0.8778\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4523 - acc: 0.8340 - val_loss: 0.4186 - val_acc: 0.8778\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4516 - acc: 0.8327 - val_loss: 0.4179 - val_acc: 0.8778\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 72us/step - loss: 0.4509 - acc: 0.8352 - val_loss: 0.4171 - val_acc: 0.8778\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4502 - acc: 0.8352 - val_loss: 0.4163 - val_acc: 0.8778\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.4495 - acc: 0.8352 - val_loss: 0.4158 - val_acc: 0.8778\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.4489 - acc: 0.8352 - val_loss: 0.4157 - val_acc: 0.8778\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 73us/step - loss: 0.4483 - acc: 0.8352 - val_loss: 0.4148 - val_acc: 0.8778\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 63us/step - loss: 0.4476 - acc: 0.8352 - val_loss: 0.4141 - val_acc: 0.8778\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.4472 - acc: 0.8352 - val_loss: 0.4134 - val_acc: 0.8778\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.4464 - acc: 0.8352 - val_loss: 0.4129 - val_acc: 0.8778\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.4458 - acc: 0.8352 - val_loss: 0.4122 - val_acc: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.4453 - acc: 0.8352 - val_loss: 0.4115 - val_acc: 0.8778\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.4447 - acc: 0.8365 - val_loss: 0.4117 - val_acc: 0.8778\n"
     ]
    }
   ],
   "source": [
    "nb_models = 10\n",
    "df_test['Survived'] = 0\n",
    "df_train['Survived_predicted'] = 0\n",
    "for i in range(nb_models):\n",
    "    model = build_model()\n",
    "    history = model.fit(df_one_hot_train, \n",
    "                        pd.get_dummies(df_train[LABEL].astype(str)), \n",
    "                        epochs=1000, \n",
    "                        batch_size=32, \n",
    "                        validation_split=0.1,\n",
    "                       callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])\n",
    "    df_test['Survived'] += model.predict(df_one_hot_test)[:, 1]\n",
    "    df_train['Survived_predicted'] += model.predict(df_one_hot_train)[:, 1]\n",
    "df_test['Survived'] /= nb_models\n",
    "df_train['Survived_predicted'] /= nb_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Survived_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Survived_predicted\n",
       "765         1                 1.0\n",
       "666         0                 0.0\n",
       "200         0                 0.0\n",
       "271         1                 0.0\n",
       "340         1                 1.0\n",
       "887         1                 1.0\n",
       "477         0                 0.0\n",
       "245         0                 0.0\n",
       "375         1                 1.0\n",
       "863         0                 0.0\n",
       "546         1                 1.0\n",
       "393         1                 1.0\n",
       "30          0                 0.0\n",
       "559         1                 0.0\n",
       "379         0                 0.0\n",
       "827         1                 1.0\n",
       "866         1                 1.0\n",
       "456         0                 0.0\n",
       "869         1                 0.0\n",
       "492         0                 0.0\n",
       "517         0                 0.0\n",
       "553         1                 0.0\n",
       "613         0                 0.0\n",
       "708         1                 1.0\n",
       "124         0                 0.0\n",
       "619         0                 0.0\n",
       "610         0                 0.0\n",
       "148         0                 0.0\n",
       "731         0                 0.0\n",
       "788         1                 0.0\n",
       "..        ...                 ...\n",
       "799         0                 1.0\n",
       "113         0                 0.0\n",
       "164         0                 0.0\n",
       "674         0                 0.0\n",
       "554         1                 0.0\n",
       "160         0                 0.0\n",
       "43          1                 1.0\n",
       "67          0                 0.0\n",
       "754         1                 1.0\n",
       "434         0                 0.0\n",
       "120         0                 0.0\n",
       "881         0                 0.0\n",
       "318         1                 1.0\n",
       "58          1                 1.0\n",
       "586         0                 0.0\n",
       "15          1                 1.0\n",
       "115         0                 0.0\n",
       "826         0                 0.0\n",
       "240         0                 1.0\n",
       "150         0                 0.0\n",
       "468         0                 0.0\n",
       "461         0                 0.0\n",
       "580         1                 1.0\n",
       "735         0                 0.0\n",
       "184         1                 1.0\n",
       "726         1                 1.0\n",
       "882         0                 0.0\n",
       "219         0                 0.0\n",
       "565         0                 0.0\n",
       "705         0                 0.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Survived_predicted'] = np.rint(df_train['Survived_predicted'])\n",
    "df_train[['Survived', 'Survived_predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Survived'] = np.rint(df_test['Survived'])\n",
    "df_test['Survived_last_model'] = np.apply_along_axis(np.argmax, 1, model.predict(df_one_hot_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Survived_last_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Survived_last_model\n",
       "0         0.0                    0\n",
       "1         1.0                    1\n",
       "2         0.0                    0\n",
       "3         0.0                    0\n",
       "4         1.0                    1\n",
       "5         0.0                    0\n",
       "6         0.0                    0\n",
       "7         0.0                    0\n",
       "8         1.0                    1\n",
       "9         0.0                    0\n",
       "10        0.0                    0\n",
       "11        0.0                    0\n",
       "12        1.0                    1\n",
       "13        0.0                    0\n",
       "14        1.0                    1\n",
       "15        1.0                    1\n",
       "16        0.0                    0\n",
       "17        0.0                    0\n",
       "18        1.0                    1\n",
       "19        1.0                    1\n",
       "20        0.0                    0\n",
       "21        0.0                    0\n",
       "22        1.0                    1\n",
       "23        0.0                    0\n",
       "24        1.0                    1\n",
       "25        0.0                    0\n",
       "26        1.0                    1\n",
       "27        0.0                    0\n",
       "28        0.0                    0\n",
       "29        0.0                    0\n",
       "..        ...                  ...\n",
       "388       0.0                    0\n",
       "389       0.0                    0\n",
       "390       0.0                    0\n",
       "391       1.0                    1\n",
       "392       0.0                    0\n",
       "393       0.0                    0\n",
       "394       0.0                    0\n",
       "395       1.0                    1\n",
       "396       0.0                    0\n",
       "397       1.0                    1\n",
       "398       0.0                    0\n",
       "399       0.0                    0\n",
       "400       1.0                    1\n",
       "401       0.0                    0\n",
       "402       1.0                    1\n",
       "403       0.0                    0\n",
       "404       1.0                    0\n",
       "405       0.0                    1\n",
       "406       0.0                    0\n",
       "407       1.0                    1\n",
       "408       0.0                    1\n",
       "409       1.0                    1\n",
       "410       1.0                    1\n",
       "411       1.0                    1\n",
       "412       0.0                    0\n",
       "413       0.0                    0\n",
       "414       1.0                    1\n",
       "415       0.0                    0\n",
       "416       0.0                    0\n",
       "417       0.0                    0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['Survived', 'Survived_last_model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83645443196\n",
      "0.877777779102\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'][-1])\n",
    "print(history.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKTf2/wGAUcVOsFnWEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10b2265da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10b56a9da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plt, = plt.plot(history.history['loss'], label='train')\n",
    "val_loss_plt, = plt.plot(history.history['val_loss'], label='valid')\n",
    "\n",
    "plt.legend(handles=[loss_plt, val_loss_plt])\n",
    "plt.show()\n",
    "\n",
    "acc_plt, = plt.plot(history.history['acc'], label='train')\n",
    "val_acc_plt, = plt.plot(history.history['val_acc'], label='valid')\n",
    "\n",
    "plt.legend(handles=[loss_plt, val_loss_plt])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66267942583732053"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-df_test['Survived'].sum()/len(df_test['Survived'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test[['PassengerId', 'Survived']].to_csv(path_or_buf='./out.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
