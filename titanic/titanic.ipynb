{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.0</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PP 9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>58.0</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.0</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28.0</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Canavan, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>1</td>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>23.0</td>\n",
       "      <td>B24</td>\n",
       "      <td>S</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>Payne, Mr. Vivian Ponsonby</td>\n",
       "      <td>0</td>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>51.0</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>Lines, Mrs. Ernest H (Elizabeth Lindsey James)</td>\n",
       "      <td>1</td>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>Abbott, Master. Eugene Joseph</td>\n",
       "      <td>2</td>\n",
       "      <td>1284</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Gilbert, Mr. William</td>\n",
       "      <td>0</td>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 30769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>Kink-Heilmann, Mr. Anton</td>\n",
       "      <td>1</td>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>18.0</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>Smith, Mrs. Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>0</td>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Colbert, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1288</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>48.0</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Larsson-Rondberg, Mr. Edvard A</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Conlon, Mr. Thomas Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>Bonnell, Miss. Caroline</td>\n",
       "      <td>0</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>Gale, Mr. Harry</td>\n",
       "      <td>0</td>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>1</td>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>Carrau, Mr. Jose Pedro</td>\n",
       "      <td>0</td>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>43.0</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>Frauenthal, Mr. Isaac Gerald</td>\n",
       "      <td>0</td>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>20.0</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>Nourney, Mr. Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Ware, Mr. William Jeffery</td>\n",
       "      <td>0</td>\n",
       "      <td>1298</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>50.0</td>\n",
       "      <td>C80</td>\n",
       "      <td>C</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>Widener, Mr. George Dunton</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Naughton, Miss. Hannah</td>\n",
       "      <td>0</td>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>37.0</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td>\n",
       "      <td>0</td>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
       "      <td>0</td>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A.5. 3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>39.0</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>0</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>38.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>1</td>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age        Cabin Embarked      Fare  \\\n",
       "0    22.0          NaN        S    7.2500   \n",
       "1    38.0          C85        C   71.2833   \n",
       "2    26.0          NaN        S    7.9250   \n",
       "3    35.0         C123        S   53.1000   \n",
       "4    35.0          NaN        S    8.0500   \n",
       "5     NaN          NaN        Q    8.4583   \n",
       "6    54.0          E46        S   51.8625   \n",
       "7     2.0          NaN        S   21.0750   \n",
       "8    27.0          NaN        S   11.1333   \n",
       "9    14.0          NaN        C   30.0708   \n",
       "10    4.0           G6        S   16.7000   \n",
       "11   58.0         C103        S   26.5500   \n",
       "12   20.0          NaN        S    8.0500   \n",
       "13   39.0          NaN        S   31.2750   \n",
       "14   14.0          NaN        S    7.8542   \n",
       "15   55.0          NaN        S   16.0000   \n",
       "16    2.0          NaN        Q   29.1250   \n",
       "17    NaN          NaN        S   13.0000   \n",
       "18   31.0          NaN        S   18.0000   \n",
       "19    NaN          NaN        C    7.2250   \n",
       "20   35.0          NaN        S   26.0000   \n",
       "21   34.0          D56        S   13.0000   \n",
       "22   15.0          NaN        Q    8.0292   \n",
       "23   28.0           A6        S   35.5000   \n",
       "24    8.0          NaN        S   21.0750   \n",
       "25   38.0          NaN        S   31.3875   \n",
       "26    NaN          NaN        C    7.2250   \n",
       "27   19.0  C23 C25 C27        S  263.0000   \n",
       "28    NaN          NaN        Q    7.8792   \n",
       "29    NaN          NaN        S    7.8958   \n",
       "..    ...          ...      ...       ...   \n",
       "388  21.0          NaN        Q    7.7500   \n",
       "389   6.0          NaN        S   21.0750   \n",
       "390  23.0          B24        S   93.5000   \n",
       "391  51.0          D28        S   39.4000   \n",
       "392  13.0          NaN        S   20.2500   \n",
       "393  47.0          NaN        S   10.5000   \n",
       "394  29.0          NaN        S   22.0250   \n",
       "395  18.0          C31        S   60.0000   \n",
       "396  24.0          NaN        Q    7.2500   \n",
       "397  48.0          B41        C   79.2000   \n",
       "398  22.0          NaN        S    7.7750   \n",
       "399  31.0          NaN        Q    7.7333   \n",
       "400  30.0           C7        S  164.8667   \n",
       "401  38.0          NaN        S   21.0000   \n",
       "402  22.0          NaN        C   59.4000   \n",
       "403  17.0          NaN        S   47.1000   \n",
       "404  43.0          D40        C   27.7208   \n",
       "405  20.0          D38        C   13.8625   \n",
       "406  23.0          NaN        S   10.5000   \n",
       "407  50.0          C80        C  211.5000   \n",
       "408   NaN          NaN        Q    7.7208   \n",
       "409   3.0          NaN        S   13.7750   \n",
       "410   NaN          NaN        Q    7.7500   \n",
       "411  37.0          C78        Q   90.0000   \n",
       "412  28.0          NaN        S    7.7750   \n",
       "413   NaN          NaN        S    8.0500   \n",
       "414  39.0         C105        C  108.9000   \n",
       "415  38.5          NaN        S    7.2500   \n",
       "416   NaN          NaN        S    8.0500   \n",
       "417   NaN          NaN        C   22.3583   \n",
       "\n",
       "                                                  Name  Parch  PassengerId  \\\n",
       "0                              Braund, Mr. Owen Harris      0            1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                               Heikkinen, Miss. Laina      0            3   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                             Allen, Mr. William Henry      0            5   \n",
       "5                                     Moran, Mr. James      0            6   \n",
       "6                              McCarthy, Mr. Timothy J      0            7   \n",
       "7                       Palsson, Master. Gosta Leonard      1            8   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      2            9   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)      0           10   \n",
       "10                     Sandstrom, Miss. Marguerite Rut      1           11   \n",
       "11                            Bonnell, Miss. Elizabeth      0           12   \n",
       "12                      Saundercock, Mr. William Henry      0           13   \n",
       "13                         Andersson, Mr. Anders Johan      5           14   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina      0           15   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)       0           16   \n",
       "16                                Rice, Master. Eugene      1           17   \n",
       "17                        Williams, Mr. Charles Eugene      0           18   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...      0           19   \n",
       "19                             Masselmani, Mrs. Fatima      0           20   \n",
       "20                                Fynney, Mr. Joseph J      0           21   \n",
       "21                               Beesley, Mr. Lawrence      0           22   \n",
       "22                         McGowan, Miss. Anna \"Annie\"      0           23   \n",
       "23                        Sloper, Mr. William Thompson      0           24   \n",
       "24                       Palsson, Miss. Torborg Danira      1           25   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...      5           26   \n",
       "26                             Emir, Mr. Farred Chehab      0           27   \n",
       "27                      Fortune, Mr. Charles Alexander      2           28   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"      0           29   \n",
       "29                                 Todoroff, Mr. Lalio      0           30   \n",
       "..                                                 ...    ...          ...   \n",
       "388                               Canavan, Mr. Patrick      0         1280   \n",
       "389                        Palsson, Master. Paul Folke      1         1281   \n",
       "390                         Payne, Mr. Vivian Ponsonby      0         1282   \n",
       "391     Lines, Mrs. Ernest H (Elizabeth Lindsey James)      1         1283   \n",
       "392                      Abbott, Master. Eugene Joseph      2         1284   \n",
       "393                               Gilbert, Mr. William      0         1285   \n",
       "394                           Kink-Heilmann, Mr. Anton      1         1286   \n",
       "395     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)      0         1287   \n",
       "396                               Colbert, Mr. Patrick      0         1288   \n",
       "397  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...      1         1289   \n",
       "398                     Larsson-Rondberg, Mr. Edvard A      0         1290   \n",
       "399                           Conlon, Mr. Thomas Henry      0         1291   \n",
       "400                            Bonnell, Miss. Caroline      0         1292   \n",
       "401                                    Gale, Mr. Harry      0         1293   \n",
       "402                     Gibson, Miss. Dorothy Winifred      1         1294   \n",
       "403                             Carrau, Mr. Jose Pedro      0         1295   \n",
       "404                       Frauenthal, Mr. Isaac Gerald      0         1296   \n",
       "405       Nourney, Mr. Alfred (Baron von Drachstedt\")\"      0         1297   \n",
       "406                          Ware, Mr. William Jeffery      0         1298   \n",
       "407                         Widener, Mr. George Dunton      1         1299   \n",
       "408                    Riordan, Miss. Johanna Hannah\"\"      0         1300   \n",
       "409                          Peacock, Miss. Treasteall      1         1301   \n",
       "410                             Naughton, Miss. Hannah      0         1302   \n",
       "411    Minahan, Mrs. William Edward (Lillian E Thorpe)      0         1303   \n",
       "412                     Henriksson, Miss. Jenny Lovisa      0         1304   \n",
       "413                                 Spector, Mr. Woolf      0         1305   \n",
       "414                       Oliva y Ocana, Dona. Fermina      0         1306   \n",
       "415                       Saether, Mr. Simon Sivertsen      0         1307   \n",
       "416                                Ware, Mr. Frederick      0         1308   \n",
       "417                           Peter, Master. Michael J      1         1309   \n",
       "\n",
       "     Pclass     Sex  SibSp  Survived              Ticket  \n",
       "0         3    male      1       0.0           A/5 21171  \n",
       "1         1  female      1       1.0            PC 17599  \n",
       "2         3  female      0       1.0    STON/O2. 3101282  \n",
       "3         1  female      1       1.0              113803  \n",
       "4         3    male      0       0.0              373450  \n",
       "5         3    male      0       0.0              330877  \n",
       "6         1    male      0       0.0               17463  \n",
       "7         3    male      3       0.0              349909  \n",
       "8         3  female      0       1.0              347742  \n",
       "9         2  female      1       1.0              237736  \n",
       "10        3  female      1       1.0             PP 9549  \n",
       "11        1  female      0       1.0              113783  \n",
       "12        3    male      0       0.0           A/5. 2151  \n",
       "13        3    male      1       0.0              347082  \n",
       "14        3  female      0       0.0              350406  \n",
       "15        2  female      0       1.0              248706  \n",
       "16        3    male      4       0.0              382652  \n",
       "17        2    male      0       1.0              244373  \n",
       "18        3  female      1       0.0              345763  \n",
       "19        3  female      0       1.0                2649  \n",
       "20        2    male      0       0.0              239865  \n",
       "21        2    male      0       1.0              248698  \n",
       "22        3  female      0       1.0              330923  \n",
       "23        1    male      0       1.0              113788  \n",
       "24        3  female      3       0.0              349909  \n",
       "25        3  female      1       1.0              347077  \n",
       "26        3    male      0       0.0                2631  \n",
       "27        1    male      3       0.0               19950  \n",
       "28        3  female      0       1.0              330959  \n",
       "29        3    male      0       0.0              349216  \n",
       "..      ...     ...    ...       ...                 ...  \n",
       "388       3    male      0       NaN              364858  \n",
       "389       3    male      3       NaN              349909  \n",
       "390       1    male      0       NaN               12749  \n",
       "391       1  female      0       NaN            PC 17592  \n",
       "392       3    male      0       NaN           C.A. 2673  \n",
       "393       2    male      0       NaN          C.A. 30769  \n",
       "394       3    male      3       NaN              315153  \n",
       "395       1  female      1       NaN               13695  \n",
       "396       3    male      0       NaN              371109  \n",
       "397       1  female      1       NaN               13567  \n",
       "398       3    male      0       NaN              347065  \n",
       "399       3    male      0       NaN               21332  \n",
       "400       1  female      0       NaN               36928  \n",
       "401       2    male      1       NaN               28664  \n",
       "402       1  female      0       NaN              112378  \n",
       "403       1    male      0       NaN              113059  \n",
       "404       1    male      1       NaN               17765  \n",
       "405       2    male      0       NaN       SC/PARIS 2166  \n",
       "406       2    male      1       NaN               28666  \n",
       "407       1    male      1       NaN              113503  \n",
       "408       3  female      0       NaN              334915  \n",
       "409       3  female      1       NaN  SOTON/O.Q. 3101315  \n",
       "410       3  female      0       NaN              365237  \n",
       "411       1  female      1       NaN               19928  \n",
       "412       3  female      0       NaN              347086  \n",
       "413       3    male      0       NaN           A.5. 3236  \n",
       "414       1  female      0       NaN            PC 17758  \n",
       "415       3    male      0       NaN  SOTON/O.Q. 3101262  \n",
       "416       3    male      0       NaN              359309  \n",
       "417       3    male      1       NaN                2668  \n",
       "\n",
       "[1309 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38383838383838381"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Survived'].sum()/len(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(data_frame):\n",
    "    df_copy = data_frame.copy()\n",
    "    df_copy['AgeModulo'] = df_copy['Age'] % 5\n",
    "    df_copy['IsBasy'] = df_copy['Age'] < 2\n",
    "    df_copy['IsYoungChildren'] = df_copy['Age'] < 7\n",
    "    df_copy['IsChildren'] = df_copy['Age'] < 12\n",
    "    df_copy['IsAdolescent'] = df_copy['Age'] < 18\n",
    "    df_copy['IsOld'] = df_copy['Age'] > 60\n",
    "    df_copy['FareModulo'] = df_copy['Fare'] % 5\n",
    "    df_copy['IsInCabin'] = pd.isnull(df_copy['Cabin']).apply(lambda x : not x)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL = ['Survived']\n",
    "ID = ['PassenderId']\n",
    "FEATURES = ['Pclass', 'Sex', 'AgeModulo', 'SibSp', 'Parch', 'Embarked', 'FareModulo', \n",
    "            'IsBasy', 'IsYoungChildren', 'IsChildren', 'IsAdolescent', 'IsOld',\n",
    "           'IsInCabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert to categorical\n",
    "df[LABEL] = df[LABEL].astype(str)\n",
    "df[FEATURES] = df[FEATURES].astype(str)\n",
    "df_one_hot = pd.get_dummies(df[FEATURES], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_one_hot_train = df_one_hot[0:len(df_train.index)]\n",
    "df_one_hot_test = df_one_hot[len(df_train.index)-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.5\n",
    "hidden_size = 75\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=hidden_size, activation='relu', input_dim=len(df_one_hot.columns)))\n",
    "model.add(Dropout(dropout_rate, noise_shape=None, seed=None))\n",
    "model.add(Dense(units=hidden_size, activation='relu', input_dim=hidden_size))\n",
    "model.add(Dropout(dropout_rate, noise_shape=None, seed=None))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00001, decay=1e-7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "712/712 [==============================] - 0s 266us/step - loss: 0.7130 - acc: 0.4930 - val_loss: 0.6971 - val_acc: 0.4804\n",
      "Epoch 2/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.7163 - acc: 0.4986 - val_loss: 0.6947 - val_acc: 0.4804\n",
      "Epoch 3/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.7080 - acc: 0.5014 - val_loss: 0.6924 - val_acc: 0.5307\n",
      "Epoch 4/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.7074 - acc: 0.4761 - val_loss: 0.6904 - val_acc: 0.5363\n",
      "Epoch 5/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6949 - acc: 0.5239 - val_loss: 0.6882 - val_acc: 0.5475\n",
      "Epoch 6/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.7033 - acc: 0.5126 - val_loss: 0.6860 - val_acc: 0.5587\n",
      "Epoch 7/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.7160 - acc: 0.4930 - val_loss: 0.6841 - val_acc: 0.5587\n",
      "Epoch 8/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.7055 - acc: 0.4986 - val_loss: 0.6821 - val_acc: 0.5810\n",
      "Epoch 9/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.7032 - acc: 0.5014 - val_loss: 0.6802 - val_acc: 0.6257\n",
      "Epoch 10/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6967 - acc: 0.5183 - val_loss: 0.6782 - val_acc: 0.6648\n",
      "Epoch 11/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.7034 - acc: 0.4916 - val_loss: 0.6764 - val_acc: 0.6983\n",
      "Epoch 12/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.7002 - acc: 0.5070 - val_loss: 0.6744 - val_acc: 0.7151\n",
      "Epoch 13/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6861 - acc: 0.5590 - val_loss: 0.6727 - val_acc: 0.7263\n",
      "Epoch 14/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6877 - acc: 0.5590 - val_loss: 0.6708 - val_acc: 0.7318\n",
      "Epoch 15/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6939 - acc: 0.5393 - val_loss: 0.6689 - val_acc: 0.7430\n",
      "Epoch 16/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6852 - acc: 0.5463 - val_loss: 0.6673 - val_acc: 0.7430\n",
      "Epoch 17/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.7004 - acc: 0.5112 - val_loss: 0.6656 - val_acc: 0.7430\n",
      "Epoch 18/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6977 - acc: 0.5253 - val_loss: 0.6639 - val_acc: 0.7486\n",
      "Epoch 19/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6894 - acc: 0.5674 - val_loss: 0.6623 - val_acc: 0.7542\n",
      "Epoch 20/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.6872 - acc: 0.5351 - val_loss: 0.6608 - val_acc: 0.7486\n",
      "Epoch 21/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6852 - acc: 0.5421 - val_loss: 0.6594 - val_acc: 0.7430\n",
      "Epoch 22/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6827 - acc: 0.5576 - val_loss: 0.6579 - val_acc: 0.7374\n",
      "Epoch 23/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6918 - acc: 0.5393 - val_loss: 0.6565 - val_acc: 0.7263\n",
      "Epoch 24/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6747 - acc: 0.5815 - val_loss: 0.6550 - val_acc: 0.7095\n",
      "Epoch 25/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6817 - acc: 0.5351 - val_loss: 0.6534 - val_acc: 0.7095\n",
      "Epoch 26/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6820 - acc: 0.5478 - val_loss: 0.6520 - val_acc: 0.7095\n",
      "Epoch 27/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6807 - acc: 0.5927 - val_loss: 0.6508 - val_acc: 0.7039\n",
      "Epoch 28/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6867 - acc: 0.5435 - val_loss: 0.6495 - val_acc: 0.6983\n",
      "Epoch 29/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6836 - acc: 0.5492 - val_loss: 0.6483 - val_acc: 0.6927\n",
      "Epoch 30/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6813 - acc: 0.5660 - val_loss: 0.6470 - val_acc: 0.6816\n",
      "Epoch 31/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6748 - acc: 0.5576 - val_loss: 0.6458 - val_acc: 0.6760\n",
      "Epoch 32/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6771 - acc: 0.5730 - val_loss: 0.6445 - val_acc: 0.6760\n",
      "Epoch 33/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6679 - acc: 0.6096 - val_loss: 0.6433 - val_acc: 0.6760\n",
      "Epoch 34/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6745 - acc: 0.5744 - val_loss: 0.6423 - val_acc: 0.6816\n",
      "Epoch 35/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.6684 - acc: 0.5941 - val_loss: 0.6411 - val_acc: 0.6704\n",
      "Epoch 36/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6746 - acc: 0.6025 - val_loss: 0.6400 - val_acc: 0.6704\n",
      "Epoch 37/1000\n",
      "712/712 [==============================] - 0s 55us/step - loss: 0.6628 - acc: 0.5730 - val_loss: 0.6389 - val_acc: 0.6760\n",
      "Epoch 38/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6686 - acc: 0.5758 - val_loss: 0.6377 - val_acc: 0.6760\n",
      "Epoch 39/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6759 - acc: 0.5646 - val_loss: 0.6365 - val_acc: 0.6704\n",
      "Epoch 40/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6721 - acc: 0.5801 - val_loss: 0.6354 - val_acc: 0.6704\n",
      "Epoch 41/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6608 - acc: 0.5927 - val_loss: 0.6343 - val_acc: 0.6704\n",
      "Epoch 42/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6650 - acc: 0.5885 - val_loss: 0.6331 - val_acc: 0.6704\n",
      "Epoch 43/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6688 - acc: 0.5674 - val_loss: 0.6321 - val_acc: 0.6704\n",
      "Epoch 44/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6657 - acc: 0.5857 - val_loss: 0.6311 - val_acc: 0.6704\n",
      "Epoch 45/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6632 - acc: 0.5913 - val_loss: 0.6300 - val_acc: 0.6704\n",
      "Epoch 46/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6613 - acc: 0.5801 - val_loss: 0.6289 - val_acc: 0.6704\n",
      "Epoch 47/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6667 - acc: 0.5983 - val_loss: 0.6280 - val_acc: 0.6704\n",
      "Epoch 48/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6621 - acc: 0.6138 - val_loss: 0.6270 - val_acc: 0.6704\n",
      "Epoch 49/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6550 - acc: 0.6096 - val_loss: 0.6259 - val_acc: 0.6760\n",
      "Epoch 50/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6522 - acc: 0.6250 - val_loss: 0.6248 - val_acc: 0.6760\n",
      "Epoch 51/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6586 - acc: 0.6194 - val_loss: 0.6238 - val_acc: 0.6760\n",
      "Epoch 52/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6683 - acc: 0.5843 - val_loss: 0.6229 - val_acc: 0.6760\n",
      "Epoch 53/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6475 - acc: 0.6376 - val_loss: 0.6220 - val_acc: 0.6760\n",
      "Epoch 54/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6605 - acc: 0.6180 - val_loss: 0.6210 - val_acc: 0.6760\n",
      "Epoch 55/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6523 - acc: 0.6138 - val_loss: 0.6201 - val_acc: 0.6760\n",
      "Epoch 56/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6581 - acc: 0.6039 - val_loss: 0.6193 - val_acc: 0.6760\n",
      "Epoch 57/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6523 - acc: 0.6306 - val_loss: 0.6185 - val_acc: 0.6760\n",
      "Epoch 58/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6510 - acc: 0.6180 - val_loss: 0.6175 - val_acc: 0.6760\n",
      "Epoch 59/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6385 - acc: 0.6320 - val_loss: 0.6165 - val_acc: 0.6760\n",
      "Epoch 60/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6506 - acc: 0.6222 - val_loss: 0.6156 - val_acc: 0.6760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6585 - acc: 0.6138 - val_loss: 0.6148 - val_acc: 0.6760\n",
      "Epoch 62/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6491 - acc: 0.6348 - val_loss: 0.6140 - val_acc: 0.6760\n",
      "Epoch 63/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6411 - acc: 0.6433 - val_loss: 0.6131 - val_acc: 0.6760\n",
      "Epoch 64/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6450 - acc: 0.6531 - val_loss: 0.6122 - val_acc: 0.6760\n",
      "Epoch 65/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6367 - acc: 0.6264 - val_loss: 0.6112 - val_acc: 0.6704\n",
      "Epoch 66/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6504 - acc: 0.6166 - val_loss: 0.6105 - val_acc: 0.6704\n",
      "Epoch 67/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6493 - acc: 0.6292 - val_loss: 0.6095 - val_acc: 0.6704\n",
      "Epoch 68/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6545 - acc: 0.6222 - val_loss: 0.6087 - val_acc: 0.6704\n",
      "Epoch 69/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6424 - acc: 0.6433 - val_loss: 0.6081 - val_acc: 0.6704\n",
      "Epoch 70/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6534 - acc: 0.6096 - val_loss: 0.6074 - val_acc: 0.6704\n",
      "Epoch 71/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6493 - acc: 0.6489 - val_loss: 0.6064 - val_acc: 0.6704\n",
      "Epoch 72/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6478 - acc: 0.6306 - val_loss: 0.6054 - val_acc: 0.6704\n",
      "Epoch 73/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6434 - acc: 0.6264 - val_loss: 0.6046 - val_acc: 0.6704\n",
      "Epoch 74/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6540 - acc: 0.6250 - val_loss: 0.6038 - val_acc: 0.6704\n",
      "Epoch 75/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6418 - acc: 0.6404 - val_loss: 0.6031 - val_acc: 0.6704\n",
      "Epoch 76/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6351 - acc: 0.6517 - val_loss: 0.6021 - val_acc: 0.6704\n",
      "Epoch 77/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6369 - acc: 0.6489 - val_loss: 0.6014 - val_acc: 0.6704\n",
      "Epoch 78/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.6392 - acc: 0.6573 - val_loss: 0.6006 - val_acc: 0.6704\n",
      "Epoch 79/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6428 - acc: 0.6404 - val_loss: 0.5998 - val_acc: 0.6704\n",
      "Epoch 80/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6480 - acc: 0.6208 - val_loss: 0.5989 - val_acc: 0.6704\n",
      "Epoch 81/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6412 - acc: 0.6503 - val_loss: 0.5982 - val_acc: 0.6704\n",
      "Epoch 82/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6404 - acc: 0.6475 - val_loss: 0.5973 - val_acc: 0.6704\n",
      "Epoch 83/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6439 - acc: 0.6236 - val_loss: 0.5965 - val_acc: 0.6704\n",
      "Epoch 84/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6414 - acc: 0.6334 - val_loss: 0.5957 - val_acc: 0.6704\n",
      "Epoch 85/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6358 - acc: 0.6587 - val_loss: 0.5949 - val_acc: 0.6760\n",
      "Epoch 86/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6518 - acc: 0.6376 - val_loss: 0.5943 - val_acc: 0.6760\n",
      "Epoch 87/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6286 - acc: 0.6545 - val_loss: 0.5936 - val_acc: 0.6760\n",
      "Epoch 88/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6293 - acc: 0.6517 - val_loss: 0.5929 - val_acc: 0.6816\n",
      "Epoch 89/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6299 - acc: 0.6390 - val_loss: 0.5921 - val_acc: 0.6816\n",
      "Epoch 90/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6346 - acc: 0.6320 - val_loss: 0.5913 - val_acc: 0.6816\n",
      "Epoch 91/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6279 - acc: 0.6573 - val_loss: 0.5906 - val_acc: 0.6872\n",
      "Epoch 92/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6299 - acc: 0.6362 - val_loss: 0.5898 - val_acc: 0.6872\n",
      "Epoch 93/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6343 - acc: 0.6517 - val_loss: 0.5890 - val_acc: 0.6927\n",
      "Epoch 94/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6385 - acc: 0.6264 - val_loss: 0.5883 - val_acc: 0.6927\n",
      "Epoch 95/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6206 - acc: 0.6475 - val_loss: 0.5877 - val_acc: 0.6927\n",
      "Epoch 96/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6298 - acc: 0.6573 - val_loss: 0.5870 - val_acc: 0.6927\n",
      "Epoch 97/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6481 - acc: 0.6587 - val_loss: 0.5864 - val_acc: 0.6927\n",
      "Epoch 98/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6292 - acc: 0.6756 - val_loss: 0.5857 - val_acc: 0.6983\n",
      "Epoch 99/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6208 - acc: 0.6629 - val_loss: 0.5849 - val_acc: 0.6983\n",
      "Epoch 100/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6240 - acc: 0.6587 - val_loss: 0.5842 - val_acc: 0.7039\n",
      "Epoch 101/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6310 - acc: 0.6657 - val_loss: 0.5835 - val_acc: 0.7039\n",
      "Epoch 102/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6294 - acc: 0.6489 - val_loss: 0.5828 - val_acc: 0.7039\n",
      "Epoch 103/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6225 - acc: 0.6770 - val_loss: 0.5819 - val_acc: 0.7039\n",
      "Epoch 104/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6208 - acc: 0.6671 - val_loss: 0.5812 - val_acc: 0.7039\n",
      "Epoch 105/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6197 - acc: 0.6489 - val_loss: 0.5806 - val_acc: 0.7095\n",
      "Epoch 106/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.6203 - acc: 0.6643 - val_loss: 0.5798 - val_acc: 0.7095\n",
      "Epoch 107/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6237 - acc: 0.6545 - val_loss: 0.5791 - val_acc: 0.7151\n",
      "Epoch 108/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6146 - acc: 0.6587 - val_loss: 0.5784 - val_acc: 0.7151\n",
      "Epoch 109/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6243 - acc: 0.6629 - val_loss: 0.5776 - val_acc: 0.7207\n",
      "Epoch 110/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6313 - acc: 0.6559 - val_loss: 0.5769 - val_acc: 0.7263\n",
      "Epoch 111/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6199 - acc: 0.6587 - val_loss: 0.5762 - val_acc: 0.7318\n",
      "Epoch 112/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6256 - acc: 0.6784 - val_loss: 0.5756 - val_acc: 0.7318\n",
      "Epoch 113/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6175 - acc: 0.6657 - val_loss: 0.5749 - val_acc: 0.7374\n",
      "Epoch 114/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6176 - acc: 0.6517 - val_loss: 0.5741 - val_acc: 0.7374\n",
      "Epoch 115/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6257 - acc: 0.6573 - val_loss: 0.5735 - val_acc: 0.7374\n",
      "Epoch 116/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6229 - acc: 0.6531 - val_loss: 0.5728 - val_acc: 0.7374\n",
      "Epoch 117/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6138 - acc: 0.6798 - val_loss: 0.5721 - val_acc: 0.7486\n",
      "Epoch 118/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6187 - acc: 0.6896 - val_loss: 0.5713 - val_acc: 0.7486\n",
      "Epoch 119/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6165 - acc: 0.6657 - val_loss: 0.5705 - val_acc: 0.7486\n",
      "Epoch 120/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6213 - acc: 0.6868 - val_loss: 0.5697 - val_acc: 0.7486\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 71us/step - loss: 0.6137 - acc: 0.6784 - val_loss: 0.5689 - val_acc: 0.7542\n",
      "Epoch 122/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6191 - acc: 0.6854 - val_loss: 0.5680 - val_acc: 0.7542\n",
      "Epoch 123/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6223 - acc: 0.6629 - val_loss: 0.5673 - val_acc: 0.7598\n",
      "Epoch 124/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6036 - acc: 0.6980 - val_loss: 0.5665 - val_acc: 0.7598\n",
      "Epoch 125/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6110 - acc: 0.6868 - val_loss: 0.5657 - val_acc: 0.7542\n",
      "Epoch 126/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6184 - acc: 0.6756 - val_loss: 0.5650 - val_acc: 0.7542\n",
      "Epoch 127/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6097 - acc: 0.6742 - val_loss: 0.5643 - val_acc: 0.7542\n",
      "Epoch 128/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6062 - acc: 0.6896 - val_loss: 0.5635 - val_acc: 0.7542\n",
      "Epoch 129/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6098 - acc: 0.6854 - val_loss: 0.5628 - val_acc: 0.7542\n",
      "Epoch 130/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6182 - acc: 0.6643 - val_loss: 0.5620 - val_acc: 0.7598\n",
      "Epoch 131/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6024 - acc: 0.6685 - val_loss: 0.5612 - val_acc: 0.7598\n",
      "Epoch 132/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6138 - acc: 0.6770 - val_loss: 0.5604 - val_acc: 0.7598\n",
      "Epoch 133/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6012 - acc: 0.6854 - val_loss: 0.5595 - val_acc: 0.7598\n",
      "Epoch 134/1000\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.6144 - acc: 0.6671 - val_loss: 0.5587 - val_acc: 0.7598\n",
      "Epoch 135/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6167 - acc: 0.6896 - val_loss: 0.5580 - val_acc: 0.7598\n",
      "Epoch 136/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6120 - acc: 0.6601 - val_loss: 0.5573 - val_acc: 0.7654\n",
      "Epoch 137/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6060 - acc: 0.6826 - val_loss: 0.5564 - val_acc: 0.7654\n",
      "Epoch 138/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6138 - acc: 0.6770 - val_loss: 0.5556 - val_acc: 0.7654\n",
      "Epoch 139/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.6005 - acc: 0.6882 - val_loss: 0.5549 - val_acc: 0.7654\n",
      "Epoch 140/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5912 - acc: 0.6924 - val_loss: 0.5541 - val_acc: 0.7709\n",
      "Epoch 141/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6007 - acc: 0.6868 - val_loss: 0.5533 - val_acc: 0.7709\n",
      "Epoch 142/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6056 - acc: 0.6826 - val_loss: 0.5525 - val_acc: 0.7765\n",
      "Epoch 143/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6124 - acc: 0.6770 - val_loss: 0.5517 - val_acc: 0.7765\n",
      "Epoch 144/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.6069 - acc: 0.6798 - val_loss: 0.5510 - val_acc: 0.7765\n",
      "Epoch 145/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6026 - acc: 0.7037 - val_loss: 0.5502 - val_acc: 0.7765\n",
      "Epoch 146/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5975 - acc: 0.6910 - val_loss: 0.5494 - val_acc: 0.7765\n",
      "Epoch 147/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6164 - acc: 0.6882 - val_loss: 0.5487 - val_acc: 0.7765\n",
      "Epoch 148/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.6015 - acc: 0.7065 - val_loss: 0.5481 - val_acc: 0.7765\n",
      "Epoch 149/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5958 - acc: 0.6854 - val_loss: 0.5473 - val_acc: 0.7765\n",
      "Epoch 150/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5866 - acc: 0.7163 - val_loss: 0.5464 - val_acc: 0.7765\n",
      "Epoch 151/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5937 - acc: 0.6924 - val_loss: 0.5456 - val_acc: 0.7765\n",
      "Epoch 152/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.6042 - acc: 0.7022 - val_loss: 0.5449 - val_acc: 0.7765\n",
      "Epoch 153/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6017 - acc: 0.6924 - val_loss: 0.5442 - val_acc: 0.7765\n",
      "Epoch 154/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6042 - acc: 0.6840 - val_loss: 0.5435 - val_acc: 0.7765\n",
      "Epoch 155/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5924 - acc: 0.6896 - val_loss: 0.5428 - val_acc: 0.7765\n",
      "Epoch 156/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6012 - acc: 0.6924 - val_loss: 0.5420 - val_acc: 0.7765\n",
      "Epoch 157/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5924 - acc: 0.6924 - val_loss: 0.5413 - val_acc: 0.7765\n",
      "Epoch 158/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5972 - acc: 0.7065 - val_loss: 0.5407 - val_acc: 0.7821\n",
      "Epoch 159/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5861 - acc: 0.7065 - val_loss: 0.5400 - val_acc: 0.7821\n",
      "Epoch 160/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6049 - acc: 0.6868 - val_loss: 0.5393 - val_acc: 0.7821\n",
      "Epoch 161/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6006 - acc: 0.7022 - val_loss: 0.5387 - val_acc: 0.7765\n",
      "Epoch 162/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5908 - acc: 0.6868 - val_loss: 0.5380 - val_acc: 0.7765\n",
      "Epoch 163/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.6035 - acc: 0.6896 - val_loss: 0.5373 - val_acc: 0.7765\n",
      "Epoch 164/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5921 - acc: 0.7022 - val_loss: 0.5367 - val_acc: 0.7765\n",
      "Epoch 165/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5994 - acc: 0.6938 - val_loss: 0.5361 - val_acc: 0.7821\n",
      "Epoch 166/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5972 - acc: 0.6812 - val_loss: 0.5354 - val_acc: 0.7821\n",
      "Epoch 167/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5922 - acc: 0.6896 - val_loss: 0.5347 - val_acc: 0.7877\n",
      "Epoch 168/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6041 - acc: 0.6840 - val_loss: 0.5339 - val_acc: 0.7877\n",
      "Epoch 169/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5896 - acc: 0.7093 - val_loss: 0.5333 - val_acc: 0.8045\n",
      "Epoch 170/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6052 - acc: 0.6994 - val_loss: 0.5327 - val_acc: 0.8045\n",
      "Epoch 171/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5891 - acc: 0.7177 - val_loss: 0.5321 - val_acc: 0.8101\n",
      "Epoch 172/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5850 - acc: 0.7037 - val_loss: 0.5314 - val_acc: 0.8101\n",
      "Epoch 173/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5913 - acc: 0.7121 - val_loss: 0.5306 - val_acc: 0.8101\n",
      "Epoch 174/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5958 - acc: 0.6868 - val_loss: 0.5300 - val_acc: 0.8101\n",
      "Epoch 175/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5859 - acc: 0.7275 - val_loss: 0.5294 - val_acc: 0.8156\n",
      "Epoch 176/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5973 - acc: 0.6994 - val_loss: 0.5288 - val_acc: 0.8156\n",
      "Epoch 177/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5704 - acc: 0.7542 - val_loss: 0.5281 - val_acc: 0.8156\n",
      "Epoch 178/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5821 - acc: 0.7149 - val_loss: 0.5273 - val_acc: 0.8156\n",
      "Epoch 179/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5957 - acc: 0.6980 - val_loss: 0.5267 - val_acc: 0.8156\n",
      "Epoch 180/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5680 - acc: 0.7416 - val_loss: 0.5259 - val_acc: 0.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5829 - acc: 0.7219 - val_loss: 0.5251 - val_acc: 0.8156\n",
      "Epoch 182/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.5782 - acc: 0.7079 - val_loss: 0.5243 - val_acc: 0.8156\n",
      "Epoch 183/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5767 - acc: 0.7191 - val_loss: 0.5234 - val_acc: 0.8156\n",
      "Epoch 184/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5756 - acc: 0.7149 - val_loss: 0.5226 - val_acc: 0.8156\n",
      "Epoch 185/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5833 - acc: 0.7008 - val_loss: 0.5218 - val_acc: 0.8156\n",
      "Epoch 186/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5839 - acc: 0.7037 - val_loss: 0.5211 - val_acc: 0.8156\n",
      "Epoch 187/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5802 - acc: 0.7191 - val_loss: 0.5204 - val_acc: 0.8156\n",
      "Epoch 188/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5791 - acc: 0.6980 - val_loss: 0.5197 - val_acc: 0.8156\n",
      "Epoch 189/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5897 - acc: 0.7219 - val_loss: 0.5190 - val_acc: 0.8156\n",
      "Epoch 190/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5717 - acc: 0.7261 - val_loss: 0.5183 - val_acc: 0.8156\n",
      "Epoch 191/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5852 - acc: 0.6966 - val_loss: 0.5177 - val_acc: 0.8156\n",
      "Epoch 192/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5811 - acc: 0.7205 - val_loss: 0.5170 - val_acc: 0.8212\n",
      "Epoch 193/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5785 - acc: 0.7163 - val_loss: 0.5163 - val_acc: 0.8212\n",
      "Epoch 194/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5712 - acc: 0.7416 - val_loss: 0.5157 - val_acc: 0.8212\n",
      "Epoch 195/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5788 - acc: 0.7121 - val_loss: 0.5150 - val_acc: 0.8212\n",
      "Epoch 196/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5663 - acc: 0.7374 - val_loss: 0.5143 - val_acc: 0.8212\n",
      "Epoch 197/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5769 - acc: 0.7205 - val_loss: 0.5136 - val_acc: 0.8212\n",
      "Epoch 198/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5678 - acc: 0.7402 - val_loss: 0.5128 - val_acc: 0.8212\n",
      "Epoch 199/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5743 - acc: 0.7219 - val_loss: 0.5122 - val_acc: 0.8212\n",
      "Epoch 200/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5681 - acc: 0.7289 - val_loss: 0.5114 - val_acc: 0.8212\n",
      "Epoch 201/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5883 - acc: 0.7177 - val_loss: 0.5110 - val_acc: 0.8212\n",
      "Epoch 202/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5736 - acc: 0.7079 - val_loss: 0.5102 - val_acc: 0.8212\n",
      "Epoch 203/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5686 - acc: 0.7374 - val_loss: 0.5096 - val_acc: 0.8212\n",
      "Epoch 204/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5685 - acc: 0.7219 - val_loss: 0.5089 - val_acc: 0.8212\n",
      "Epoch 205/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5754 - acc: 0.7177 - val_loss: 0.5081 - val_acc: 0.8212\n",
      "Epoch 206/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5701 - acc: 0.7360 - val_loss: 0.5074 - val_acc: 0.8212\n",
      "Epoch 207/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5779 - acc: 0.7093 - val_loss: 0.5068 - val_acc: 0.8212\n",
      "Epoch 208/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5693 - acc: 0.7444 - val_loss: 0.5062 - val_acc: 0.8212\n",
      "Epoch 209/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5801 - acc: 0.7163 - val_loss: 0.5055 - val_acc: 0.8212\n",
      "Epoch 210/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5739 - acc: 0.7163 - val_loss: 0.5049 - val_acc: 0.8212\n",
      "Epoch 211/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5651 - acc: 0.7374 - val_loss: 0.5043 - val_acc: 0.8212\n",
      "Epoch 212/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5580 - acc: 0.7388 - val_loss: 0.5036 - val_acc: 0.8268\n",
      "Epoch 213/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5596 - acc: 0.7486 - val_loss: 0.5029 - val_acc: 0.8324\n",
      "Epoch 214/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5706 - acc: 0.7135 - val_loss: 0.5023 - val_acc: 0.8324\n",
      "Epoch 215/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5612 - acc: 0.7458 - val_loss: 0.5018 - val_acc: 0.8324\n",
      "Epoch 216/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5532 - acc: 0.7444 - val_loss: 0.5011 - val_acc: 0.8324\n",
      "Epoch 217/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5753 - acc: 0.7247 - val_loss: 0.5004 - val_acc: 0.8324\n",
      "Epoch 218/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5609 - acc: 0.7219 - val_loss: 0.4998 - val_acc: 0.8324\n",
      "Epoch 219/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5722 - acc: 0.7233 - val_loss: 0.4992 - val_acc: 0.8324\n",
      "Epoch 220/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5664 - acc: 0.7275 - val_loss: 0.4986 - val_acc: 0.8324\n",
      "Epoch 221/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5691 - acc: 0.7261 - val_loss: 0.4981 - val_acc: 0.8324\n",
      "Epoch 222/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5673 - acc: 0.7388 - val_loss: 0.4975 - val_acc: 0.8324\n",
      "Epoch 223/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5694 - acc: 0.7163 - val_loss: 0.4970 - val_acc: 0.8324\n",
      "Epoch 224/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5392 - acc: 0.7570 - val_loss: 0.4962 - val_acc: 0.8324\n",
      "Epoch 225/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5674 - acc: 0.7402 - val_loss: 0.4956 - val_acc: 0.8324\n",
      "Epoch 226/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5593 - acc: 0.7233 - val_loss: 0.4949 - val_acc: 0.8324\n",
      "Epoch 227/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5717 - acc: 0.7317 - val_loss: 0.4944 - val_acc: 0.8324\n",
      "Epoch 228/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5594 - acc: 0.7402 - val_loss: 0.4939 - val_acc: 0.8324\n",
      "Epoch 229/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5475 - acc: 0.7598 - val_loss: 0.4931 - val_acc: 0.8324\n",
      "Epoch 230/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5569 - acc: 0.7219 - val_loss: 0.4925 - val_acc: 0.8324\n",
      "Epoch 231/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5503 - acc: 0.7261 - val_loss: 0.4918 - val_acc: 0.8324\n",
      "Epoch 232/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5500 - acc: 0.7430 - val_loss: 0.4911 - val_acc: 0.8324\n",
      "Epoch 233/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5591 - acc: 0.7388 - val_loss: 0.4904 - val_acc: 0.8324\n",
      "Epoch 234/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5625 - acc: 0.7331 - val_loss: 0.4898 - val_acc: 0.8324\n",
      "Epoch 235/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5660 - acc: 0.7219 - val_loss: 0.4894 - val_acc: 0.8324\n",
      "Epoch 236/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5620 - acc: 0.7430 - val_loss: 0.4888 - val_acc: 0.8324\n",
      "Epoch 237/1000\n",
      "712/712 [==============================] - 0s 55us/step - loss: 0.5504 - acc: 0.7346 - val_loss: 0.4883 - val_acc: 0.8324\n",
      "Epoch 238/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5406 - acc: 0.7416 - val_loss: 0.4876 - val_acc: 0.8324\n",
      "Epoch 239/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5656 - acc: 0.7388 - val_loss: 0.4870 - val_acc: 0.8324\n",
      "Epoch 240/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5423 - acc: 0.7514 - val_loss: 0.4863 - val_acc: 0.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5521 - acc: 0.7430 - val_loss: 0.4856 - val_acc: 0.8324\n",
      "Epoch 242/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5564 - acc: 0.7472 - val_loss: 0.4850 - val_acc: 0.8380\n",
      "Epoch 243/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5536 - acc: 0.7303 - val_loss: 0.4844 - val_acc: 0.8380\n",
      "Epoch 244/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5597 - acc: 0.7388 - val_loss: 0.4838 - val_acc: 0.8380\n",
      "Epoch 245/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5358 - acc: 0.7556 - val_loss: 0.4831 - val_acc: 0.8380\n",
      "Epoch 246/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5546 - acc: 0.7416 - val_loss: 0.4824 - val_acc: 0.8380\n",
      "Epoch 247/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5373 - acc: 0.7626 - val_loss: 0.4819 - val_acc: 0.8380\n",
      "Epoch 248/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5423 - acc: 0.7458 - val_loss: 0.4811 - val_acc: 0.8380\n",
      "Epoch 249/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5425 - acc: 0.7612 - val_loss: 0.4805 - val_acc: 0.8380\n",
      "Epoch 250/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5467 - acc: 0.7346 - val_loss: 0.4799 - val_acc: 0.8436\n",
      "Epoch 251/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5505 - acc: 0.7402 - val_loss: 0.4793 - val_acc: 0.8436\n",
      "Epoch 252/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5393 - acc: 0.7669 - val_loss: 0.4786 - val_acc: 0.8436\n",
      "Epoch 253/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5575 - acc: 0.7416 - val_loss: 0.4780 - val_acc: 0.8436\n",
      "Epoch 254/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5509 - acc: 0.7303 - val_loss: 0.4774 - val_acc: 0.8436\n",
      "Epoch 255/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5345 - acc: 0.7683 - val_loss: 0.4768 - val_acc: 0.8436\n",
      "Epoch 256/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5412 - acc: 0.7626 - val_loss: 0.4761 - val_acc: 0.8436\n",
      "Epoch 257/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5520 - acc: 0.7205 - val_loss: 0.4755 - val_acc: 0.8436\n",
      "Epoch 258/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5636 - acc: 0.7374 - val_loss: 0.4751 - val_acc: 0.8436\n",
      "Epoch 259/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5424 - acc: 0.7556 - val_loss: 0.4746 - val_acc: 0.8436\n",
      "Epoch 260/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5457 - acc: 0.7528 - val_loss: 0.4741 - val_acc: 0.8436\n",
      "Epoch 261/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5576 - acc: 0.7612 - val_loss: 0.4739 - val_acc: 0.8436\n",
      "Epoch 262/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.5404 - acc: 0.7711 - val_loss: 0.4733 - val_acc: 0.8436\n",
      "Epoch 263/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5441 - acc: 0.7472 - val_loss: 0.4726 - val_acc: 0.8436\n",
      "Epoch 264/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5318 - acc: 0.7584 - val_loss: 0.4720 - val_acc: 0.8436\n",
      "Epoch 265/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5552 - acc: 0.7472 - val_loss: 0.4715 - val_acc: 0.8436\n",
      "Epoch 266/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.5494 - acc: 0.7388 - val_loss: 0.4711 - val_acc: 0.8436\n",
      "Epoch 267/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5297 - acc: 0.7683 - val_loss: 0.4705 - val_acc: 0.8436\n",
      "Epoch 268/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5389 - acc: 0.7514 - val_loss: 0.4700 - val_acc: 0.8436\n",
      "Epoch 269/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5399 - acc: 0.7697 - val_loss: 0.4694 - val_acc: 0.8436\n",
      "Epoch 270/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5547 - acc: 0.7402 - val_loss: 0.4689 - val_acc: 0.8436\n",
      "Epoch 271/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5435 - acc: 0.7514 - val_loss: 0.4686 - val_acc: 0.8436\n",
      "Epoch 272/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5420 - acc: 0.7612 - val_loss: 0.4680 - val_acc: 0.8436\n",
      "Epoch 273/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5431 - acc: 0.7444 - val_loss: 0.4675 - val_acc: 0.8436\n",
      "Epoch 274/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5472 - acc: 0.7458 - val_loss: 0.4670 - val_acc: 0.8436\n",
      "Epoch 275/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5315 - acc: 0.7500 - val_loss: 0.4665 - val_acc: 0.8436\n",
      "Epoch 276/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5325 - acc: 0.7640 - val_loss: 0.4659 - val_acc: 0.8436\n",
      "Epoch 277/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5441 - acc: 0.7626 - val_loss: 0.4654 - val_acc: 0.8436\n",
      "Epoch 278/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5405 - acc: 0.7528 - val_loss: 0.4648 - val_acc: 0.8436\n",
      "Epoch 279/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5541 - acc: 0.7261 - val_loss: 0.4645 - val_acc: 0.8436\n",
      "Epoch 280/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5439 - acc: 0.7472 - val_loss: 0.4639 - val_acc: 0.8436\n",
      "Epoch 281/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5415 - acc: 0.7402 - val_loss: 0.4634 - val_acc: 0.8436\n",
      "Epoch 282/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5534 - acc: 0.718 - 0s 64us/step - loss: 0.5360 - acc: 0.7654 - val_loss: 0.4629 - val_acc: 0.8436\n",
      "Epoch 283/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5523 - acc: 0.7289 - val_loss: 0.4625 - val_acc: 0.8436\n",
      "Epoch 284/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5323 - acc: 0.7626 - val_loss: 0.4620 - val_acc: 0.8436\n",
      "Epoch 285/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5261 - acc: 0.7697 - val_loss: 0.4615 - val_acc: 0.8436\n",
      "Epoch 286/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5241 - acc: 0.7654 - val_loss: 0.4610 - val_acc: 0.8436\n",
      "Epoch 287/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5307 - acc: 0.7654 - val_loss: 0.4605 - val_acc: 0.8436\n",
      "Epoch 288/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5425 - acc: 0.7626 - val_loss: 0.4599 - val_acc: 0.8436\n",
      "Epoch 289/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5207 - acc: 0.7893 - val_loss: 0.4593 - val_acc: 0.8436\n",
      "Epoch 290/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5409 - acc: 0.7556 - val_loss: 0.4589 - val_acc: 0.8492\n",
      "Epoch 291/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5310 - acc: 0.7640 - val_loss: 0.4584 - val_acc: 0.8492\n",
      "Epoch 292/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5444 - acc: 0.7331 - val_loss: 0.4580 - val_acc: 0.8492\n",
      "Epoch 293/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5447 - acc: 0.7598 - val_loss: 0.4577 - val_acc: 0.8492\n",
      "Epoch 294/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5424 - acc: 0.7528 - val_loss: 0.4574 - val_acc: 0.8492\n",
      "Epoch 295/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.5432 - acc: 0.7514 - val_loss: 0.4570 - val_acc: 0.8492\n",
      "Epoch 296/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5266 - acc: 0.7809 - val_loss: 0.4565 - val_acc: 0.8492\n",
      "Epoch 297/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5236 - acc: 0.7865 - val_loss: 0.4560 - val_acc: 0.8492\n",
      "Epoch 298/1000\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.5302 - acc: 0.7486 - val_loss: 0.4554 - val_acc: 0.8492\n",
      "Epoch 299/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5304 - acc: 0.7753 - val_loss: 0.4549 - val_acc: 0.8492\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 66us/step - loss: 0.5464 - acc: 0.7556 - val_loss: 0.4546 - val_acc: 0.8492\n",
      "Epoch 301/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5338 - acc: 0.7584 - val_loss: 0.4541 - val_acc: 0.8492\n",
      "Epoch 302/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5196 - acc: 0.7753 - val_loss: 0.4536 - val_acc: 0.8492\n",
      "Epoch 303/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5326 - acc: 0.7612 - val_loss: 0.4530 - val_acc: 0.8492\n",
      "Epoch 304/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5301 - acc: 0.7669 - val_loss: 0.4526 - val_acc: 0.8547\n",
      "Epoch 305/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5201 - acc: 0.7584 - val_loss: 0.4522 - val_acc: 0.8547\n",
      "Epoch 306/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5207 - acc: 0.7725 - val_loss: 0.4517 - val_acc: 0.8547\n",
      "Epoch 307/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5263 - acc: 0.7472 - val_loss: 0.4512 - val_acc: 0.8547\n",
      "Epoch 308/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5162 - acc: 0.7711 - val_loss: 0.4507 - val_acc: 0.8547\n",
      "Epoch 309/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5153 - acc: 0.7823 - val_loss: 0.4502 - val_acc: 0.8547\n",
      "Epoch 310/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5334 - acc: 0.7486 - val_loss: 0.4498 - val_acc: 0.8547\n",
      "Epoch 311/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5188 - acc: 0.7570 - val_loss: 0.4492 - val_acc: 0.8547\n",
      "Epoch 312/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5268 - acc: 0.7683 - val_loss: 0.4489 - val_acc: 0.8547\n",
      "Epoch 313/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5095 - acc: 0.7697 - val_loss: 0.4484 - val_acc: 0.8547\n",
      "Epoch 314/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5155 - acc: 0.7795 - val_loss: 0.4478 - val_acc: 0.8547\n",
      "Epoch 315/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5132 - acc: 0.7992 - val_loss: 0.4474 - val_acc: 0.8547\n",
      "Epoch 316/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5150 - acc: 0.7809 - val_loss: 0.4469 - val_acc: 0.8547\n",
      "Epoch 317/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5343 - acc: 0.7767 - val_loss: 0.4466 - val_acc: 0.8547\n",
      "Epoch 318/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5339 - acc: 0.7570 - val_loss: 0.4463 - val_acc: 0.8547\n",
      "Epoch 319/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5305 - acc: 0.7683 - val_loss: 0.4460 - val_acc: 0.8547\n",
      "Epoch 320/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5268 - acc: 0.7626 - val_loss: 0.4456 - val_acc: 0.8492\n",
      "Epoch 321/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5196 - acc: 0.7697 - val_loss: 0.4452 - val_acc: 0.8492\n",
      "Epoch 322/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5350 - acc: 0.7570 - val_loss: 0.4449 - val_acc: 0.8492\n",
      "Epoch 323/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5310 - acc: 0.7767 - val_loss: 0.4446 - val_acc: 0.8492\n",
      "Epoch 324/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5308 - acc: 0.7598 - val_loss: 0.4443 - val_acc: 0.8492\n",
      "Epoch 325/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5083 - acc: 0.7767 - val_loss: 0.4439 - val_acc: 0.8492\n",
      "Epoch 326/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5139 - acc: 0.7753 - val_loss: 0.4434 - val_acc: 0.8492\n",
      "Epoch 327/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5206 - acc: 0.7739 - val_loss: 0.4430 - val_acc: 0.8492\n",
      "Epoch 328/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5120 - acc: 0.7654 - val_loss: 0.4426 - val_acc: 0.8492\n",
      "Epoch 329/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5189 - acc: 0.7556 - val_loss: 0.4422 - val_acc: 0.8492\n",
      "Epoch 330/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5235 - acc: 0.7739 - val_loss: 0.4419 - val_acc: 0.8492\n",
      "Epoch 331/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5181 - acc: 0.7739 - val_loss: 0.4415 - val_acc: 0.8492\n",
      "Epoch 332/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5023 - acc: 0.7992 - val_loss: 0.4410 - val_acc: 0.8492\n",
      "Epoch 333/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5233 - acc: 0.7711 - val_loss: 0.4405 - val_acc: 0.8492\n",
      "Epoch 334/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5192 - acc: 0.7781 - val_loss: 0.4400 - val_acc: 0.8492\n",
      "Epoch 335/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5118 - acc: 0.7753 - val_loss: 0.4396 - val_acc: 0.8492\n",
      "Epoch 336/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5179 - acc: 0.7570 - val_loss: 0.4391 - val_acc: 0.8492\n",
      "Epoch 337/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5261 - acc: 0.7753 - val_loss: 0.4388 - val_acc: 0.8547\n",
      "Epoch 338/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5071 - acc: 0.7823 - val_loss: 0.4383 - val_acc: 0.8547\n",
      "Epoch 339/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5141 - acc: 0.7556 - val_loss: 0.4378 - val_acc: 0.8547\n",
      "Epoch 340/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5267 - acc: 0.7640 - val_loss: 0.4375 - val_acc: 0.8547\n",
      "Epoch 341/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5161 - acc: 0.7640 - val_loss: 0.4371 - val_acc: 0.8547\n",
      "Epoch 342/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5225 - acc: 0.7514 - val_loss: 0.4367 - val_acc: 0.8547\n",
      "Epoch 343/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5215 - acc: 0.7935 - val_loss: 0.4364 - val_acc: 0.8547\n",
      "Epoch 344/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5282 - acc: 0.7739 - val_loss: 0.4360 - val_acc: 0.8547\n",
      "Epoch 345/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5271 - acc: 0.7486 - val_loss: 0.4358 - val_acc: 0.8547\n",
      "Epoch 346/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5242 - acc: 0.7556 - val_loss: 0.4354 - val_acc: 0.8547\n",
      "Epoch 347/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5171 - acc: 0.7753 - val_loss: 0.4352 - val_acc: 0.8547\n",
      "Epoch 348/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5103 - acc: 0.7725 - val_loss: 0.4348 - val_acc: 0.8547\n",
      "Epoch 349/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5177 - acc: 0.7725 - val_loss: 0.4345 - val_acc: 0.8547\n",
      "Epoch 350/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5177 - acc: 0.7893 - val_loss: 0.4342 - val_acc: 0.8547\n",
      "Epoch 351/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5196 - acc: 0.7767 - val_loss: 0.4338 - val_acc: 0.8547\n",
      "Epoch 352/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5296 - acc: 0.7598 - val_loss: 0.4336 - val_acc: 0.8547\n",
      "Epoch 353/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5167 - acc: 0.7753 - val_loss: 0.4333 - val_acc: 0.8547\n",
      "Epoch 354/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4931 - acc: 0.7795 - val_loss: 0.4329 - val_acc: 0.8547\n",
      "Epoch 355/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5090 - acc: 0.7809 - val_loss: 0.4326 - val_acc: 0.8547\n",
      "Epoch 356/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5075 - acc: 0.7725 - val_loss: 0.4322 - val_acc: 0.8547\n",
      "Epoch 357/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5000 - acc: 0.7556 - val_loss: 0.4318 - val_acc: 0.8547\n",
      "Epoch 358/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5096 - acc: 0.7823 - val_loss: 0.4314 - val_acc: 0.8547\n",
      "Epoch 359/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5091 - acc: 0.7654 - val_loss: 0.4311 - val_acc: 0.8547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5029 - acc: 0.7725 - val_loss: 0.4307 - val_acc: 0.8547\n",
      "Epoch 361/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5258 - acc: 0.7893 - val_loss: 0.4303 - val_acc: 0.8547\n",
      "Epoch 362/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5229 - acc: 0.7837 - val_loss: 0.4301 - val_acc: 0.8547\n",
      "Epoch 363/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5021 - acc: 0.7781 - val_loss: 0.4297 - val_acc: 0.8547\n",
      "Epoch 364/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5188 - acc: 0.7556 - val_loss: 0.4293 - val_acc: 0.8547\n",
      "Epoch 365/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5143 - acc: 0.7654 - val_loss: 0.4290 - val_acc: 0.8547\n",
      "Epoch 366/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5193 - acc: 0.7486 - val_loss: 0.4287 - val_acc: 0.8547\n",
      "Epoch 367/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.5252 - acc: 0.7640 - val_loss: 0.4284 - val_acc: 0.8547\n",
      "Epoch 368/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5123 - acc: 0.7795 - val_loss: 0.4283 - val_acc: 0.8547\n",
      "Epoch 369/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5059 - acc: 0.7865 - val_loss: 0.4279 - val_acc: 0.8547\n",
      "Epoch 370/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5112 - acc: 0.7612 - val_loss: 0.4277 - val_acc: 0.8547\n",
      "Epoch 371/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5083 - acc: 0.7879 - val_loss: 0.4274 - val_acc: 0.8492\n",
      "Epoch 372/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5066 - acc: 0.7795 - val_loss: 0.4270 - val_acc: 0.8492\n",
      "Epoch 373/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5039 - acc: 0.7851 - val_loss: 0.4266 - val_acc: 0.8492\n",
      "Epoch 374/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5102 - acc: 0.7711 - val_loss: 0.4263 - val_acc: 0.8492\n",
      "Epoch 375/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5289 - acc: 0.7697 - val_loss: 0.4260 - val_acc: 0.8492\n",
      "Epoch 376/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.5131 - acc: 0.7725 - val_loss: 0.4257 - val_acc: 0.8492\n",
      "Epoch 377/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5257 - acc: 0.7598 - val_loss: 0.4255 - val_acc: 0.8492\n",
      "Epoch 378/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4979 - acc: 0.7837 - val_loss: 0.4252 - val_acc: 0.8492\n",
      "Epoch 379/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4977 - acc: 0.7781 - val_loss: 0.4248 - val_acc: 0.8492\n",
      "Epoch 380/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5152 - acc: 0.7739 - val_loss: 0.4245 - val_acc: 0.8492\n",
      "Epoch 381/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5003 - acc: 0.7683 - val_loss: 0.4241 - val_acc: 0.8492\n",
      "Epoch 382/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5226 - acc: 0.7570 - val_loss: 0.4239 - val_acc: 0.8492\n",
      "Epoch 383/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5062 - acc: 0.7739 - val_loss: 0.4236 - val_acc: 0.8492\n",
      "Epoch 384/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4990 - acc: 0.7753 - val_loss: 0.4233 - val_acc: 0.8492\n",
      "Epoch 385/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4954 - acc: 0.7725 - val_loss: 0.4231 - val_acc: 0.8492\n",
      "Epoch 386/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4902 - acc: 0.7711 - val_loss: 0.4228 - val_acc: 0.8492\n",
      "Epoch 387/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5023 - acc: 0.7626 - val_loss: 0.4224 - val_acc: 0.8492\n",
      "Epoch 388/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5180 - acc: 0.7753 - val_loss: 0.4221 - val_acc: 0.8492\n",
      "Epoch 389/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5024 - acc: 0.7907 - val_loss: 0.4218 - val_acc: 0.8492\n",
      "Epoch 390/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5041 - acc: 0.7767 - val_loss: 0.4216 - val_acc: 0.8492\n",
      "Epoch 391/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4837 - acc: 0.7795 - val_loss: 0.4213 - val_acc: 0.8492\n",
      "Epoch 392/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4993 - acc: 0.7851 - val_loss: 0.4210 - val_acc: 0.8492\n",
      "Epoch 393/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5056 - acc: 0.7823 - val_loss: 0.4208 - val_acc: 0.8492\n",
      "Epoch 394/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4944 - acc: 0.7626 - val_loss: 0.4205 - val_acc: 0.8492\n",
      "Epoch 395/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4968 - acc: 0.7795 - val_loss: 0.4201 - val_acc: 0.8492\n",
      "Epoch 396/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5022 - acc: 0.7767 - val_loss: 0.4199 - val_acc: 0.8492\n",
      "Epoch 397/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4896 - acc: 0.7963 - val_loss: 0.4195 - val_acc: 0.8547\n",
      "Epoch 398/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5187 - acc: 0.7570 - val_loss: 0.4192 - val_acc: 0.8547\n",
      "Epoch 399/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5019 - acc: 0.7823 - val_loss: 0.4189 - val_acc: 0.8547\n",
      "Epoch 400/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5071 - acc: 0.7795 - val_loss: 0.4186 - val_acc: 0.8547\n",
      "Epoch 401/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4976 - acc: 0.7949 - val_loss: 0.4183 - val_acc: 0.8547\n",
      "Epoch 402/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5047 - acc: 0.7865 - val_loss: 0.4182 - val_acc: 0.8547\n",
      "Epoch 403/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5105 - acc: 0.7725 - val_loss: 0.4179 - val_acc: 0.8547\n",
      "Epoch 404/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5235 - acc: 0.7612 - val_loss: 0.4177 - val_acc: 0.8547\n",
      "Epoch 405/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.5004 - acc: 0.7739 - val_loss: 0.4173 - val_acc: 0.8547\n",
      "Epoch 406/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5175 - acc: 0.7584 - val_loss: 0.4171 - val_acc: 0.8547\n",
      "Epoch 407/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5089 - acc: 0.7711 - val_loss: 0.4169 - val_acc: 0.8547\n",
      "Epoch 408/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5135 - acc: 0.7739 - val_loss: 0.4168 - val_acc: 0.8547\n",
      "Epoch 409/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5008 - acc: 0.7781 - val_loss: 0.4165 - val_acc: 0.8547\n",
      "Epoch 410/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5025 - acc: 0.7640 - val_loss: 0.4162 - val_acc: 0.8547\n",
      "Epoch 411/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4871 - acc: 0.8062 - val_loss: 0.4159 - val_acc: 0.8547\n",
      "Epoch 412/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5184 - acc: 0.7739 - val_loss: 0.4158 - val_acc: 0.8547\n",
      "Epoch 413/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5004 - acc: 0.7767 - val_loss: 0.4156 - val_acc: 0.8547\n",
      "Epoch 414/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4944 - acc: 0.7935 - val_loss: 0.4153 - val_acc: 0.8547\n",
      "Epoch 415/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5107 - acc: 0.7711 - val_loss: 0.4151 - val_acc: 0.8547\n",
      "Epoch 416/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4875 - acc: 0.7753 - val_loss: 0.4148 - val_acc: 0.8547\n",
      "Epoch 417/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4853 - acc: 0.8076 - val_loss: 0.4144 - val_acc: 0.8547\n",
      "Epoch 418/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5011 - acc: 0.7809 - val_loss: 0.4141 - val_acc: 0.8547\n",
      "Epoch 419/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4998 - acc: 0.7837 - val_loss: 0.4138 - val_acc: 0.8547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4964 - acc: 0.7907 - val_loss: 0.4136 - val_acc: 0.8547\n",
      "Epoch 421/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5066 - acc: 0.7767 - val_loss: 0.4134 - val_acc: 0.8547\n",
      "Epoch 422/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5070 - acc: 0.7823 - val_loss: 0.4132 - val_acc: 0.8547\n",
      "Epoch 423/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4832 - acc: 0.7865 - val_loss: 0.4129 - val_acc: 0.8547\n",
      "Epoch 424/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4910 - acc: 0.7809 - val_loss: 0.4125 - val_acc: 0.8547\n",
      "Epoch 425/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4952 - acc: 0.7963 - val_loss: 0.4124 - val_acc: 0.8547\n",
      "Epoch 426/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.4957 - acc: 0.7837 - val_loss: 0.4121 - val_acc: 0.8547\n",
      "Epoch 427/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4940 - acc: 0.8034 - val_loss: 0.4119 - val_acc: 0.8547\n",
      "Epoch 428/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5078 - acc: 0.7837 - val_loss: 0.4118 - val_acc: 0.8547\n",
      "Epoch 429/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4927 - acc: 0.7921 - val_loss: 0.4115 - val_acc: 0.8547\n",
      "Epoch 430/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5016 - acc: 0.7851 - val_loss: 0.4112 - val_acc: 0.8547\n",
      "Epoch 431/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4880 - acc: 0.8006 - val_loss: 0.4110 - val_acc: 0.8547\n",
      "Epoch 432/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4896 - acc: 0.7612 - val_loss: 0.4107 - val_acc: 0.8547\n",
      "Epoch 433/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5107 - acc: 0.7725 - val_loss: 0.4105 - val_acc: 0.8547\n",
      "Epoch 434/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4896 - acc: 0.7921 - val_loss: 0.4103 - val_acc: 0.8547\n",
      "Epoch 435/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4813 - acc: 0.7921 - val_loss: 0.4101 - val_acc: 0.8547\n",
      "Epoch 436/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4922 - acc: 0.7767 - val_loss: 0.4098 - val_acc: 0.8547\n",
      "Epoch 437/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4958 - acc: 0.7823 - val_loss: 0.4096 - val_acc: 0.8547\n",
      "Epoch 438/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4945 - acc: 0.7669 - val_loss: 0.4093 - val_acc: 0.8547\n",
      "Epoch 439/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5107 - acc: 0.7921 - val_loss: 0.4091 - val_acc: 0.8547\n",
      "Epoch 440/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4994 - acc: 0.7767 - val_loss: 0.4089 - val_acc: 0.8547\n",
      "Epoch 441/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4969 - acc: 0.7753 - val_loss: 0.4087 - val_acc: 0.8547\n",
      "Epoch 442/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4769 - acc: 0.7893 - val_loss: 0.4084 - val_acc: 0.8547\n",
      "Epoch 443/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4982 - acc: 0.7837 - val_loss: 0.4081 - val_acc: 0.8547\n",
      "Epoch 444/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4999 - acc: 0.7907 - val_loss: 0.4080 - val_acc: 0.8547\n",
      "Epoch 445/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4825 - acc: 0.8020 - val_loss: 0.4078 - val_acc: 0.8547\n",
      "Epoch 446/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4915 - acc: 0.7795 - val_loss: 0.4075 - val_acc: 0.8547\n",
      "Epoch 447/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4857 - acc: 0.7949 - val_loss: 0.4074 - val_acc: 0.8547\n",
      "Epoch 448/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4909 - acc: 0.7893 - val_loss: 0.4071 - val_acc: 0.8547\n",
      "Epoch 449/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5060 - acc: 0.7851 - val_loss: 0.4068 - val_acc: 0.8547\n",
      "Epoch 450/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4996 - acc: 0.7640 - val_loss: 0.4065 - val_acc: 0.8547\n",
      "Epoch 451/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5117 - acc: 0.7893 - val_loss: 0.4063 - val_acc: 0.8547\n",
      "Epoch 452/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4985 - acc: 0.7837 - val_loss: 0.4062 - val_acc: 0.8547\n",
      "Epoch 453/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4988 - acc: 0.7893 - val_loss: 0.4061 - val_acc: 0.8547\n",
      "Epoch 454/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4982 - acc: 0.7963 - val_loss: 0.4059 - val_acc: 0.8547\n",
      "Epoch 455/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.5060 - acc: 0.7809 - val_loss: 0.4056 - val_acc: 0.8547\n",
      "Epoch 456/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.5041 - acc: 0.7935 - val_loss: 0.4055 - val_acc: 0.8547\n",
      "Epoch 457/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4824 - acc: 0.7865 - val_loss: 0.4054 - val_acc: 0.8547\n",
      "Epoch 458/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4876 - acc: 0.7809 - val_loss: 0.4052 - val_acc: 0.8547\n",
      "Epoch 459/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4977 - acc: 0.7963 - val_loss: 0.4050 - val_acc: 0.8547\n",
      "Epoch 460/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4711 - acc: 0.8090 - val_loss: 0.4048 - val_acc: 0.8547\n",
      "Epoch 461/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4859 - acc: 0.7851 - val_loss: 0.4045 - val_acc: 0.8547\n",
      "Epoch 462/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4765 - acc: 0.7851 - val_loss: 0.4042 - val_acc: 0.8547\n",
      "Epoch 463/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4978 - acc: 0.7837 - val_loss: 0.4040 - val_acc: 0.8603\n",
      "Epoch 464/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4771 - acc: 0.7879 - val_loss: 0.4038 - val_acc: 0.8603\n",
      "Epoch 465/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4802 - acc: 0.8048 - val_loss: 0.4036 - val_acc: 0.8603\n",
      "Epoch 466/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4894 - acc: 0.7683 - val_loss: 0.4032 - val_acc: 0.8603\n",
      "Epoch 467/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4694 - acc: 0.7879 - val_loss: 0.4031 - val_acc: 0.8603\n",
      "Epoch 468/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4747 - acc: 0.7893 - val_loss: 0.4028 - val_acc: 0.8603\n",
      "Epoch 469/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4778 - acc: 0.7907 - val_loss: 0.4026 - val_acc: 0.8603\n",
      "Epoch 470/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4918 - acc: 0.7978 - val_loss: 0.4023 - val_acc: 0.8603\n",
      "Epoch 471/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4954 - acc: 0.7851 - val_loss: 0.4021 - val_acc: 0.8603\n",
      "Epoch 472/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4904 - acc: 0.7893 - val_loss: 0.4019 - val_acc: 0.8603\n",
      "Epoch 473/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4680 - acc: 0.8048 - val_loss: 0.4017 - val_acc: 0.8603\n",
      "Epoch 474/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4929 - acc: 0.7865 - val_loss: 0.4015 - val_acc: 0.8603\n",
      "Epoch 475/1000\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4899 - acc: 0.7837 - val_loss: 0.4014 - val_acc: 0.8603\n",
      "Epoch 476/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4770 - acc: 0.8146 - val_loss: 0.4012 - val_acc: 0.8603\n",
      "Epoch 477/1000\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.5133 - acc: 0.7823 - val_loss: 0.4011 - val_acc: 0.8603\n",
      "Epoch 478/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4956 - acc: 0.7654 - val_loss: 0.4010 - val_acc: 0.8603\n",
      "Epoch 479/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4793 - acc: 0.7949 - val_loss: 0.4008 - val_acc: 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4836 - acc: 0.7837 - val_loss: 0.4007 - val_acc: 0.8603\n",
      "Epoch 481/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4793 - acc: 0.7935 - val_loss: 0.4005 - val_acc: 0.8603\n",
      "Epoch 482/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4743 - acc: 0.7879 - val_loss: 0.4003 - val_acc: 0.8603\n",
      "Epoch 483/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4991 - acc: 0.7781 - val_loss: 0.4001 - val_acc: 0.8603\n",
      "Epoch 484/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4705 - acc: 0.8216 - val_loss: 0.3999 - val_acc: 0.8603\n",
      "Epoch 485/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.5021 - acc: 0.7823 - val_loss: 0.3998 - val_acc: 0.8603\n",
      "Epoch 486/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4927 - acc: 0.7823 - val_loss: 0.3997 - val_acc: 0.8603\n",
      "Epoch 487/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4835 - acc: 0.7963 - val_loss: 0.3995 - val_acc: 0.8603\n",
      "Epoch 488/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4776 - acc: 0.7921 - val_loss: 0.3993 - val_acc: 0.8659\n",
      "Epoch 489/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4594 - acc: 0.8188 - val_loss: 0.3991 - val_acc: 0.8659\n",
      "Epoch 490/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4767 - acc: 0.8090 - val_loss: 0.3988 - val_acc: 0.8659\n",
      "Epoch 491/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4873 - acc: 0.7907 - val_loss: 0.3988 - val_acc: 0.8659\n",
      "Epoch 492/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4718 - acc: 0.7935 - val_loss: 0.3984 - val_acc: 0.8659\n",
      "Epoch 493/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4805 - acc: 0.7851 - val_loss: 0.3982 - val_acc: 0.8603\n",
      "Epoch 494/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4721 - acc: 0.7893 - val_loss: 0.3980 - val_acc: 0.8659\n",
      "Epoch 495/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4741 - acc: 0.8048 - val_loss: 0.3978 - val_acc: 0.8659\n",
      "Epoch 496/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4745 - acc: 0.7949 - val_loss: 0.3976 - val_acc: 0.8659\n",
      "Epoch 497/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4762 - acc: 0.8006 - val_loss: 0.3975 - val_acc: 0.8659\n",
      "Epoch 498/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4841 - acc: 0.7837 - val_loss: 0.3973 - val_acc: 0.8659\n",
      "Epoch 499/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4862 - acc: 0.7753 - val_loss: 0.3971 - val_acc: 0.8659\n",
      "Epoch 500/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4755 - acc: 0.7992 - val_loss: 0.3969 - val_acc: 0.8659\n",
      "Epoch 501/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4778 - acc: 0.8006 - val_loss: 0.3968 - val_acc: 0.8659\n",
      "Epoch 502/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4901 - acc: 0.7992 - val_loss: 0.3966 - val_acc: 0.8659\n",
      "Epoch 503/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4557 - acc: 0.8090 - val_loss: 0.3963 - val_acc: 0.8659\n",
      "Epoch 504/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4814 - acc: 0.8006 - val_loss: 0.3961 - val_acc: 0.8659\n",
      "Epoch 505/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4879 - acc: 0.7992 - val_loss: 0.3960 - val_acc: 0.8659\n",
      "Epoch 506/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4827 - acc: 0.8188 - val_loss: 0.3958 - val_acc: 0.8659\n",
      "Epoch 507/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4764 - acc: 0.8104 - val_loss: 0.3957 - val_acc: 0.8659\n",
      "Epoch 508/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4822 - acc: 0.7795 - val_loss: 0.3955 - val_acc: 0.8659\n",
      "Epoch 509/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4760 - acc: 0.7992 - val_loss: 0.3954 - val_acc: 0.8659\n",
      "Epoch 510/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4804 - acc: 0.7851 - val_loss: 0.3951 - val_acc: 0.8659\n",
      "Epoch 511/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4903 - acc: 0.7753 - val_loss: 0.3949 - val_acc: 0.8659\n",
      "Epoch 512/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4780 - acc: 0.7992 - val_loss: 0.3948 - val_acc: 0.8659\n",
      "Epoch 513/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4820 - acc: 0.8118 - val_loss: 0.3945 - val_acc: 0.8659\n",
      "Epoch 514/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4946 - acc: 0.7893 - val_loss: 0.3945 - val_acc: 0.8659\n",
      "Epoch 515/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4792 - acc: 0.7767 - val_loss: 0.3943 - val_acc: 0.8659\n",
      "Epoch 516/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4865 - acc: 0.7907 - val_loss: 0.3940 - val_acc: 0.8659\n",
      "Epoch 517/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4873 - acc: 0.7837 - val_loss: 0.3939 - val_acc: 0.8659\n",
      "Epoch 518/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4726 - acc: 0.8132 - val_loss: 0.3938 - val_acc: 0.8659\n",
      "Epoch 519/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4888 - acc: 0.7893 - val_loss: 0.3937 - val_acc: 0.8659\n",
      "Epoch 520/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4881 - acc: 0.7921 - val_loss: 0.3936 - val_acc: 0.8659\n",
      "Epoch 521/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4763 - acc: 0.8020 - val_loss: 0.3936 - val_acc: 0.8659\n",
      "Epoch 522/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4900 - acc: 0.7837 - val_loss: 0.3935 - val_acc: 0.8659\n",
      "Epoch 523/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4728 - acc: 0.8006 - val_loss: 0.3933 - val_acc: 0.8659\n",
      "Epoch 524/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4893 - acc: 0.7725 - val_loss: 0.3931 - val_acc: 0.8659\n",
      "Epoch 525/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4796 - acc: 0.8020 - val_loss: 0.3930 - val_acc: 0.8659\n",
      "Epoch 526/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4748 - acc: 0.7978 - val_loss: 0.3929 - val_acc: 0.8659\n",
      "Epoch 527/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4884 - acc: 0.7935 - val_loss: 0.3927 - val_acc: 0.8659\n",
      "Epoch 528/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4669 - acc: 0.8104 - val_loss: 0.3926 - val_acc: 0.8659\n",
      "Epoch 529/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4845 - acc: 0.8020 - val_loss: 0.3924 - val_acc: 0.8659\n",
      "Epoch 530/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4945 - acc: 0.7907 - val_loss: 0.3924 - val_acc: 0.8659\n",
      "Epoch 531/1000\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4749 - acc: 0.8048 - val_loss: 0.3922 - val_acc: 0.8659\n",
      "Epoch 532/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4766 - acc: 0.7921 - val_loss: 0.3921 - val_acc: 0.8659\n",
      "Epoch 533/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4799 - acc: 0.7935 - val_loss: 0.3919 - val_acc: 0.8659\n",
      "Epoch 534/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4582 - acc: 0.8216 - val_loss: 0.3918 - val_acc: 0.8659\n",
      "Epoch 535/1000\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4929 - acc: 0.7935 - val_loss: 0.3916 - val_acc: 0.8659\n",
      "Epoch 536/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4870 - acc: 0.7921 - val_loss: 0.3915 - val_acc: 0.8659\n",
      "Epoch 537/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4705 - acc: 0.7978 - val_loss: 0.3913 - val_acc: 0.8659\n",
      "Epoch 538/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4650 - acc: 0.8118 - val_loss: 0.3909 - val_acc: 0.8659\n",
      "Epoch 539/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4923 - acc: 0.7978 - val_loss: 0.3909 - val_acc: 0.8659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4668 - acc: 0.7949 - val_loss: 0.3908 - val_acc: 0.8659\n",
      "Epoch 541/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4660 - acc: 0.8272 - val_loss: 0.3906 - val_acc: 0.8659\n",
      "Epoch 542/1000\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4787 - acc: 0.7935 - val_loss: 0.3906 - val_acc: 0.8659\n",
      "Epoch 543/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4904 - acc: 0.8174 - val_loss: 0.3904 - val_acc: 0.8603\n",
      "Epoch 544/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4726 - acc: 0.7893 - val_loss: 0.3903 - val_acc: 0.8603\n",
      "Epoch 545/1000\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4515 - acc: 0.8160 - val_loss: 0.3900 - val_acc: 0.8603\n",
      "Epoch 546/1000\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4694 - acc: 0.8146 - val_loss: 0.3898 - val_acc: 0.8603\n",
      "Epoch 547/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4779 - acc: 0.7963 - val_loss: 0.3898 - val_acc: 0.8603\n",
      "Epoch 548/1000\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4573 - acc: 0.8006 - val_loss: 0.3895 - val_acc: 0.8547\n",
      "Epoch 549/1000\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4689 - acc: 0.8146 - val_loss: 0.3894 - val_acc: 0.8547\n",
      "Epoch 550/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4656 - acc: 0.8020 - val_loss: 0.3892 - val_acc: 0.8547\n",
      "Epoch 551/1000\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4733 - acc: 0.8174 - val_loss: 0.3891 - val_acc: 0.8547\n",
      "Epoch 552/1000\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4857 - acc: 0.7865 - val_loss: 0.3891 - val_acc: 0.8547\n",
      "Epoch 553/1000\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4973 - acc: 0.7921 - val_loss: 0.3891 - val_acc: 0.8547\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(df_one_hot_train, \n",
    "                    pd.get_dummies(df_train[LABEL].astype(str)), \n",
    "                    epochs=1000, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792134831461\n",
      "0.854748601687\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'][-1])\n",
    "print(history.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d3d3a2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2PglqTE2fklqjI1fkhpj45ekxnwBxmjmPk95FHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d3d32a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plt, = plt.plot(history.history['loss'], label='train')\n",
    "val_loss_plt, = plt.plot(history.history['val_loss'], label='valid')\n",
    "\n",
    "plt.legend(handles=[loss_plt, val_loss_plt])\n",
    "plt.show()\n",
    "\n",
    "acc_plt, = plt.plot(history.history['acc'], label='train')\n",
    "val_acc_plt, = plt.plot(history.history['val_acc'], label='valid')\n",
    "\n",
    "plt.legend(handles=[loss_plt, val_loss_plt])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Survived'] = np.apply_along_axis(np.argmax, 1, model.predict(df_one_hot_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35406698564593303"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Survived'].sum()/len(df_test['Survived'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['PassengerId', 'Survived']].to_csv(path_or_buf='./out.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
